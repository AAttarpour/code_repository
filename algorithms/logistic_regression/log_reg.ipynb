{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ahmadreza Attarpour  \n",
    "**Email:** [a.attarpour@mail.utoronto.ca](mailto:a.attarpour@mail.utoronto.ca)  \n",
    "\n",
    "This notebook demonstrates logistic regression algorithm for a simple classification task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Logistic Regression Overview**\n",
    "Logistic Regression is a classification algorithm used to predict **binary outcomes** (e.g., 0 or 1, Yes or No, Spam or Not Spam). It is based on the **sigmoid function**, which maps real-valued inputs into a range between **0 and 1**.\n",
    "\n",
    "## **2. Mathematical Formulation**\n",
    "Given an input feature vector \\( X \\), we compute a linear combination of the features:\n",
    "\n",
    "$$\n",
    "z = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( z \\) is the linear combination of inputs\n",
    "- \\( w_0 \\) (bias term) and \\( w_i \\) (weights) are parameters of the model\n",
    "- \\( x_i \\) are the feature values\n",
    "\n",
    "## **3. Sigmoid (Logistic) Function**\n",
    "To convert the linear output \\( z \\) into a probability between 0 and 1, we apply the **sigmoid function**:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "This function ensures that the output is always between **0 and 1**.\n",
    "\n",
    "## **4. Hypothesis Function**\n",
    "The probability of class **1** (positive class) is given by:\n",
    "\n",
    "$$\n",
    "P(y=1 | X) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Similarly, the probability of class **0** (negative class) is:\n",
    "\n",
    "$$\n",
    "P(y=0 | X) = 1 - \\sigma(z)\n",
    "$$\n",
    "\n",
    "## **5. Cost Function (Log Loss)**\n",
    "The cost function for logistic regression is called the **log loss (logarithmic loss)**:\n",
    "\n",
    "$$\n",
    "J(w) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( m \\) is the number of training samples\n",
    "- \\( y^{(i)} \\) is the actual class label (0 or 1)\n",
    "- \\( \\hat{y}^{(i)} = \\sigma(z) \\) is the predicted probability\n",
    "\n",
    "## **6. Gradient Descent for Optimization**\n",
    "To find the optimal weights \\( w \\), we use **gradient descent**:\n",
    "\n",
    "$$\n",
    "w_j := w_j - \\alpha \\frac{\\partial J(w)}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( \\alpha \\) is the learning rate\n",
    "- The gradient of the cost function w.r.t \\( w_j \\) is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(w)}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "This updates the weights to minimize the cost function.\n",
    "\n",
    "## **7. Decision Boundary**\n",
    "To classify a new sample, we use a **threshold**:\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } \\sigma(z) \\geq 0.5 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This means if the predicted probability \\( \\hat{y} \\) is **greater than or equal to 0.5**, we classify it as **1**; otherwise, we classify it as **0**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Python Practice\n",
    "---\n",
    "We will use the scikit-learnâ€™s decision tree classifier to classify patients into liver patient (liver disease) or not (no disease). \n",
    "\n",
    "We will use a dataset of 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. 10 variables for each patient are recorded, and the true label is in column Dataset. The data is obtained through https://www.kaggle.com/datasets/uciml/indian-liver-patient-records. We will use the data stored in HW1_data.csv on the course website for this assignment.\n",
    "You will build a KNN classifier to classify patients into liver patient (liver disease) or not (no disease).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler,  LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Source\n",
    "# setting random seed for reproducibility\n",
    "np.random.seed(1210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data\n",
    "data_path = \"/Users/ahmadreza/Documents/Files/PhD Files/code/code_repository/algorithms/logistic_regression/hw1_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the data\n",
    "def load_data(data_path: str) -> tuple[list, list, list]:\n",
    "    # Load the dataset from the given CSV file\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(df)\n",
    "    \n",
    "    # Initialize the encoder for categorical 'Gender' feature\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Encode the 'Gender' column (Male: 0, Female: 1)\n",
    "    df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "    \n",
    "    # Extract target labels from 'Dataset' column\n",
    "    y = df[\"Dataset\"].to_numpy()\n",
    "    \n",
    "    # Drop the target column from the feature set\n",
    "    df = df.drop(columns=[\"Dataset\"])\n",
    "    \n",
    "    # Convert features to numpy array\n",
    "    X = df.to_numpy()\n",
    "    \n",
    "    # Handle NaN values by replacing them with 0\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    # Split the dataset into training + validation and testing sets (80% train + validation, 20% test)\n",
    "    train_val_X, test_X, train_val_y, test_y = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    # Split the training + validation set into train and validation sets (90% train, 10% validation)\n",
    "    train_X, val_X, train_y, val_y = train_test_split(train_val_X, train_val_y, test_size=(0.10/0.80))\n",
    "    \n",
    "    # Return the train, validation, and test sets as tuples\n",
    "    return [train_X, train_y], [val_X, val_y], [test_X, test_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
      "0     65  Female              0.7               0.1                   187   \n",
      "1     62    Male             10.9               5.5                   699   \n",
      "2     62    Male              7.3               4.1                   490   \n",
      "3     58    Male              1.0               0.4                   182   \n",
      "4     72    Male              3.9               2.0                   195   \n",
      "..   ...     ...              ...               ...                   ...   \n",
      "578   60    Male              0.5               0.1                   500   \n",
      "579   40    Male              0.6               0.1                    98   \n",
      "580   52    Male              0.8               0.2                   245   \n",
      "581   31    Male              1.3               0.5                   184   \n",
      "582   38    Male              1.0               0.3                   216   \n",
      "\n",
      "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
      "0                          16                          18             6.8   \n",
      "1                          64                         100             7.5   \n",
      "2                          60                          68             7.0   \n",
      "3                          14                          20             6.8   \n",
      "4                          27                          59             7.3   \n",
      "..                        ...                         ...             ...   \n",
      "578                        20                          34             5.9   \n",
      "579                        35                          31             6.0   \n",
      "580                        48                          49             6.4   \n",
      "581                        29                          32             6.8   \n",
      "582                        21                          24             7.3   \n",
      "\n",
      "     Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
      "0        3.3                        0.90        1  \n",
      "1        3.2                        0.74        1  \n",
      "2        3.3                        0.89        1  \n",
      "3        3.4                        1.00        1  \n",
      "4        2.4                        0.40        1  \n",
      "..       ...                         ...      ...  \n",
      "578      1.6                        0.37        2  \n",
      "579      3.2                        1.10        1  \n",
      "580      3.2                        1.00        1  \n",
      "581      3.4                        1.00        1  \n",
      "582      4.4                        1.50        2  \n",
      "\n",
      "[583 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train, val, test = load_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_rec(\n",
    "        train: tuple[list, list],\n",
    "        val: tuple[list, list],\n",
    "        standardization: bool = True, \n",
    "        solver: str = 'lbfgs',\n",
    "        penalty: str = 'l2',\n",
    "        fit_intercept: bool = True,\n",
    "        max_iter: int = 100\n",
    ") -> LogisticRegression:\n",
    "\n",
    "    # Extract data and labels for training, validation, and testing\n",
    "    train_X, train_y = train[0], train[1]\n",
    "    val_X, val_y = val[0], val[1]\n",
    "\n",
    "    # If standardization is enabled, scale the features to have zero mean and unit variance\n",
    "    if standardization:\n",
    "        scaler = StandardScaler().fit(train_X)  # Fit scaler on training data\n",
    "        train_X = scaler.transform(train_X)  # Apply transformation to training data\n",
    "        val_X = scaler.transform(val_X)  # Apply transformation to validation data\n",
    "\n",
    "    # Initialize the logistic regression model\n",
    "    model = LogisticRegression(penalty=penalty, solver=solver, fit_intercept=fit_intercept, max_iter=max_iter)\n",
    "    model.fit(train_X, train_y)  # Fit the model on the training data\n",
    "    print(f\"Training accuracy: {model.score(train_X, train_y):.2f}\")  # Compute the training accuracy\n",
    "    print(f\"Training accuracy: {model.score(val_X, val_y):.2f}\")  # Compute the training accuracy\n",
    "    print(f\"model coefficients and intercept: {model.coef_}, {model.intercept_}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(\n",
    "        model: LogisticRegression,\n",
    "        test: tuple[list, list],\n",
    "        standardization=True,\n",
    ") -> None:\n",
    "        # Extract data and labels for testing\n",
    "        test_X, test_y = test[0], test[1]\n",
    "        if standardization:\n",
    "            scaler = StandardScaler().fit(test_X)  # Fit scaler on training data\n",
    "            test_X = scaler.transform(test_X)\n",
    "        \n",
    "        print(f\"Test accuracy: {model.score(test_X, test_y):.2f}\")  # Compute the test accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.73\n",
      "Training accuracy: 0.76\n",
      "model coefficients and intercept: [[-0.29245042 -0.04213527 -0.27462571 -0.90181007 -0.27261782 -1.08441888\n",
      "  -0.63433761 -0.37197053  0.39236702 -0.13727922]], [-1.47372187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadreza/anaconda3/envs/aa_ml/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = train_logistic_rec(train,\n",
    "                            val,\n",
    "                            standardization=True,\n",
    "                            solver='saga',\n",
    "                            penalty='l1',\n",
    "                            fit_intercept=True,\n",
    "                            max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.72\n",
      "Training accuracy: 0.75\n",
      "model coefficients and intercept: [[-0.30187614 -0.04353233 -0.33050351 -0.8726239  -0.28869057 -1.17073254\n",
      "  -0.66645098 -0.63273211  0.76998586 -0.37284885]], [-1.53028852]\n"
     ]
    }
   ],
   "source": [
    "model2 = train_logistic_rec(train,\n",
    "                            val,\n",
    "                            standardization=True,\n",
    "                            penalty='l2',\n",
    "                            fit_intercept=True,\n",
    "                            max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(model1, test, standardization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(model2, test, standardization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
