{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ahmadreza Attarpour  \n",
    "**Email:** [a.attarpour@mail.utoronto.ca](mailto:a.attarpour@mail.utoronto.ca)  \n",
    "\n",
    "This notebook demonstrates MLP model for MNIST image classficaition using PyTorch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "The **MNIST** database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "We split the training set into 50k and 10k of training and validation data sets.\n",
    "\n",
    "**Data Set**  \n",
    "$$X_{train} \\in \\mathcal{R}^{50000 \\times 784}, Y_{train} \\in \\mathcal{Z}^{50000}$$  \n",
    "$$X_{val} \\in \\mathcal{R}^{10000 \\times 784}, Y_{val} \\in \\mathcal{Z}^{10000}$$  \n",
    "$$X_{test} \\in \\mathcal{R}^{10000 \\times 784}, Y_{test} \\in \\mathcal{Z}^{10000}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:03<00:00, 2.54MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 289kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 593kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.38MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: 50000\n",
      "Validation dataset shape: 10000\n",
      "Test dataset shape: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_dataset =  datasets.MNIST('./data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# print the shape and len of the datasets\n",
    "print(f\"Train dataset shape: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset shape: {len(val_dataset)}\")\n",
    "print(f\"Test dataset shape: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x900 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enumerating over the train_loader, which loads batches of the MNIST dataset.\n",
    "examples = enumerate(train_loader)\n",
    "# Get the first batch of data\n",
    "batch_idx, (example_data, example_targets) = next(examples)  \n",
    "\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mlp(nn.Module):\n",
    "    \"\"\"\n",
    "    A Multi-Layer Perceptron (MLP) model with customizable architecture.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dim (int): Number of neurons in each hidden layer.\n",
    "        output_dim (int): Number of output units.\n",
    "        num_layers (int): Number of hidden layers.\n",
    "        act_layer (nn.Module, optional): Activation function class (default is nn.ReLU).\n",
    "        dropout (float, optional): Dropout probability (default is 0.1).\n",
    "        batch_norm (bool, optional): Whether to apply Batch Normalization (default is False).\n",
    "        init_weights (bool, optional): Whether to initialize weights using He/Xavier based on activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim,\n",
    "                 num_layers, act_layer=nn.ReLU, dropout=0.1,\n",
    "                 batch_norm=False, init_weights=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.act_layer = act_layer\n",
    "        self.dropout = dropout\n",
    "        self.batch_norm = batch_norm\n",
    "        self.init_weights = init_weights\n",
    "\n",
    "        # First layer\n",
    "        self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Hidden layers and optional batchnorm\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.batch_norm_layers = nn.ModuleList()\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            if batch_norm:\n",
    "                self.batch_norm_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Activation and dropout\n",
    "        self.act = act_layer()\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "        # Optional initialization\n",
    "        if self.init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes weights using He or Xavier initialization\n",
    "        depending on the activation function.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if isinstance(self.act, nn.ReLU):  # Note: `self.act` not `self.act_layer`\n",
    "                    init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                elif isinstance(self.act, (nn.Sigmoid, nn.Tanh)):\n",
    "                    init.xavier_normal_(m.weight)\n",
    "                else:\n",
    "                    init.kaiming_normal_(m.weight, nonlinearity='relu')  # Fallback\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout_layer(x)\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.hidden_layers[i](x)\n",
    "            x = self.act(x)\n",
    "            if self.batch_norm:\n",
    "                x = self.batch_norm_layers[i](x)\n",
    "            x = self.dropout_layer(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available.\n"
     ]
    }
   ],
   "source": [
    "# for macOS users\n",
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found. Using CPU.\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(\"CUDA is available.\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"CUDA not found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiment Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(args):\n",
    "    model = Mlp(args.in_dim, args.hid_dim, args.out_dim, args.n_layers, args.act_layer, args.dropout, args.batch_norm, args.init_weights)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # ====== Loss function ====== #\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # ====== Data collection ====== #\n",
    "    list_epoch = [] \n",
    "    list_train_loss = []\n",
    "    list_val_loss = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    # ====== Loop ====== #\n",
    "    for epoch in range(args.epoch):  \n",
    "        \n",
    "        # ====== Train ====== #\n",
    "        model.train() # Set the model be 'train mode' \n",
    "        \n",
    "        # train_loader contains 128 * 1 * 28 * 28 boxes\n",
    "        train_loss = 0\n",
    "        for i, (input_X, true_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_x = input_X.squeeze()\n",
    "            input_x = input_x.view(-1, 784) # 28x28 = 784\n",
    "\n",
    "            input_x = input_x.to(device)\n",
    "            true_y = true_y.to(device)\n",
    "\n",
    "            pred_y = model(input_x)\n",
    "\n",
    "            loss = criterion(pred_y.squeeze(), true_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            # print loss for each step\n",
    "            print(f\"Step {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "        # calculate the train loss for this epoch\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_epoch.append(epoch)\n",
    "\n",
    "        # print average loss for the epoch\n",
    "        print(f\"Epoch {epoch+1}/{args.epoch}, Average Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # ====== Validation ====== #\n",
    "\n",
    "        if epoch % args.val_interval == 0:\n",
    "            model.eval() # Set the model be 'val mode' \n",
    "            val_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for input_X, true_y in val_loader:\n",
    "\n",
    "                    input_x = input_X.squeeze()\n",
    "                    input_x = input_x.view(-1, 784) # 28x28 = 784\n",
    "\n",
    "                    input_x = input_x.to(device)\n",
    "                    true_y = true_y.to(device)\n",
    "\n",
    "                    pred_y = model(input_x)\n",
    "\n",
    "                    loss = criterion(pred_y.squeeze(), true_y)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                val_loss = val_loss / len(val_loader)\n",
    "                list_val_loss.append(val_loss)\n",
    "\n",
    "                # print average loss for the epoch\n",
    "                print(f\"Epoch {epoch+1}/{args.epoch}, Average Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "                # Save the model if the validation loss is the best so far\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_epoch = epoch\n",
    "                    best_model = model\n",
    "                    print(f\"Model saved at epoch {epoch+1} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    return list_epoch, list_train_loss, list_val_loss, best_model\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp(\n",
      "  (fc_in): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (batch_norm_layers): ModuleList(\n",
      "    (0-3): 4 x BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (act): ReLU()\n",
      "  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Step 1/391, Loss: 3.0929\n",
      "Step 2/391, Loss: 2.6248\n",
      "Step 3/391, Loss: 1.8895\n",
      "Step 4/391, Loss: 1.6496\n",
      "Step 5/391, Loss: 1.3647\n",
      "Step 6/391, Loss: 1.3815\n",
      "Step 7/391, Loss: 1.5041\n",
      "Step 8/391, Loss: 1.1810\n",
      "Step 9/391, Loss: 1.0314\n",
      "Step 10/391, Loss: 1.2071\n",
      "Step 11/391, Loss: 1.0977\n",
      "Step 12/391, Loss: 0.8107\n",
      "Step 13/391, Loss: 0.9822\n",
      "Step 14/391, Loss: 0.7254\n",
      "Step 15/391, Loss: 0.7831\n",
      "Step 16/391, Loss: 0.6334\n",
      "Step 17/391, Loss: 0.7118\n",
      "Step 18/391, Loss: 0.6348\n",
      "Step 19/391, Loss: 0.7158\n",
      "Step 20/391, Loss: 0.7113\n",
      "Step 21/391, Loss: 0.6590\n",
      "Step 22/391, Loss: 0.7402\n",
      "Step 23/391, Loss: 0.5063\n",
      "Step 24/391, Loss: 0.7580\n",
      "Step 25/391, Loss: 0.5939\n",
      "Step 26/391, Loss: 0.4601\n",
      "Step 27/391, Loss: 0.6896\n",
      "Step 28/391, Loss: 0.3922\n",
      "Step 29/391, Loss: 0.6548\n",
      "Step 30/391, Loss: 0.5846\n",
      "Step 31/391, Loss: 0.7917\n",
      "Step 32/391, Loss: 0.4655\n",
      "Step 33/391, Loss: 0.7513\n",
      "Step 34/391, Loss: 0.5506\n",
      "Step 35/391, Loss: 0.5502\n",
      "Step 36/391, Loss: 0.7674\n",
      "Step 37/391, Loss: 0.5977\n",
      "Step 38/391, Loss: 0.6437\n",
      "Step 39/391, Loss: 0.6082\n",
      "Step 40/391, Loss: 0.4056\n",
      "Step 41/391, Loss: 0.6710\n",
      "Step 42/391, Loss: 0.5112\n",
      "Step 43/391, Loss: 0.4926\n",
      "Step 44/391, Loss: 0.5636\n",
      "Step 45/391, Loss: 0.3028\n",
      "Step 46/391, Loss: 0.5274\n",
      "Step 47/391, Loss: 0.5651\n",
      "Step 48/391, Loss: 0.5481\n",
      "Step 49/391, Loss: 0.3707\n",
      "Step 50/391, Loss: 0.4748\n",
      "Step 51/391, Loss: 0.4500\n",
      "Step 52/391, Loss: 0.3962\n",
      "Step 53/391, Loss: 0.4426\n",
      "Step 54/391, Loss: 0.2804\n",
      "Step 55/391, Loss: 0.4663\n",
      "Step 56/391, Loss: 0.3038\n",
      "Step 57/391, Loss: 0.4230\n",
      "Step 58/391, Loss: 0.2867\n",
      "Step 59/391, Loss: 0.3441\n",
      "Step 60/391, Loss: 0.4846\n",
      "Step 61/391, Loss: 0.4804\n",
      "Step 62/391, Loss: 0.3743\n",
      "Step 63/391, Loss: 0.3112\n",
      "Step 64/391, Loss: 0.3517\n",
      "Step 65/391, Loss: 0.4043\n",
      "Step 66/391, Loss: 0.4708\n",
      "Step 67/391, Loss: 0.2980\n",
      "Step 68/391, Loss: 0.3721\n",
      "Step 69/391, Loss: 0.4222\n",
      "Step 70/391, Loss: 0.2819\n",
      "Step 71/391, Loss: 0.2903\n",
      "Step 72/391, Loss: 0.4459\n",
      "Step 73/391, Loss: 0.4158\n",
      "Step 74/391, Loss: 0.2445\n",
      "Step 75/391, Loss: 0.2889\n",
      "Step 76/391, Loss: 0.3995\n",
      "Step 77/391, Loss: 0.3822\n",
      "Step 78/391, Loss: 0.3427\n",
      "Step 79/391, Loss: 0.4156\n",
      "Step 80/391, Loss: 0.2950\n",
      "Step 81/391, Loss: 0.3804\n",
      "Step 82/391, Loss: 0.3411\n",
      "Step 83/391, Loss: 0.2123\n",
      "Step 84/391, Loss: 0.4387\n",
      "Step 85/391, Loss: 0.3836\n",
      "Step 86/391, Loss: 0.4342\n",
      "Step 87/391, Loss: 0.2823\n",
      "Step 88/391, Loss: 0.4995\n",
      "Step 89/391, Loss: 0.3571\n",
      "Step 90/391, Loss: 0.4457\n",
      "Step 91/391, Loss: 0.3508\n",
      "Step 92/391, Loss: 0.3892\n",
      "Step 93/391, Loss: 0.2930\n",
      "Step 94/391, Loss: 0.4443\n",
      "Step 95/391, Loss: 0.4389\n",
      "Step 96/391, Loss: 0.3767\n",
      "Step 97/391, Loss: 0.3044\n",
      "Step 98/391, Loss: 0.4198\n",
      "Step 99/391, Loss: 0.4986\n",
      "Step 100/391, Loss: 0.3574\n",
      "Step 101/391, Loss: 0.3581\n",
      "Step 102/391, Loss: 0.3931\n",
      "Step 103/391, Loss: 0.3465\n",
      "Step 104/391, Loss: 0.3282\n",
      "Step 105/391, Loss: 0.2847\n",
      "Step 106/391, Loss: 0.2857\n",
      "Step 107/391, Loss: 0.5952\n",
      "Step 108/391, Loss: 0.3586\n",
      "Step 109/391, Loss: 0.3167\n",
      "Step 110/391, Loss: 0.4492\n",
      "Step 111/391, Loss: 0.3995\n",
      "Step 112/391, Loss: 0.3438\n",
      "Step 113/391, Loss: 0.3241\n",
      "Step 114/391, Loss: 0.3245\n",
      "Step 115/391, Loss: 0.4106\n",
      "Step 116/391, Loss: 0.3757\n",
      "Step 117/391, Loss: 0.3981\n",
      "Step 118/391, Loss: 0.3071\n",
      "Step 119/391, Loss: 0.3233\n",
      "Step 120/391, Loss: 0.5425\n",
      "Step 121/391, Loss: 0.3240\n",
      "Step 122/391, Loss: 0.3963\n",
      "Step 123/391, Loss: 0.3601\n",
      "Step 124/391, Loss: 0.3719\n",
      "Step 125/391, Loss: 0.2908\n",
      "Step 126/391, Loss: 0.2755\n",
      "Step 127/391, Loss: 0.2552\n",
      "Step 128/391, Loss: 0.3805\n",
      "Step 129/391, Loss: 0.3620\n",
      "Step 130/391, Loss: 0.4342\n",
      "Step 131/391, Loss: 0.3263\n",
      "Step 132/391, Loss: 0.2710\n",
      "Step 133/391, Loss: 0.2603\n",
      "Step 134/391, Loss: 0.3416\n",
      "Step 135/391, Loss: 0.2549\n",
      "Step 136/391, Loss: 0.2936\n",
      "Step 137/391, Loss: 0.2949\n",
      "Step 138/391, Loss: 0.2880\n",
      "Step 139/391, Loss: 0.3497\n",
      "Step 140/391, Loss: 0.3207\n",
      "Step 141/391, Loss: 0.2253\n",
      "Step 142/391, Loss: 0.2178\n",
      "Step 143/391, Loss: 0.2186\n",
      "Step 144/391, Loss: 0.3100\n",
      "Step 145/391, Loss: 0.2977\n",
      "Step 146/391, Loss: 0.2514\n",
      "Step 147/391, Loss: 0.2251\n",
      "Step 148/391, Loss: 0.2166\n",
      "Step 149/391, Loss: 0.3770\n",
      "Step 150/391, Loss: 0.2326\n",
      "Step 151/391, Loss: 0.2823\n",
      "Step 152/391, Loss: 0.2340\n",
      "Step 153/391, Loss: 0.2571\n",
      "Step 154/391, Loss: 0.2157\n",
      "Step 155/391, Loss: 0.2607\n",
      "Step 156/391, Loss: 0.2906\n",
      "Step 157/391, Loss: 0.3022\n",
      "Step 158/391, Loss: 0.2674\n",
      "Step 159/391, Loss: 0.3777\n",
      "Step 160/391, Loss: 0.1859\n",
      "Step 161/391, Loss: 0.4212\n",
      "Step 162/391, Loss: 0.3100\n",
      "Step 163/391, Loss: 0.4108\n",
      "Step 164/391, Loss: 0.3315\n",
      "Step 165/391, Loss: 0.3797\n",
      "Step 166/391, Loss: 0.1613\n",
      "Step 167/391, Loss: 0.2863\n",
      "Step 168/391, Loss: 0.3956\n",
      "Step 169/391, Loss: 0.2242\n",
      "Step 170/391, Loss: 0.3477\n",
      "Step 171/391, Loss: 0.2250\n",
      "Step 172/391, Loss: 0.3943\n",
      "Step 173/391, Loss: 0.2039\n",
      "Step 174/391, Loss: 0.4407\n",
      "Step 175/391, Loss: 0.2634\n",
      "Step 176/391, Loss: 0.2721\n",
      "Step 177/391, Loss: 0.2956\n",
      "Step 178/391, Loss: 0.3176\n",
      "Step 179/391, Loss: 0.3330\n",
      "Step 180/391, Loss: 0.2876\n",
      "Step 181/391, Loss: 0.1753\n",
      "Step 182/391, Loss: 0.2307\n",
      "Step 183/391, Loss: 0.4003\n",
      "Step 184/391, Loss: 0.1480\n",
      "Step 185/391, Loss: 0.1827\n",
      "Step 186/391, Loss: 0.3234\n",
      "Step 187/391, Loss: 0.2890\n",
      "Step 188/391, Loss: 0.3845\n",
      "Step 189/391, Loss: 0.2389\n",
      "Step 190/391, Loss: 0.2283\n",
      "Step 191/391, Loss: 0.2812\n",
      "Step 192/391, Loss: 0.2452\n",
      "Step 193/391, Loss: 0.1817\n",
      "Step 194/391, Loss: 0.1642\n",
      "Step 195/391, Loss: 0.2748\n",
      "Step 196/391, Loss: 0.3021\n",
      "Step 197/391, Loss: 0.3055\n",
      "Step 198/391, Loss: 0.3421\n",
      "Step 199/391, Loss: 0.2279\n",
      "Step 200/391, Loss: 0.2808\n",
      "Step 201/391, Loss: 0.2725\n",
      "Step 202/391, Loss: 0.2163\n",
      "Step 203/391, Loss: 0.2744\n",
      "Step 204/391, Loss: 0.3192\n",
      "Step 205/391, Loss: 0.3368\n",
      "Step 206/391, Loss: 0.1221\n",
      "Step 207/391, Loss: 0.2661\n",
      "Step 208/391, Loss: 0.3499\n",
      "Step 209/391, Loss: 0.3387\n",
      "Step 210/391, Loss: 0.2458\n",
      "Step 211/391, Loss: 0.1912\n",
      "Step 212/391, Loss: 0.2436\n",
      "Step 213/391, Loss: 0.2027\n",
      "Step 214/391, Loss: 0.4418\n",
      "Step 215/391, Loss: 0.2001\n",
      "Step 216/391, Loss: 0.2189\n",
      "Step 217/391, Loss: 0.1764\n",
      "Step 218/391, Loss: 0.2160\n",
      "Step 219/391, Loss: 0.1469\n",
      "Step 220/391, Loss: 0.1897\n",
      "Step 221/391, Loss: 0.1371\n",
      "Step 222/391, Loss: 0.2461\n",
      "Step 223/391, Loss: 0.1371\n",
      "Step 224/391, Loss: 0.1988\n",
      "Step 225/391, Loss: 0.2764\n",
      "Step 226/391, Loss: 0.2644\n",
      "Step 227/391, Loss: 0.2047\n",
      "Step 228/391, Loss: 0.1432\n",
      "Step 229/391, Loss: 0.3521\n",
      "Step 230/391, Loss: 0.1566\n",
      "Step 231/391, Loss: 0.2079\n",
      "Step 232/391, Loss: 0.2396\n",
      "Step 233/391, Loss: 0.1762\n",
      "Step 234/391, Loss: 0.1818\n",
      "Step 235/391, Loss: 0.3062\n",
      "Step 236/391, Loss: 0.2709\n",
      "Step 237/391, Loss: 0.3823\n",
      "Step 238/391, Loss: 0.2124\n",
      "Step 239/391, Loss: 0.1779\n",
      "Step 240/391, Loss: 0.1871\n",
      "Step 241/391, Loss: 0.2876\n",
      "Step 242/391, Loss: 0.1545\n",
      "Step 243/391, Loss: 0.1827\n",
      "Step 244/391, Loss: 0.1843\n",
      "Step 245/391, Loss: 0.4272\n",
      "Step 246/391, Loss: 0.3260\n",
      "Step 247/391, Loss: 0.2793\n",
      "Step 248/391, Loss: 0.3746\n",
      "Step 249/391, Loss: 0.1614\n",
      "Step 250/391, Loss: 0.2335\n",
      "Step 251/391, Loss: 0.2546\n",
      "Step 252/391, Loss: 0.3071\n",
      "Step 253/391, Loss: 0.2885\n",
      "Step 254/391, Loss: 0.3120\n",
      "Step 255/391, Loss: 0.0894\n",
      "Step 256/391, Loss: 0.3071\n",
      "Step 257/391, Loss: 0.1875\n",
      "Step 258/391, Loss: 0.3674\n",
      "Step 259/391, Loss: 0.2436\n",
      "Step 260/391, Loss: 0.2038\n",
      "Step 261/391, Loss: 0.2927\n",
      "Step 262/391, Loss: 0.1510\n",
      "Step 263/391, Loss: 0.2497\n",
      "Step 264/391, Loss: 0.2318\n",
      "Step 265/391, Loss: 0.2980\n",
      "Step 266/391, Loss: 0.1812\n",
      "Step 267/391, Loss: 0.2227\n",
      "Step 268/391, Loss: 0.3415\n",
      "Step 269/391, Loss: 0.4201\n",
      "Step 270/391, Loss: 0.4014\n",
      "Step 271/391, Loss: 0.2990\n",
      "Step 272/391, Loss: 0.1385\n",
      "Step 273/391, Loss: 0.1064\n",
      "Step 274/391, Loss: 0.2580\n",
      "Step 275/391, Loss: 0.2904\n",
      "Step 276/391, Loss: 0.2839\n",
      "Step 277/391, Loss: 0.1451\n",
      "Step 278/391, Loss: 0.2359\n",
      "Step 279/391, Loss: 0.1633\n",
      "Step 280/391, Loss: 0.2516\n",
      "Step 281/391, Loss: 0.2344\n",
      "Step 282/391, Loss: 0.1459\n",
      "Step 283/391, Loss: 0.3773\n",
      "Step 284/391, Loss: 0.3256\n",
      "Step 285/391, Loss: 0.1410\n",
      "Step 286/391, Loss: 0.1579\n",
      "Step 287/391, Loss: 0.2654\n",
      "Step 288/391, Loss: 0.1464\n",
      "Step 289/391, Loss: 0.3747\n",
      "Step 290/391, Loss: 0.2690\n",
      "Step 291/391, Loss: 0.2322\n",
      "Step 292/391, Loss: 0.2972\n",
      "Step 293/391, Loss: 0.1180\n",
      "Step 294/391, Loss: 0.1490\n",
      "Step 295/391, Loss: 0.1228\n",
      "Step 296/391, Loss: 0.2320\n",
      "Step 297/391, Loss: 0.3033\n",
      "Step 298/391, Loss: 0.2273\n",
      "Step 299/391, Loss: 0.1554\n",
      "Step 300/391, Loss: 0.1795\n",
      "Step 301/391, Loss: 0.2274\n",
      "Step 302/391, Loss: 0.2322\n",
      "Step 303/391, Loss: 0.1577\n",
      "Step 304/391, Loss: 0.2875\n",
      "Step 305/391, Loss: 0.2307\n",
      "Step 306/391, Loss: 0.1484\n",
      "Step 307/391, Loss: 0.3243\n",
      "Step 308/391, Loss: 0.1410\n",
      "Step 309/391, Loss: 0.2511\n",
      "Step 310/391, Loss: 0.3198\n",
      "Step 311/391, Loss: 0.3191\n",
      "Step 312/391, Loss: 0.2177\n",
      "Step 313/391, Loss: 0.3572\n",
      "Step 314/391, Loss: 0.2264\n",
      "Step 315/391, Loss: 0.3106\n",
      "Step 316/391, Loss: 0.2961\n",
      "Step 317/391, Loss: 0.1839\n",
      "Step 318/391, Loss: 0.1273\n",
      "Step 319/391, Loss: 0.2914\n",
      "Step 320/391, Loss: 0.2520\n",
      "Step 321/391, Loss: 0.2976\n",
      "Step 322/391, Loss: 0.1132\n",
      "Step 323/391, Loss: 0.3054\n",
      "Step 324/391, Loss: 0.2119\n",
      "Step 325/391, Loss: 0.3195\n",
      "Step 326/391, Loss: 0.3336\n",
      "Step 327/391, Loss: 0.3051\n",
      "Step 328/391, Loss: 0.1162\n",
      "Step 329/391, Loss: 0.2436\n",
      "Step 330/391, Loss: 0.1536\n",
      "Step 331/391, Loss: 0.2331\n",
      "Step 332/391, Loss: 0.2736\n",
      "Step 333/391, Loss: 0.1496\n",
      "Step 334/391, Loss: 0.2083\n",
      "Step 335/391, Loss: 0.1579\n",
      "Step 336/391, Loss: 0.2544\n",
      "Step 337/391, Loss: 0.2133\n",
      "Step 338/391, Loss: 0.1050\n",
      "Step 339/391, Loss: 0.1749\n",
      "Step 340/391, Loss: 0.1825\n",
      "Step 341/391, Loss: 0.2646\n",
      "Step 342/391, Loss: 0.1771\n",
      "Step 343/391, Loss: 0.2759\n",
      "Step 344/391, Loss: 0.1366\n",
      "Step 345/391, Loss: 0.2109\n",
      "Step 346/391, Loss: 0.1848\n",
      "Step 347/391, Loss: 0.1680\n",
      "Step 348/391, Loss: 0.2328\n",
      "Step 349/391, Loss: 0.1255\n",
      "Step 350/391, Loss: 0.1700\n",
      "Step 351/391, Loss: 0.3521\n",
      "Step 352/391, Loss: 0.1229\n",
      "Step 353/391, Loss: 0.4202\n",
      "Step 354/391, Loss: 0.2756\n",
      "Step 355/391, Loss: 0.1580\n",
      "Step 356/391, Loss: 0.1712\n",
      "Step 357/391, Loss: 0.2622\n",
      "Step 358/391, Loss: 0.3080\n",
      "Step 359/391, Loss: 0.2809\n",
      "Step 360/391, Loss: 0.1865\n",
      "Step 361/391, Loss: 0.2083\n",
      "Step 362/391, Loss: 0.1659\n",
      "Step 363/391, Loss: 0.1081\n",
      "Step 364/391, Loss: 0.1710\n",
      "Step 365/391, Loss: 0.1696\n",
      "Step 366/391, Loss: 0.3272\n",
      "Step 367/391, Loss: 0.1424\n",
      "Step 368/391, Loss: 0.1815\n",
      "Step 369/391, Loss: 0.1675\n",
      "Step 370/391, Loss: 0.2868\n",
      "Step 371/391, Loss: 0.2341\n",
      "Step 372/391, Loss: 0.2639\n",
      "Step 373/391, Loss: 0.2782\n",
      "Step 374/391, Loss: 0.1734\n",
      "Step 375/391, Loss: 0.2121\n",
      "Step 376/391, Loss: 0.2432\n",
      "Step 377/391, Loss: 0.3330\n",
      "Step 378/391, Loss: 0.2689\n",
      "Step 379/391, Loss: 0.2140\n",
      "Step 380/391, Loss: 0.1764\n",
      "Step 381/391, Loss: 0.4178\n",
      "Step 382/391, Loss: 0.2873\n",
      "Step 383/391, Loss: 0.3001\n",
      "Step 384/391, Loss: 0.1666\n",
      "Step 385/391, Loss: 0.2143\n",
      "Step 386/391, Loss: 0.2741\n",
      "Step 387/391, Loss: 0.2587\n",
      "Step 388/391, Loss: 0.1980\n",
      "Step 389/391, Loss: 0.0915\n",
      "Step 390/391, Loss: 0.2729\n",
      "Step 391/391, Loss: 0.4547\n",
      "Epoch 1/25, Average Train Loss: 0.3489\n",
      "Epoch 1/25, Average Validation Loss: 0.1929\n",
      "Model saved at epoch 1 with validation loss: 0.1929\n",
      "Step 1/391, Loss: 0.2171\n",
      "Step 2/391, Loss: 0.1811\n",
      "Step 3/391, Loss: 0.3360\n",
      "Step 4/391, Loss: 0.2137\n",
      "Step 5/391, Loss: 0.1739\n",
      "Step 6/391, Loss: 0.2597\n",
      "Step 7/391, Loss: 0.2068\n",
      "Step 8/391, Loss: 0.1764\n",
      "Step 9/391, Loss: 0.3278\n",
      "Step 10/391, Loss: 0.1467\n",
      "Step 11/391, Loss: 0.1724\n",
      "Step 12/391, Loss: 0.1738\n",
      "Step 13/391, Loss: 0.2148\n",
      "Step 14/391, Loss: 0.0861\n",
      "Step 15/391, Loss: 0.2239\n",
      "Step 16/391, Loss: 0.2700\n",
      "Step 17/391, Loss: 0.2241\n",
      "Step 18/391, Loss: 0.2517\n",
      "Step 19/391, Loss: 0.1613\n",
      "Step 20/391, Loss: 0.1684\n",
      "Step 21/391, Loss: 0.1665\n",
      "Step 22/391, Loss: 0.2278\n",
      "Step 23/391, Loss: 0.1432\n",
      "Step 24/391, Loss: 0.1295\n",
      "Step 25/391, Loss: 0.1078\n",
      "Step 26/391, Loss: 0.3352\n",
      "Step 27/391, Loss: 0.1291\n",
      "Step 28/391, Loss: 0.2292\n",
      "Step 29/391, Loss: 0.1735\n",
      "Step 30/391, Loss: 0.1585\n",
      "Step 31/391, Loss: 0.2601\n",
      "Step 32/391, Loss: 0.1374\n",
      "Step 33/391, Loss: 0.1645\n",
      "Step 34/391, Loss: 0.1451\n",
      "Step 35/391, Loss: 0.3318\n",
      "Step 36/391, Loss: 0.2167\n",
      "Step 37/391, Loss: 0.1512\n",
      "Step 38/391, Loss: 0.0582\n",
      "Step 39/391, Loss: 0.1450\n",
      "Step 40/391, Loss: 0.2417\n",
      "Step 41/391, Loss: 0.1381\n",
      "Step 42/391, Loss: 0.1322\n",
      "Step 43/391, Loss: 0.1748\n",
      "Step 44/391, Loss: 0.2181\n",
      "Step 45/391, Loss: 0.1360\n",
      "Step 46/391, Loss: 0.1706\n",
      "Step 47/391, Loss: 0.1896\n",
      "Step 48/391, Loss: 0.1491\n",
      "Step 49/391, Loss: 0.1806\n",
      "Step 50/391, Loss: 0.1800\n",
      "Step 51/391, Loss: 0.0938\n",
      "Step 52/391, Loss: 0.1680\n",
      "Step 53/391, Loss: 0.2255\n",
      "Step 54/391, Loss: 0.1148\n",
      "Step 55/391, Loss: 0.1156\n",
      "Step 56/391, Loss: 0.1807\n",
      "Step 57/391, Loss: 0.1247\n",
      "Step 58/391, Loss: 0.2445\n",
      "Step 59/391, Loss: 0.2547\n",
      "Step 60/391, Loss: 0.2490\n",
      "Step 61/391, Loss: 0.2158\n",
      "Step 62/391, Loss: 0.1788\n",
      "Step 63/391, Loss: 0.1433\n",
      "Step 64/391, Loss: 0.2042\n",
      "Step 65/391, Loss: 0.2934\n",
      "Step 66/391, Loss: 0.0468\n",
      "Step 67/391, Loss: 0.0799\n",
      "Step 68/391, Loss: 0.2101\n",
      "Step 69/391, Loss: 0.1438\n",
      "Step 70/391, Loss: 0.1222\n",
      "Step 71/391, Loss: 0.1677\n",
      "Step 72/391, Loss: 0.1197\n",
      "Step 73/391, Loss: 0.0943\n",
      "Step 74/391, Loss: 0.2095\n",
      "Step 75/391, Loss: 0.1550\n",
      "Step 76/391, Loss: 0.1442\n",
      "Step 77/391, Loss: 0.1743\n",
      "Step 78/391, Loss: 0.2118\n",
      "Step 79/391, Loss: 0.1928\n",
      "Step 80/391, Loss: 0.2513\n",
      "Step 81/391, Loss: 0.1439\n",
      "Step 82/391, Loss: 0.1424\n",
      "Step 83/391, Loss: 0.3400\n",
      "Step 84/391, Loss: 0.1093\n",
      "Step 85/391, Loss: 0.1314\n",
      "Step 86/391, Loss: 0.2048\n",
      "Step 87/391, Loss: 0.1229\n",
      "Step 88/391, Loss: 0.1705\n",
      "Step 89/391, Loss: 0.1750\n",
      "Step 90/391, Loss: 0.1875\n",
      "Step 91/391, Loss: 0.2079\n",
      "Step 92/391, Loss: 0.1354\n",
      "Step 93/391, Loss: 0.2090\n",
      "Step 94/391, Loss: 0.1823\n",
      "Step 95/391, Loss: 0.1092\n",
      "Step 96/391, Loss: 0.1178\n",
      "Step 97/391, Loss: 0.1498\n",
      "Step 98/391, Loss: 0.1411\n",
      "Step 99/391, Loss: 0.1967\n",
      "Step 100/391, Loss: 0.2198\n",
      "Step 101/391, Loss: 0.2418\n",
      "Step 102/391, Loss: 0.1008\n",
      "Step 103/391, Loss: 0.1397\n",
      "Step 104/391, Loss: 0.1494\n",
      "Step 105/391, Loss: 0.1599\n",
      "Step 106/391, Loss: 0.1165\n",
      "Step 107/391, Loss: 0.0935\n",
      "Step 108/391, Loss: 0.2502\n",
      "Step 109/391, Loss: 0.1171\n",
      "Step 110/391, Loss: 0.2744\n",
      "Step 111/391, Loss: 0.1576\n",
      "Step 112/391, Loss: 0.1586\n",
      "Step 113/391, Loss: 0.1433\n",
      "Step 114/391, Loss: 0.2457\n",
      "Step 115/391, Loss: 0.1441\n",
      "Step 116/391, Loss: 0.1093\n",
      "Step 117/391, Loss: 0.2117\n",
      "Step 118/391, Loss: 0.2458\n",
      "Step 119/391, Loss: 0.2234\n",
      "Step 120/391, Loss: 0.2288\n",
      "Step 121/391, Loss: 0.2175\n",
      "Step 122/391, Loss: 0.3206\n",
      "Step 123/391, Loss: 0.1346\n",
      "Step 124/391, Loss: 0.1326\n",
      "Step 125/391, Loss: 0.1157\n",
      "Step 126/391, Loss: 0.1921\n",
      "Step 127/391, Loss: 0.2104\n",
      "Step 128/391, Loss: 0.1307\n",
      "Step 129/391, Loss: 0.1868\n",
      "Step 130/391, Loss: 0.1410\n",
      "Step 131/391, Loss: 0.1887\n",
      "Step 132/391, Loss: 0.2228\n",
      "Step 133/391, Loss: 0.1924\n",
      "Step 134/391, Loss: 0.1231\n",
      "Step 135/391, Loss: 0.1316\n",
      "Step 136/391, Loss: 0.1071\n",
      "Step 137/391, Loss: 0.1290\n",
      "Step 138/391, Loss: 0.2097\n",
      "Step 139/391, Loss: 0.3380\n",
      "Step 140/391, Loss: 0.2222\n",
      "Step 141/391, Loss: 0.2857\n",
      "Step 142/391, Loss: 0.2070\n",
      "Step 143/391, Loss: 0.2292\n",
      "Step 144/391, Loss: 0.2502\n",
      "Step 145/391, Loss: 0.2818\n",
      "Step 146/391, Loss: 0.1576\n",
      "Step 147/391, Loss: 0.0993\n",
      "Step 148/391, Loss: 0.1353\n",
      "Step 149/391, Loss: 0.2026\n",
      "Step 150/391, Loss: 0.1294\n",
      "Step 151/391, Loss: 0.0998\n",
      "Step 152/391, Loss: 0.1773\n",
      "Step 153/391, Loss: 0.1355\n",
      "Step 154/391, Loss: 0.1641\n",
      "Step 155/391, Loss: 0.1516\n",
      "Step 156/391, Loss: 0.2295\n",
      "Step 157/391, Loss: 0.1289\n",
      "Step 158/391, Loss: 0.2216\n",
      "Step 159/391, Loss: 0.1406\n",
      "Step 160/391, Loss: 0.1541\n",
      "Step 161/391, Loss: 0.1819\n",
      "Step 162/391, Loss: 0.2145\n",
      "Step 163/391, Loss: 0.1877\n",
      "Step 164/391, Loss: 0.1507\n",
      "Step 165/391, Loss: 0.2536\n",
      "Step 166/391, Loss: 0.3317\n",
      "Step 167/391, Loss: 0.2255\n",
      "Step 168/391, Loss: 0.2253\n",
      "Step 169/391, Loss: 0.2040\n",
      "Step 170/391, Loss: 0.1155\n",
      "Step 171/391, Loss: 0.2908\n",
      "Step 172/391, Loss: 0.2416\n",
      "Step 173/391, Loss: 0.2484\n",
      "Step 174/391, Loss: 0.1730\n",
      "Step 175/391, Loss: 0.1597\n",
      "Step 176/391, Loss: 0.1139\n",
      "Step 177/391, Loss: 0.0747\n",
      "Step 178/391, Loss: 0.2916\n",
      "Step 179/391, Loss: 0.0984\n",
      "Step 180/391, Loss: 0.1718\n",
      "Step 181/391, Loss: 0.0971\n",
      "Step 182/391, Loss: 0.1017\n",
      "Step 183/391, Loss: 0.2395\n",
      "Step 184/391, Loss: 0.2252\n",
      "Step 185/391, Loss: 0.1282\n",
      "Step 186/391, Loss: 0.0940\n",
      "Step 187/391, Loss: 0.2228\n",
      "Step 188/391, Loss: 0.1851\n",
      "Step 189/391, Loss: 0.1298\n",
      "Step 190/391, Loss: 0.2547\n",
      "Step 191/391, Loss: 0.1038\n",
      "Step 192/391, Loss: 0.1628\n",
      "Step 193/391, Loss: 0.2174\n",
      "Step 194/391, Loss: 0.2866\n",
      "Step 195/391, Loss: 0.1709\n",
      "Step 196/391, Loss: 0.2985\n",
      "Step 197/391, Loss: 0.1765\n",
      "Step 198/391, Loss: 0.0725\n",
      "Step 199/391, Loss: 0.2261\n",
      "Step 200/391, Loss: 0.0892\n",
      "Step 201/391, Loss: 0.1993\n",
      "Step 202/391, Loss: 0.1199\n",
      "Step 203/391, Loss: 0.1637\n",
      "Step 204/391, Loss: 0.3561\n",
      "Step 205/391, Loss: 0.1974\n",
      "Step 206/391, Loss: 0.2028\n",
      "Step 207/391, Loss: 0.2180\n",
      "Step 208/391, Loss: 0.2325\n",
      "Step 209/391, Loss: 0.1791\n",
      "Step 210/391, Loss: 0.1158\n",
      "Step 211/391, Loss: 0.2256\n",
      "Step 212/391, Loss: 0.1245\n",
      "Step 213/391, Loss: 0.1012\n",
      "Step 214/391, Loss: 0.1271\n",
      "Step 215/391, Loss: 0.2023\n",
      "Step 216/391, Loss: 0.1423\n",
      "Step 217/391, Loss: 0.2734\n",
      "Step 218/391, Loss: 0.1829\n",
      "Step 219/391, Loss: 0.1526\n",
      "Step 220/391, Loss: 0.3475\n",
      "Step 221/391, Loss: 0.4528\n",
      "Step 222/391, Loss: 0.1858\n",
      "Step 223/391, Loss: 0.1056\n",
      "Step 224/391, Loss: 0.2651\n",
      "Step 225/391, Loss: 0.1012\n",
      "Step 226/391, Loss: 0.2153\n",
      "Step 227/391, Loss: 0.0921\n",
      "Step 228/391, Loss: 0.1280\n",
      "Step 229/391, Loss: 0.1234\n",
      "Step 230/391, Loss: 0.1262\n",
      "Step 231/391, Loss: 0.0837\n",
      "Step 232/391, Loss: 0.2173\n",
      "Step 233/391, Loss: 0.0697\n",
      "Step 234/391, Loss: 0.0730\n",
      "Step 235/391, Loss: 0.1244\n",
      "Step 236/391, Loss: 0.2008\n",
      "Step 237/391, Loss: 0.1943\n",
      "Step 238/391, Loss: 0.1604\n",
      "Step 239/391, Loss: 0.1312\n",
      "Step 240/391, Loss: 0.3288\n",
      "Step 241/391, Loss: 0.1209\n",
      "Step 242/391, Loss: 0.1756\n",
      "Step 243/391, Loss: 0.3009\n",
      "Step 244/391, Loss: 0.2010\n",
      "Step 245/391, Loss: 0.1872\n",
      "Step 246/391, Loss: 0.1258\n",
      "Step 247/391, Loss: 0.4092\n",
      "Step 248/391, Loss: 0.1129\n",
      "Step 249/391, Loss: 0.0498\n",
      "Step 250/391, Loss: 0.2358\n",
      "Step 251/391, Loss: 0.1566\n",
      "Step 252/391, Loss: 0.1372\n",
      "Step 253/391, Loss: 0.2468\n",
      "Step 254/391, Loss: 0.1489\n",
      "Step 255/391, Loss: 0.0739\n",
      "Step 256/391, Loss: 0.1913\n",
      "Step 257/391, Loss: 0.0993\n",
      "Step 258/391, Loss: 0.1611\n",
      "Step 259/391, Loss: 0.1801\n",
      "Step 260/391, Loss: 0.1085\n",
      "Step 261/391, Loss: 0.0886\n",
      "Step 262/391, Loss: 0.1945\n",
      "Step 263/391, Loss: 0.2658\n",
      "Step 264/391, Loss: 0.1056\n",
      "Step 265/391, Loss: 0.1368\n",
      "Step 266/391, Loss: 0.0914\n",
      "Step 267/391, Loss: 0.1829\n",
      "Step 268/391, Loss: 0.2093\n",
      "Step 269/391, Loss: 0.2291\n",
      "Step 270/391, Loss: 0.1373\n",
      "Step 271/391, Loss: 0.1363\n",
      "Step 272/391, Loss: 0.1469\n",
      "Step 273/391, Loss: 0.1234\n",
      "Step 274/391, Loss: 0.0872\n",
      "Step 275/391, Loss: 0.1171\n",
      "Step 276/391, Loss: 0.1927\n",
      "Step 277/391, Loss: 0.1930\n",
      "Step 278/391, Loss: 0.1524\n",
      "Step 279/391, Loss: 0.2924\n",
      "Step 280/391, Loss: 0.1915\n",
      "Step 281/391, Loss: 0.1675\n",
      "Step 282/391, Loss: 0.1653\n",
      "Step 283/391, Loss: 0.2917\n",
      "Step 284/391, Loss: 0.2231\n",
      "Step 285/391, Loss: 0.1207\n",
      "Step 286/391, Loss: 0.2611\n",
      "Step 287/391, Loss: 0.1975\n",
      "Step 288/391, Loss: 0.1577\n",
      "Step 289/391, Loss: 0.1465\n",
      "Step 290/391, Loss: 0.1890\n",
      "Step 291/391, Loss: 0.1551\n",
      "Step 292/391, Loss: 0.2754\n",
      "Step 293/391, Loss: 0.2225\n",
      "Step 294/391, Loss: 0.1148\n",
      "Step 295/391, Loss: 0.1380\n",
      "Step 296/391, Loss: 0.4006\n",
      "Step 297/391, Loss: 0.2202\n",
      "Step 298/391, Loss: 0.2896\n",
      "Step 299/391, Loss: 0.1018\n",
      "Step 300/391, Loss: 0.1377\n",
      "Step 301/391, Loss: 0.2485\n",
      "Step 302/391, Loss: 0.1061\n",
      "Step 303/391, Loss: 0.1067\n",
      "Step 304/391, Loss: 0.1546\n",
      "Step 305/391, Loss: 0.1786\n",
      "Step 306/391, Loss: 0.1903\n",
      "Step 307/391, Loss: 0.2405\n",
      "Step 308/391, Loss: 0.1868\n",
      "Step 309/391, Loss: 0.2450\n",
      "Step 310/391, Loss: 0.2267\n",
      "Step 311/391, Loss: 0.2525\n",
      "Step 312/391, Loss: 0.1543\n",
      "Step 313/391, Loss: 0.1184\n",
      "Step 314/391, Loss: 0.1952\n",
      "Step 315/391, Loss: 0.0893\n",
      "Step 316/391, Loss: 0.1342\n",
      "Step 317/391, Loss: 0.1825\n",
      "Step 318/391, Loss: 0.1886\n",
      "Step 319/391, Loss: 0.1946\n",
      "Step 320/391, Loss: 0.1796\n",
      "Step 321/391, Loss: 0.1519\n",
      "Step 322/391, Loss: 0.2042\n",
      "Step 323/391, Loss: 0.2242\n",
      "Step 324/391, Loss: 0.1661\n",
      "Step 325/391, Loss: 0.1715\n",
      "Step 326/391, Loss: 0.1667\n",
      "Step 327/391, Loss: 0.0883\n",
      "Step 328/391, Loss: 0.1560\n",
      "Step 329/391, Loss: 0.1505\n",
      "Step 330/391, Loss: 0.2442\n",
      "Step 331/391, Loss: 0.0872\n",
      "Step 332/391, Loss: 0.1324\n",
      "Step 333/391, Loss: 0.1289\n",
      "Step 334/391, Loss: 0.1228\n",
      "Step 335/391, Loss: 0.1133\n",
      "Step 336/391, Loss: 0.1604\n",
      "Step 337/391, Loss: 0.1720\n",
      "Step 338/391, Loss: 0.1575\n",
      "Step 339/391, Loss: 0.1755\n",
      "Step 340/391, Loss: 0.1466\n",
      "Step 341/391, Loss: 0.0904\n",
      "Step 342/391, Loss: 0.1603\n",
      "Step 343/391, Loss: 0.1144\n",
      "Step 344/391, Loss: 0.1898\n",
      "Step 345/391, Loss: 0.1245\n",
      "Step 346/391, Loss: 0.1459\n",
      "Step 347/391, Loss: 0.1558\n",
      "Step 348/391, Loss: 0.1135\n",
      "Step 349/391, Loss: 0.0473\n",
      "Step 350/391, Loss: 0.2253\n",
      "Step 351/391, Loss: 0.2343\n",
      "Step 352/391, Loss: 0.0432\n",
      "Step 353/391, Loss: 0.1965\n",
      "Step 354/391, Loss: 0.0420\n",
      "Step 355/391, Loss: 0.1272\n",
      "Step 356/391, Loss: 0.1398\n",
      "Step 357/391, Loss: 0.1380\n",
      "Step 358/391, Loss: 0.1734\n",
      "Step 359/391, Loss: 0.1349\n",
      "Step 360/391, Loss: 0.1393\n",
      "Step 361/391, Loss: 0.1032\n",
      "Step 362/391, Loss: 0.1661\n",
      "Step 363/391, Loss: 0.2426\n",
      "Step 364/391, Loss: 0.0698\n",
      "Step 365/391, Loss: 0.1487\n",
      "Step 366/391, Loss: 0.1368\n",
      "Step 367/391, Loss: 0.1796\n",
      "Step 368/391, Loss: 0.1105\n",
      "Step 369/391, Loss: 0.1698\n",
      "Step 370/391, Loss: 0.2918\n",
      "Step 371/391, Loss: 0.1127\n",
      "Step 372/391, Loss: 0.1168\n",
      "Step 373/391, Loss: 0.0850\n",
      "Step 374/391, Loss: 0.2126\n",
      "Step 375/391, Loss: 0.1966\n",
      "Step 376/391, Loss: 0.2191\n",
      "Step 377/391, Loss: 0.3958\n",
      "Step 378/391, Loss: 0.1006\n",
      "Step 379/391, Loss: 0.1774\n",
      "Step 380/391, Loss: 0.2181\n",
      "Step 381/391, Loss: 0.2714\n",
      "Step 382/391, Loss: 0.1089\n",
      "Step 383/391, Loss: 0.1427\n",
      "Step 384/391, Loss: 0.1530\n",
      "Step 385/391, Loss: 0.0573\n",
      "Step 386/391, Loss: 0.1655\n",
      "Step 387/391, Loss: 0.2062\n",
      "Step 388/391, Loss: 0.3237\n",
      "Step 389/391, Loss: 0.0968\n",
      "Step 390/391, Loss: 0.2588\n",
      "Step 391/391, Loss: 0.2180\n",
      "Epoch 2/25, Average Train Loss: 0.1765\n",
      "Epoch 2/25, Average Validation Loss: 0.1290\n",
      "Model saved at epoch 2 with validation loss: 0.1290\n",
      "Step 1/391, Loss: 0.0752\n",
      "Step 2/391, Loss: 0.1253\n",
      "Step 3/391, Loss: 0.1749\n",
      "Step 4/391, Loss: 0.1746\n",
      "Step 5/391, Loss: 0.0815\n",
      "Step 6/391, Loss: 0.1222\n",
      "Step 7/391, Loss: 0.2075\n",
      "Step 8/391, Loss: 0.0906\n",
      "Step 9/391, Loss: 0.1574\n",
      "Step 10/391, Loss: 0.2122\n",
      "Step 11/391, Loss: 0.1601\n",
      "Step 12/391, Loss: 0.1178\n",
      "Step 13/391, Loss: 0.1667\n",
      "Step 14/391, Loss: 0.1080\n",
      "Step 15/391, Loss: 0.2301\n",
      "Step 16/391, Loss: 0.1789\n",
      "Step 17/391, Loss: 0.0831\n",
      "Step 18/391, Loss: 0.0894\n",
      "Step 19/391, Loss: 0.2750\n",
      "Step 20/391, Loss: 0.2008\n",
      "Step 21/391, Loss: 0.2072\n",
      "Step 22/391, Loss: 0.1467\n",
      "Step 23/391, Loss: 0.1402\n",
      "Step 24/391, Loss: 0.0727\n",
      "Step 25/391, Loss: 0.0747\n",
      "Step 26/391, Loss: 0.0905\n",
      "Step 27/391, Loss: 0.1277\n",
      "Step 28/391, Loss: 0.0822\n",
      "Step 29/391, Loss: 0.0538\n",
      "Step 30/391, Loss: 0.1511\n",
      "Step 31/391, Loss: 0.1584\n",
      "Step 32/391, Loss: 0.1241\n",
      "Step 33/391, Loss: 0.1528\n",
      "Step 34/391, Loss: 0.1084\n",
      "Step 35/391, Loss: 0.1479\n",
      "Step 36/391, Loss: 0.1397\n",
      "Step 37/391, Loss: 0.1115\n",
      "Step 38/391, Loss: 0.2013\n",
      "Step 39/391, Loss: 0.0967\n",
      "Step 40/391, Loss: 0.1545\n",
      "Step 41/391, Loss: 0.1141\n",
      "Step 42/391, Loss: 0.3675\n",
      "Step 43/391, Loss: 0.1241\n",
      "Step 44/391, Loss: 0.2075\n",
      "Step 45/391, Loss: 0.1661\n",
      "Step 46/391, Loss: 0.2743\n",
      "Step 47/391, Loss: 0.2131\n",
      "Step 48/391, Loss: 0.1330\n",
      "Step 49/391, Loss: 0.1116\n",
      "Step 50/391, Loss: 0.2732\n",
      "Step 51/391, Loss: 0.1874\n",
      "Step 52/391, Loss: 0.1488\n",
      "Step 53/391, Loss: 0.2297\n",
      "Step 54/391, Loss: 0.2302\n",
      "Step 55/391, Loss: 0.1079\n",
      "Step 56/391, Loss: 0.1955\n",
      "Step 57/391, Loss: 0.1528\n",
      "Step 58/391, Loss: 0.1718\n",
      "Step 59/391, Loss: 0.0799\n",
      "Step 60/391, Loss: 0.1458\n",
      "Step 61/391, Loss: 0.1153\n",
      "Step 62/391, Loss: 0.1719\n",
      "Step 63/391, Loss: 0.1660\n",
      "Step 64/391, Loss: 0.2094\n",
      "Step 65/391, Loss: 0.0951\n",
      "Step 66/391, Loss: 0.1498\n",
      "Step 67/391, Loss: 0.2332\n",
      "Step 68/391, Loss: 0.2286\n",
      "Step 69/391, Loss: 0.1567\n",
      "Step 70/391, Loss: 0.1085\n",
      "Step 71/391, Loss: 0.2139\n",
      "Step 72/391, Loss: 0.1327\n",
      "Step 73/391, Loss: 0.1192\n",
      "Step 74/391, Loss: 0.1249\n",
      "Step 75/391, Loss: 0.1430\n",
      "Step 76/391, Loss: 0.1049\n",
      "Step 77/391, Loss: 0.0852\n",
      "Step 78/391, Loss: 0.1749\n",
      "Step 79/391, Loss: 0.2367\n",
      "Step 80/391, Loss: 0.1192\n",
      "Step 81/391, Loss: 0.2565\n",
      "Step 82/391, Loss: 0.1685\n",
      "Step 83/391, Loss: 0.1516\n",
      "Step 84/391, Loss: 0.0989\n",
      "Step 85/391, Loss: 0.1181\n",
      "Step 86/391, Loss: 0.1317\n",
      "Step 87/391, Loss: 0.1634\n",
      "Step 88/391, Loss: 0.1634\n",
      "Step 89/391, Loss: 0.1477\n",
      "Step 90/391, Loss: 0.1448\n",
      "Step 91/391, Loss: 0.1133\n",
      "Step 92/391, Loss: 0.1081\n",
      "Step 93/391, Loss: 0.0944\n",
      "Step 94/391, Loss: 0.1092\n",
      "Step 95/391, Loss: 0.1315\n",
      "Step 96/391, Loss: 0.1470\n",
      "Step 97/391, Loss: 0.1645\n",
      "Step 98/391, Loss: 0.2053\n",
      "Step 99/391, Loss: 0.1003\n",
      "Step 100/391, Loss: 0.1317\n",
      "Step 101/391, Loss: 0.1743\n",
      "Step 102/391, Loss: 0.1155\n",
      "Step 103/391, Loss: 0.1154\n",
      "Step 104/391, Loss: 0.1058\n",
      "Step 105/391, Loss: 0.1451\n",
      "Step 106/391, Loss: 0.1328\n",
      "Step 107/391, Loss: 0.0621\n",
      "Step 108/391, Loss: 0.2639\n",
      "Step 109/391, Loss: 0.2257\n",
      "Step 110/391, Loss: 0.0782\n",
      "Step 111/391, Loss: 0.2184\n",
      "Step 112/391, Loss: 0.2264\n",
      "Step 113/391, Loss: 0.1839\n",
      "Step 114/391, Loss: 0.3034\n",
      "Step 115/391, Loss: 0.1936\n",
      "Step 116/391, Loss: 0.2040\n",
      "Step 117/391, Loss: 0.1592\n",
      "Step 118/391, Loss: 0.0966\n",
      "Step 119/391, Loss: 0.0745\n",
      "Step 120/391, Loss: 0.1742\n",
      "Step 121/391, Loss: 0.1652\n",
      "Step 122/391, Loss: 0.2025\n",
      "Step 123/391, Loss: 0.2599\n",
      "Step 124/391, Loss: 0.2213\n",
      "Step 125/391, Loss: 0.1425\n",
      "Step 126/391, Loss: 0.1392\n",
      "Step 127/391, Loss: 0.4155\n",
      "Step 128/391, Loss: 0.1948\n",
      "Step 129/391, Loss: 0.1639\n",
      "Step 130/391, Loss: 0.1431\n",
      "Step 131/391, Loss: 0.1444\n",
      "Step 132/391, Loss: 0.0671\n",
      "Step 133/391, Loss: 0.1567\n",
      "Step 134/391, Loss: 0.3163\n",
      "Step 135/391, Loss: 0.2362\n",
      "Step 136/391, Loss: 0.0662\n",
      "Step 137/391, Loss: 0.1604\n",
      "Step 138/391, Loss: 0.2857\n",
      "Step 139/391, Loss: 0.2582\n",
      "Step 140/391, Loss: 0.1516\n",
      "Step 141/391, Loss: 0.1858\n",
      "Step 142/391, Loss: 0.3177\n",
      "Step 143/391, Loss: 0.1934\n",
      "Step 144/391, Loss: 0.1034\n",
      "Step 145/391, Loss: 0.1606\n",
      "Step 146/391, Loss: 0.0832\n",
      "Step 147/391, Loss: 0.1329\n",
      "Step 148/391, Loss: 0.1298\n",
      "Step 149/391, Loss: 0.1062\n",
      "Step 150/391, Loss: 0.1612\n",
      "Step 151/391, Loss: 0.0863\n",
      "Step 152/391, Loss: 0.1568\n",
      "Step 153/391, Loss: 0.1433\n",
      "Step 154/391, Loss: 0.2377\n",
      "Step 155/391, Loss: 0.1693\n",
      "Step 156/391, Loss: 0.2197\n",
      "Step 157/391, Loss: 0.1030\n",
      "Step 158/391, Loss: 0.0714\n",
      "Step 159/391, Loss: 0.1290\n",
      "Step 160/391, Loss: 0.1546\n",
      "Step 161/391, Loss: 0.0914\n",
      "Step 162/391, Loss: 0.1309\n",
      "Step 163/391, Loss: 0.1310\n",
      "Step 164/391, Loss: 0.0676\n",
      "Step 165/391, Loss: 0.0549\n",
      "Step 166/391, Loss: 0.1412\n",
      "Step 167/391, Loss: 0.1260\n",
      "Step 168/391, Loss: 0.1553\n",
      "Step 169/391, Loss: 0.1496\n",
      "Step 170/391, Loss: 0.0877\n",
      "Step 171/391, Loss: 0.1334\n",
      "Step 172/391, Loss: 0.1255\n",
      "Step 173/391, Loss: 0.1264\n",
      "Step 174/391, Loss: 0.2650\n",
      "Step 175/391, Loss: 0.2008\n",
      "Step 176/391, Loss: 0.2286\n",
      "Step 177/391, Loss: 0.2251\n",
      "Step 178/391, Loss: 0.2779\n",
      "Step 179/391, Loss: 0.1175\n",
      "Step 180/391, Loss: 0.1866\n",
      "Step 181/391, Loss: 0.1548\n",
      "Step 182/391, Loss: 0.0199\n",
      "Step 183/391, Loss: 0.1179\n",
      "Step 184/391, Loss: 0.1979\n",
      "Step 185/391, Loss: 0.0669\n",
      "Step 186/391, Loss: 0.0997\n",
      "Step 187/391, Loss: 0.1955\n",
      "Step 188/391, Loss: 0.1888\n",
      "Step 189/391, Loss: 0.1182\n",
      "Step 190/391, Loss: 0.0960\n",
      "Step 191/391, Loss: 0.1961\n",
      "Step 192/391, Loss: 0.1033\n",
      "Step 193/391, Loss: 0.1241\n",
      "Step 194/391, Loss: 0.2606\n",
      "Step 195/391, Loss: 0.0787\n",
      "Step 196/391, Loss: 0.1343\n",
      "Step 197/391, Loss: 0.0616\n",
      "Step 198/391, Loss: 0.0767\n",
      "Step 199/391, Loss: 0.1645\n",
      "Step 200/391, Loss: 0.2085\n",
      "Step 201/391, Loss: 0.1080\n",
      "Step 202/391, Loss: 0.1848\n",
      "Step 203/391, Loss: 0.1310\n",
      "Step 204/391, Loss: 0.1780\n",
      "Step 205/391, Loss: 0.0725\n",
      "Step 206/391, Loss: 0.0890\n",
      "Step 207/391, Loss: 0.1452\n",
      "Step 208/391, Loss: 0.0793\n",
      "Step 209/391, Loss: 0.0751\n",
      "Step 210/391, Loss: 0.0810\n",
      "Step 211/391, Loss: 0.1108\n",
      "Step 212/391, Loss: 0.1544\n",
      "Step 213/391, Loss: 0.0895\n",
      "Step 214/391, Loss: 0.1346\n",
      "Step 215/391, Loss: 0.0620\n",
      "Step 216/391, Loss: 0.2237\n",
      "Step 217/391, Loss: 0.1328\n",
      "Step 218/391, Loss: 0.1100\n",
      "Step 219/391, Loss: 0.1283\n",
      "Step 220/391, Loss: 0.1193\n",
      "Step 221/391, Loss: 0.1338\n",
      "Step 222/391, Loss: 0.1412\n",
      "Step 223/391, Loss: 0.0871\n",
      "Step 224/391, Loss: 0.0647\n",
      "Step 225/391, Loss: 0.1215\n",
      "Step 226/391, Loss: 0.1625\n",
      "Step 227/391, Loss: 0.1975\n",
      "Step 228/391, Loss: 0.1886\n",
      "Step 229/391, Loss: 0.2553\n",
      "Step 230/391, Loss: 0.2933\n",
      "Step 231/391, Loss: 0.1127\n",
      "Step 232/391, Loss: 0.1470\n",
      "Step 233/391, Loss: 0.1069\n",
      "Step 234/391, Loss: 0.1672\n",
      "Step 235/391, Loss: 0.0648\n",
      "Step 236/391, Loss: 0.0423\n",
      "Step 237/391, Loss: 0.1451\n",
      "Step 238/391, Loss: 0.1615\n",
      "Step 239/391, Loss: 0.1087\n",
      "Step 240/391, Loss: 0.0489\n",
      "Step 241/391, Loss: 0.1410\n",
      "Step 242/391, Loss: 0.1307\n",
      "Step 243/391, Loss: 0.1748\n",
      "Step 244/391, Loss: 0.2059\n",
      "Step 245/391, Loss: 0.1204\n",
      "Step 246/391, Loss: 0.1089\n",
      "Step 247/391, Loss: 0.1156\n",
      "Step 248/391, Loss: 0.0868\n",
      "Step 249/391, Loss: 0.0701\n",
      "Step 250/391, Loss: 0.1391\n",
      "Step 251/391, Loss: 0.2669\n",
      "Step 252/391, Loss: 0.1348\n",
      "Step 253/391, Loss: 0.0939\n",
      "Step 254/391, Loss: 0.1463\n",
      "Step 255/391, Loss: 0.1716\n",
      "Step 256/391, Loss: 0.0798\n",
      "Step 257/391, Loss: 0.1258\n",
      "Step 258/391, Loss: 0.1457\n",
      "Step 259/391, Loss: 0.0867\n",
      "Step 260/391, Loss: 0.1500\n",
      "Step 261/391, Loss: 0.1161\n",
      "Step 262/391, Loss: 0.0897\n",
      "Step 263/391, Loss: 0.1648\n",
      "Step 264/391, Loss: 0.2016\n",
      "Step 265/391, Loss: 0.1401\n",
      "Step 266/391, Loss: 0.1641\n",
      "Step 267/391, Loss: 0.0731\n",
      "Step 268/391, Loss: 0.0978\n",
      "Step 269/391, Loss: 0.1571\n",
      "Step 270/391, Loss: 0.1455\n",
      "Step 271/391, Loss: 0.1623\n",
      "Step 272/391, Loss: 0.1235\n",
      "Step 273/391, Loss: 0.2139\n",
      "Step 274/391, Loss: 0.0920\n",
      "Step 275/391, Loss: 0.1098\n",
      "Step 276/391, Loss: 0.0898\n",
      "Step 277/391, Loss: 0.1584\n",
      "Step 278/391, Loss: 0.1915\n",
      "Step 279/391, Loss: 0.2153\n",
      "Step 280/391, Loss: 0.1270\n",
      "Step 281/391, Loss: 0.0708\n",
      "Step 282/391, Loss: 0.0968\n",
      "Step 283/391, Loss: 0.0895\n",
      "Step 284/391, Loss: 0.0971\n",
      "Step 285/391, Loss: 0.0796\n",
      "Step 286/391, Loss: 0.3117\n",
      "Step 287/391, Loss: 0.2076\n",
      "Step 288/391, Loss: 0.0640\n",
      "Step 289/391, Loss: 0.0695\n",
      "Step 290/391, Loss: 0.0960\n",
      "Step 291/391, Loss: 0.0928\n",
      "Step 292/391, Loss: 0.1633\n",
      "Step 293/391, Loss: 0.1281\n",
      "Step 294/391, Loss: 0.1283\n",
      "Step 295/391, Loss: 0.1026\n",
      "Step 296/391, Loss: 0.1439\n",
      "Step 297/391, Loss: 0.0984\n",
      "Step 298/391, Loss: 0.1177\n",
      "Step 299/391, Loss: 0.1334\n",
      "Step 300/391, Loss: 0.2632\n",
      "Step 301/391, Loss: 0.0880\n",
      "Step 302/391, Loss: 0.1899\n",
      "Step 303/391, Loss: 0.1173\n",
      "Step 304/391, Loss: 0.0256\n",
      "Step 305/391, Loss: 0.1730\n",
      "Step 306/391, Loss: 0.1722\n",
      "Step 307/391, Loss: 0.1644\n",
      "Step 308/391, Loss: 0.0670\n",
      "Step 309/391, Loss: 0.1961\n",
      "Step 310/391, Loss: 0.0874\n",
      "Step 311/391, Loss: 0.2643\n",
      "Step 312/391, Loss: 0.1974\n",
      "Step 313/391, Loss: 0.1251\n",
      "Step 314/391, Loss: 0.1584\n",
      "Step 315/391, Loss: 0.0472\n",
      "Step 316/391, Loss: 0.1198\n",
      "Step 317/391, Loss: 0.1135\n",
      "Step 318/391, Loss: 0.1022\n",
      "Step 319/391, Loss: 0.1517\n",
      "Step 320/391, Loss: 0.1199\n",
      "Step 321/391, Loss: 0.2275\n",
      "Step 322/391, Loss: 0.2149\n",
      "Step 323/391, Loss: 0.0446\n",
      "Step 324/391, Loss: 0.1615\n",
      "Step 325/391, Loss: 0.1228\n",
      "Step 326/391, Loss: 0.0848\n",
      "Step 327/391, Loss: 0.0740\n",
      "Step 328/391, Loss: 0.1885\n",
      "Step 329/391, Loss: 0.0551\n",
      "Step 330/391, Loss: 0.1347\n",
      "Step 331/391, Loss: 0.0579\n",
      "Step 332/391, Loss: 0.1047\n",
      "Step 333/391, Loss: 0.1946\n",
      "Step 334/391, Loss: 0.1071\n",
      "Step 335/391, Loss: 0.0914\n",
      "Step 336/391, Loss: 0.1382\n",
      "Step 337/391, Loss: 0.1208\n",
      "Step 338/391, Loss: 0.1360\n",
      "Step 339/391, Loss: 0.1640\n",
      "Step 340/391, Loss: 0.1620\n",
      "Step 341/391, Loss: 0.1312\n",
      "Step 342/391, Loss: 0.1751\n",
      "Step 343/391, Loss: 0.0797\n",
      "Step 344/391, Loss: 0.1655\n",
      "Step 345/391, Loss: 0.1404\n",
      "Step 346/391, Loss: 0.0975\n",
      "Step 347/391, Loss: 0.2369\n",
      "Step 348/391, Loss: 0.1292\n",
      "Step 349/391, Loss: 0.2353\n",
      "Step 350/391, Loss: 0.0690\n",
      "Step 351/391, Loss: 0.1167\n",
      "Step 352/391, Loss: 0.0341\n",
      "Step 353/391, Loss: 0.2029\n",
      "Step 354/391, Loss: 0.1076\n",
      "Step 355/391, Loss: 0.1762\n",
      "Step 356/391, Loss: 0.1486\n",
      "Step 357/391, Loss: 0.1011\n",
      "Step 358/391, Loss: 0.1116\n",
      "Step 359/391, Loss: 0.0943\n",
      "Step 360/391, Loss: 0.0982\n",
      "Step 361/391, Loss: 0.1648\n",
      "Step 362/391, Loss: 0.0772\n",
      "Step 363/391, Loss: 0.1034\n",
      "Step 364/391, Loss: 0.1124\n",
      "Step 365/391, Loss: 0.1406\n",
      "Step 366/391, Loss: 0.1235\n",
      "Step 367/391, Loss: 0.1050\n",
      "Step 368/391, Loss: 0.1276\n",
      "Step 369/391, Loss: 0.0790\n",
      "Step 370/391, Loss: 0.1043\n",
      "Step 371/391, Loss: 0.2125\n",
      "Step 372/391, Loss: 0.0851\n",
      "Step 373/391, Loss: 0.1318\n",
      "Step 374/391, Loss: 0.0707\n",
      "Step 375/391, Loss: 0.0908\n",
      "Step 376/391, Loss: 0.1830\n",
      "Step 377/391, Loss: 0.0564\n",
      "Step 378/391, Loss: 0.0522\n",
      "Step 379/391, Loss: 0.1493\n",
      "Step 380/391, Loss: 0.1605\n",
      "Step 381/391, Loss: 0.1299\n",
      "Step 382/391, Loss: 0.0856\n",
      "Step 383/391, Loss: 0.1582\n",
      "Step 384/391, Loss: 0.1078\n",
      "Step 385/391, Loss: 0.0773\n",
      "Step 386/391, Loss: 0.1154\n",
      "Step 387/391, Loss: 0.1159\n",
      "Step 388/391, Loss: 0.1859\n",
      "Step 389/391, Loss: 0.0943\n",
      "Step 390/391, Loss: 0.1236\n",
      "Step 391/391, Loss: 0.2740\n",
      "Epoch 3/25, Average Train Loss: 0.1432\n",
      "Epoch 3/25, Average Validation Loss: 0.1136\n",
      "Model saved at epoch 3 with validation loss: 0.1136\n",
      "Step 1/391, Loss: 0.0531\n",
      "Step 2/391, Loss: 0.1229\n",
      "Step 3/391, Loss: 0.1460\n",
      "Step 4/391, Loss: 0.1455\n",
      "Step 5/391, Loss: 0.1907\n",
      "Step 6/391, Loss: 0.1690\n",
      "Step 7/391, Loss: 0.1693\n",
      "Step 8/391, Loss: 0.1365\n",
      "Step 9/391, Loss: 0.1736\n",
      "Step 10/391, Loss: 0.1000\n",
      "Step 11/391, Loss: 0.0780\n",
      "Step 12/391, Loss: 0.1064\n",
      "Step 13/391, Loss: 0.0768\n",
      "Step 14/391, Loss: 0.0492\n",
      "Step 15/391, Loss: 0.1403\n",
      "Step 16/391, Loss: 0.1524\n",
      "Step 17/391, Loss: 0.0611\n",
      "Step 18/391, Loss: 0.1383\n",
      "Step 19/391, Loss: 0.1324\n",
      "Step 20/391, Loss: 0.0831\n",
      "Step 21/391, Loss: 0.0483\n",
      "Step 22/391, Loss: 0.1138\n",
      "Step 23/391, Loss: 0.2054\n",
      "Step 24/391, Loss: 0.0829\n",
      "Step 25/391, Loss: 0.1545\n",
      "Step 26/391, Loss: 0.0741\n",
      "Step 27/391, Loss: 0.0949\n",
      "Step 28/391, Loss: 0.0802\n",
      "Step 29/391, Loss: 0.0968\n",
      "Step 30/391, Loss: 0.1085\n",
      "Step 31/391, Loss: 0.0116\n",
      "Step 32/391, Loss: 0.0684\n",
      "Step 33/391, Loss: 0.2183\n",
      "Step 34/391, Loss: 0.1381\n",
      "Step 35/391, Loss: 0.1070\n",
      "Step 36/391, Loss: 0.0949\n",
      "Step 37/391, Loss: 0.0867\n",
      "Step 38/391, Loss: 0.0461\n",
      "Step 39/391, Loss: 0.0833\n",
      "Step 40/391, Loss: 0.0922\n",
      "Step 41/391, Loss: 0.1311\n",
      "Step 42/391, Loss: 0.0719\n",
      "Step 43/391, Loss: 0.0795\n",
      "Step 44/391, Loss: 0.2005\n",
      "Step 45/391, Loss: 0.1678\n",
      "Step 46/391, Loss: 0.1592\n",
      "Step 47/391, Loss: 0.1034\n",
      "Step 48/391, Loss: 0.1252\n",
      "Step 49/391, Loss: 0.0960\n",
      "Step 50/391, Loss: 0.1074\n",
      "Step 51/391, Loss: 0.3293\n",
      "Step 52/391, Loss: 0.0804\n",
      "Step 53/391, Loss: 0.0977\n",
      "Step 54/391, Loss: 0.0296\n",
      "Step 55/391, Loss: 0.0907\n",
      "Step 56/391, Loss: 0.0743\n",
      "Step 57/391, Loss: 0.1229\n",
      "Step 58/391, Loss: 0.1436\n",
      "Step 59/391, Loss: 0.1425\n",
      "Step 60/391, Loss: 0.1260\n",
      "Step 61/391, Loss: 0.0709\n",
      "Step 62/391, Loss: 0.1926\n",
      "Step 63/391, Loss: 0.1122\n",
      "Step 64/391, Loss: 0.1903\n",
      "Step 65/391, Loss: 0.0897\n",
      "Step 66/391, Loss: 0.1366\n",
      "Step 67/391, Loss: 0.1897\n",
      "Step 68/391, Loss: 0.1670\n",
      "Step 69/391, Loss: 0.1712\n",
      "Step 70/391, Loss: 0.1102\n",
      "Step 71/391, Loss: 0.1019\n",
      "Step 72/391, Loss: 0.1402\n",
      "Step 73/391, Loss: 0.1008\n",
      "Step 74/391, Loss: 0.1212\n",
      "Step 75/391, Loss: 0.2421\n",
      "Step 76/391, Loss: 0.1303\n",
      "Step 77/391, Loss: 0.1540\n",
      "Step 78/391, Loss: 0.1756\n",
      "Step 79/391, Loss: 0.1665\n",
      "Step 80/391, Loss: 0.1451\n",
      "Step 81/391, Loss: 0.0717\n",
      "Step 82/391, Loss: 0.1063\n",
      "Step 83/391, Loss: 0.1080\n",
      "Step 84/391, Loss: 0.1427\n",
      "Step 85/391, Loss: 0.1366\n",
      "Step 86/391, Loss: 0.1407\n",
      "Step 87/391, Loss: 0.1490\n",
      "Step 88/391, Loss: 0.0803\n",
      "Step 89/391, Loss: 0.0482\n",
      "Step 90/391, Loss: 0.1461\n",
      "Step 91/391, Loss: 0.0862\n",
      "Step 92/391, Loss: 0.1375\n",
      "Step 93/391, Loss: 0.0697\n",
      "Step 94/391, Loss: 0.2073\n",
      "Step 95/391, Loss: 0.1491\n",
      "Step 96/391, Loss: 0.2030\n",
      "Step 97/391, Loss: 0.0719\n",
      "Step 98/391, Loss: 0.1105\n",
      "Step 99/391, Loss: 0.0907\n",
      "Step 100/391, Loss: 0.0419\n",
      "Step 101/391, Loss: 0.0746\n",
      "Step 102/391, Loss: 0.1905\n",
      "Step 103/391, Loss: 0.1171\n",
      "Step 104/391, Loss: 0.2502\n",
      "Step 105/391, Loss: 0.0447\n",
      "Step 106/391, Loss: 0.0778\n",
      "Step 107/391, Loss: 0.1339\n",
      "Step 108/391, Loss: 0.1684\n",
      "Step 109/391, Loss: 0.0552\n",
      "Step 110/391, Loss: 0.1149\n",
      "Step 111/391, Loss: 0.1101\n",
      "Step 112/391, Loss: 0.1442\n",
      "Step 113/391, Loss: 0.1080\n",
      "Step 114/391, Loss: 0.0469\n",
      "Step 115/391, Loss: 0.1422\n",
      "Step 116/391, Loss: 0.1832\n",
      "Step 117/391, Loss: 0.1183\n",
      "Step 118/391, Loss: 0.0750\n",
      "Step 119/391, Loss: 0.0919\n",
      "Step 120/391, Loss: 0.0756\n",
      "Step 121/391, Loss: 0.0609\n",
      "Step 122/391, Loss: 0.0709\n",
      "Step 123/391, Loss: 0.1130\n",
      "Step 124/391, Loss: 0.0879\n",
      "Step 125/391, Loss: 0.1290\n",
      "Step 126/391, Loss: 0.1880\n",
      "Step 127/391, Loss: 0.1074\n",
      "Step 128/391, Loss: 0.1491\n",
      "Step 129/391, Loss: 0.1883\n",
      "Step 130/391, Loss: 0.1478\n",
      "Step 131/391, Loss: 0.0756\n",
      "Step 132/391, Loss: 0.3299\n",
      "Step 133/391, Loss: 0.2050\n",
      "Step 134/391, Loss: 0.0703\n",
      "Step 135/391, Loss: 0.0514\n",
      "Step 136/391, Loss: 0.0597\n",
      "Step 137/391, Loss: 0.1341\n",
      "Step 138/391, Loss: 0.1293\n",
      "Step 139/391, Loss: 0.0421\n",
      "Step 140/391, Loss: 0.1272\n",
      "Step 141/391, Loss: 0.1073\n",
      "Step 142/391, Loss: 0.1407\n",
      "Step 143/391, Loss: 0.2208\n",
      "Step 144/391, Loss: 0.1188\n",
      "Step 145/391, Loss: 0.1444\n",
      "Step 146/391, Loss: 0.3119\n",
      "Step 147/391, Loss: 0.0787\n",
      "Step 148/391, Loss: 0.1439\n",
      "Step 149/391, Loss: 0.1220\n",
      "Step 150/391, Loss: 0.1273\n",
      "Step 151/391, Loss: 0.1451\n",
      "Step 152/391, Loss: 0.0887\n",
      "Step 153/391, Loss: 0.1017\n",
      "Step 154/391, Loss: 0.2803\n",
      "Step 155/391, Loss: 0.1779\n",
      "Step 156/391, Loss: 0.1011\n",
      "Step 157/391, Loss: 0.1481\n",
      "Step 158/391, Loss: 0.1551\n",
      "Step 159/391, Loss: 0.1145\n",
      "Step 160/391, Loss: 0.1185\n",
      "Step 161/391, Loss: 0.0629\n",
      "Step 162/391, Loss: 0.1966\n",
      "Step 163/391, Loss: 0.1361\n",
      "Step 164/391, Loss: 0.0902\n",
      "Step 165/391, Loss: 0.1177\n",
      "Step 166/391, Loss: 0.0554\n",
      "Step 167/391, Loss: 0.0423\n",
      "Step 168/391, Loss: 0.1049\n",
      "Step 169/391, Loss: 0.0811\n",
      "Step 170/391, Loss: 0.0636\n",
      "Step 171/391, Loss: 0.1235\n",
      "Step 172/391, Loss: 0.1737\n",
      "Step 173/391, Loss: 0.1324\n",
      "Step 174/391, Loss: 0.1234\n",
      "Step 175/391, Loss: 0.0833\n",
      "Step 176/391, Loss: 0.0328\n",
      "Step 177/391, Loss: 0.1532\n",
      "Step 178/391, Loss: 0.0666\n",
      "Step 179/391, Loss: 0.0517\n",
      "Step 180/391, Loss: 0.0806\n",
      "Step 181/391, Loss: 0.1040\n",
      "Step 182/391, Loss: 0.1106\n",
      "Step 183/391, Loss: 0.1038\n",
      "Step 184/391, Loss: 0.0605\n",
      "Step 185/391, Loss: 0.1016\n",
      "Step 186/391, Loss: 0.1986\n",
      "Step 187/391, Loss: 0.1898\n",
      "Step 188/391, Loss: 0.0667\n",
      "Step 189/391, Loss: 0.0542\n",
      "Step 190/391, Loss: 0.0583\n",
      "Step 191/391, Loss: 0.0956\n",
      "Step 192/391, Loss: 0.1299\n",
      "Step 193/391, Loss: 0.1362\n",
      "Step 194/391, Loss: 0.1500\n",
      "Step 195/391, Loss: 0.1485\n",
      "Step 196/391, Loss: 0.1295\n",
      "Step 197/391, Loss: 0.1378\n",
      "Step 198/391, Loss: 0.1337\n",
      "Step 199/391, Loss: 0.1467\n",
      "Step 200/391, Loss: 0.0434\n",
      "Step 201/391, Loss: 0.1114\n",
      "Step 202/391, Loss: 0.1000\n",
      "Step 203/391, Loss: 0.0652\n",
      "Step 204/391, Loss: 0.0806\n",
      "Step 205/391, Loss: 0.0862\n",
      "Step 206/391, Loss: 0.0626\n",
      "Step 207/391, Loss: 0.0432\n",
      "Step 208/391, Loss: 0.2692\n",
      "Step 209/391, Loss: 0.2090\n",
      "Step 210/391, Loss: 0.0968\n",
      "Step 211/391, Loss: 0.1011\n",
      "Step 212/391, Loss: 0.2536\n",
      "Step 213/391, Loss: 0.0804\n",
      "Step 214/391, Loss: 0.0718\n",
      "Step 215/391, Loss: 0.0517\n",
      "Step 216/391, Loss: 0.1454\n",
      "Step 217/391, Loss: 0.2058\n",
      "Step 218/391, Loss: 0.1818\n",
      "Step 219/391, Loss: 0.0888\n",
      "Step 220/391, Loss: 0.0896\n",
      "Step 221/391, Loss: 0.1508\n",
      "Step 222/391, Loss: 0.0954\n",
      "Step 223/391, Loss: 0.0796\n",
      "Step 224/391, Loss: 0.0848\n",
      "Step 225/391, Loss: 0.2645\n",
      "Step 226/391, Loss: 0.0614\n",
      "Step 227/391, Loss: 0.0492\n",
      "Step 228/391, Loss: 0.0906\n",
      "Step 229/391, Loss: 0.1331\n",
      "Step 230/391, Loss: 0.0829\n",
      "Step 231/391, Loss: 0.0836\n",
      "Step 232/391, Loss: 0.1595\n",
      "Step 233/391, Loss: 0.1691\n",
      "Step 234/391, Loss: 0.1300\n",
      "Step 235/391, Loss: 0.0910\n",
      "Step 236/391, Loss: 0.1453\n",
      "Step 237/391, Loss: 0.0944\n",
      "Step 238/391, Loss: 0.0582\n",
      "Step 239/391, Loss: 0.1790\n",
      "Step 240/391, Loss: 0.0586\n",
      "Step 241/391, Loss: 0.1177\n",
      "Step 242/391, Loss: 0.2293\n",
      "Step 243/391, Loss: 0.1504\n",
      "Step 244/391, Loss: 0.1619\n",
      "Step 245/391, Loss: 0.0337\n",
      "Step 246/391, Loss: 0.1040\n",
      "Step 247/391, Loss: 0.0819\n",
      "Step 248/391, Loss: 0.1060\n",
      "Step 249/391, Loss: 0.1088\n",
      "Step 250/391, Loss: 0.0803\n",
      "Step 251/391, Loss: 0.0770\n",
      "Step 252/391, Loss: 0.1348\n",
      "Step 253/391, Loss: 0.3105\n",
      "Step 254/391, Loss: 0.2751\n",
      "Step 255/391, Loss: 0.1300\n",
      "Step 256/391, Loss: 0.0695\n",
      "Step 257/391, Loss: 0.1387\n",
      "Step 258/391, Loss: 0.0934\n",
      "Step 259/391, Loss: 0.1703\n",
      "Step 260/391, Loss: 0.0734\n",
      "Step 261/391, Loss: 0.0953\n",
      "Step 262/391, Loss: 0.2175\n",
      "Step 263/391, Loss: 0.1378\n",
      "Step 264/391, Loss: 0.1109\n",
      "Step 265/391, Loss: 0.0746\n",
      "Step 266/391, Loss: 0.1345\n",
      "Step 267/391, Loss: 0.2951\n",
      "Step 268/391, Loss: 0.0909\n",
      "Step 269/391, Loss: 0.1800\n",
      "Step 270/391, Loss: 0.0946\n",
      "Step 271/391, Loss: 0.1579\n",
      "Step 272/391, Loss: 0.1367\n",
      "Step 273/391, Loss: 0.0764\n",
      "Step 274/391, Loss: 0.0799\n",
      "Step 275/391, Loss: 0.1202\n",
      "Step 276/391, Loss: 0.1232\n",
      "Step 277/391, Loss: 0.0913\n",
      "Step 278/391, Loss: 0.1188\n",
      "Step 279/391, Loss: 0.1549\n",
      "Step 280/391, Loss: 0.0715\n",
      "Step 281/391, Loss: 0.1817\n",
      "Step 282/391, Loss: 0.1045\n",
      "Step 283/391, Loss: 0.2038\n",
      "Step 284/391, Loss: 0.1924\n",
      "Step 285/391, Loss: 0.1312\n",
      "Step 286/391, Loss: 0.1102\n",
      "Step 287/391, Loss: 0.1933\n",
      "Step 288/391, Loss: 0.0814\n",
      "Step 289/391, Loss: 0.0438\n",
      "Step 290/391, Loss: 0.1632\n",
      "Step 291/391, Loss: 0.1010\n",
      "Step 292/391, Loss: 0.1128\n",
      "Step 293/391, Loss: 0.1835\n",
      "Step 294/391, Loss: 0.1273\n",
      "Step 295/391, Loss: 0.0543\n",
      "Step 296/391, Loss: 0.0878\n",
      "Step 297/391, Loss: 0.1805\n",
      "Step 298/391, Loss: 0.0761\n",
      "Step 299/391, Loss: 0.1173\n",
      "Step 300/391, Loss: 0.1051\n",
      "Step 301/391, Loss: 0.1396\n",
      "Step 302/391, Loss: 0.1238\n",
      "Step 303/391, Loss: 0.0732\n",
      "Step 304/391, Loss: 0.1531\n",
      "Step 305/391, Loss: 0.0771\n",
      "Step 306/391, Loss: 0.0945\n",
      "Step 307/391, Loss: 0.0584\n",
      "Step 308/391, Loss: 0.1045\n",
      "Step 309/391, Loss: 0.1426\n",
      "Step 310/391, Loss: 0.0839\n",
      "Step 311/391, Loss: 0.0658\n",
      "Step 312/391, Loss: 0.0799\n",
      "Step 313/391, Loss: 0.1235\n",
      "Step 314/391, Loss: 0.0905\n",
      "Step 315/391, Loss: 0.1631\n",
      "Step 316/391, Loss: 0.0797\n",
      "Step 317/391, Loss: 0.1234\n",
      "Step 318/391, Loss: 0.0537\n",
      "Step 319/391, Loss: 0.1527\n",
      "Step 320/391, Loss: 0.0850\n",
      "Step 321/391, Loss: 0.1905\n",
      "Step 322/391, Loss: 0.1362\n",
      "Step 323/391, Loss: 0.0756\n",
      "Step 324/391, Loss: 0.0549\n",
      "Step 325/391, Loss: 0.0805\n",
      "Step 326/391, Loss: 0.1255\n",
      "Step 327/391, Loss: 0.1124\n",
      "Step 328/391, Loss: 0.2180\n",
      "Step 329/391, Loss: 0.1574\n",
      "Step 330/391, Loss: 0.2120\n",
      "Step 331/391, Loss: 0.2114\n",
      "Step 332/391, Loss: 0.1382\n",
      "Step 333/391, Loss: 0.1269\n",
      "Step 334/391, Loss: 0.0816\n",
      "Step 335/391, Loss: 0.1466\n",
      "Step 336/391, Loss: 0.0744\n",
      "Step 337/391, Loss: 0.0841\n",
      "Step 338/391, Loss: 0.0461\n",
      "Step 339/391, Loss: 0.1135\n",
      "Step 340/391, Loss: 0.0554\n",
      "Step 341/391, Loss: 0.1189\n",
      "Step 342/391, Loss: 0.0867\n",
      "Step 343/391, Loss: 0.0866\n",
      "Step 344/391, Loss: 0.0818\n",
      "Step 345/391, Loss: 0.1856\n",
      "Step 346/391, Loss: 0.0386\n",
      "Step 347/391, Loss: 0.2769\n",
      "Step 348/391, Loss: 0.1085\n",
      "Step 349/391, Loss: 0.3309\n",
      "Step 350/391, Loss: 0.1284\n",
      "Step 351/391, Loss: 0.0387\n",
      "Step 352/391, Loss: 0.0843\n",
      "Step 353/391, Loss: 0.1066\n",
      "Step 354/391, Loss: 0.1199\n",
      "Step 355/391, Loss: 0.0904\n",
      "Step 356/391, Loss: 0.1526\n",
      "Step 357/391, Loss: 0.1828\n",
      "Step 358/391, Loss: 0.1653\n",
      "Step 359/391, Loss: 0.0804\n",
      "Step 360/391, Loss: 0.1232\n",
      "Step 361/391, Loss: 0.1405\n",
      "Step 362/391, Loss: 0.1145\n",
      "Step 363/391, Loss: 0.1072\n",
      "Step 364/391, Loss: 0.1130\n",
      "Step 365/391, Loss: 0.1027\n",
      "Step 366/391, Loss: 0.0409\n",
      "Step 367/391, Loss: 0.1271\n",
      "Step 368/391, Loss: 0.1259\n",
      "Step 369/391, Loss: 0.0747\n",
      "Step 370/391, Loss: 0.1149\n",
      "Step 371/391, Loss: 0.1009\n",
      "Step 372/391, Loss: 0.0584\n",
      "Step 373/391, Loss: 0.0584\n",
      "Step 374/391, Loss: 0.0972\n",
      "Step 375/391, Loss: 0.1222\n",
      "Step 376/391, Loss: 0.1103\n",
      "Step 377/391, Loss: 0.1798\n",
      "Step 378/391, Loss: 0.0720\n",
      "Step 379/391, Loss: 0.0840\n",
      "Step 380/391, Loss: 0.1911\n",
      "Step 381/391, Loss: 0.1803\n",
      "Step 382/391, Loss: 0.0540\n",
      "Step 383/391, Loss: 0.0907\n",
      "Step 384/391, Loss: 0.1087\n",
      "Step 385/391, Loss: 0.0520\n",
      "Step 386/391, Loss: 0.1542\n",
      "Step 387/391, Loss: 0.1548\n",
      "Step 388/391, Loss: 0.0660\n",
      "Step 389/391, Loss: 0.0497\n",
      "Step 390/391, Loss: 0.0888\n",
      "Step 391/391, Loss: 0.1751\n",
      "Epoch 4/25, Average Train Loss: 0.1201\n",
      "Epoch 4/25, Average Validation Loss: 0.1038\n",
      "Model saved at epoch 4 with validation loss: 0.1038\n",
      "Step 1/391, Loss: 0.0424\n",
      "Step 2/391, Loss: 0.0779\n",
      "Step 3/391, Loss: 0.1714\n",
      "Step 4/391, Loss: 0.0416\n",
      "Step 5/391, Loss: 0.0582\n",
      "Step 6/391, Loss: 0.0631\n",
      "Step 7/391, Loss: 0.0747\n",
      "Step 8/391, Loss: 0.0845\n",
      "Step 9/391, Loss: 0.1062\n",
      "Step 10/391, Loss: 0.0342\n",
      "Step 11/391, Loss: 0.0351\n",
      "Step 12/391, Loss: 0.1274\n",
      "Step 13/391, Loss: 0.1987\n",
      "Step 14/391, Loss: 0.1110\n",
      "Step 15/391, Loss: 0.0484\n",
      "Step 16/391, Loss: 0.0262\n",
      "Step 17/391, Loss: 0.0952\n",
      "Step 18/391, Loss: 0.1512\n",
      "Step 19/391, Loss: 0.0576\n",
      "Step 20/391, Loss: 0.1032\n",
      "Step 21/391, Loss: 0.0688\n",
      "Step 22/391, Loss: 0.0823\n",
      "Step 23/391, Loss: 0.0607\n",
      "Step 24/391, Loss: 0.1517\n",
      "Step 25/391, Loss: 0.0549\n",
      "Step 26/391, Loss: 0.1326\n",
      "Step 27/391, Loss: 0.1087\n",
      "Step 28/391, Loss: 0.1705\n",
      "Step 29/391, Loss: 0.1526\n",
      "Step 30/391, Loss: 0.1202\n",
      "Step 31/391, Loss: 0.0676\n",
      "Step 32/391, Loss: 0.0285\n",
      "Step 33/391, Loss: 0.0409\n",
      "Step 34/391, Loss: 0.0679\n",
      "Step 35/391, Loss: 0.1377\n",
      "Step 36/391, Loss: 0.0788\n",
      "Step 37/391, Loss: 0.1663\n",
      "Step 38/391, Loss: 0.1271\n",
      "Step 39/391, Loss: 0.1034\n",
      "Step 40/391, Loss: 0.1312\n",
      "Step 41/391, Loss: 0.0573\n",
      "Step 42/391, Loss: 0.1309\n",
      "Step 43/391, Loss: 0.0650\n",
      "Step 44/391, Loss: 0.0739\n",
      "Step 45/391, Loss: 0.0518\n",
      "Step 46/391, Loss: 0.1317\n",
      "Step 47/391, Loss: 0.0742\n",
      "Step 48/391, Loss: 0.1875\n",
      "Step 49/391, Loss: 0.0805\n",
      "Step 50/391, Loss: 0.0891\n",
      "Step 51/391, Loss: 0.0790\n",
      "Step 52/391, Loss: 0.1326\n",
      "Step 53/391, Loss: 0.0833\n",
      "Step 54/391, Loss: 0.1261\n",
      "Step 55/391, Loss: 0.1636\n",
      "Step 56/391, Loss: 0.1692\n",
      "Step 57/391, Loss: 0.1152\n",
      "Step 58/391, Loss: 0.0680\n",
      "Step 59/391, Loss: 0.0862\n",
      "Step 60/391, Loss: 0.0774\n",
      "Step 61/391, Loss: 0.0799\n",
      "Step 62/391, Loss: 0.0738\n",
      "Step 63/391, Loss: 0.1330\n",
      "Step 64/391, Loss: 0.1127\n",
      "Step 65/391, Loss: 0.0681\n",
      "Step 66/391, Loss: 0.1389\n",
      "Step 67/391, Loss: 0.1088\n",
      "Step 68/391, Loss: 0.0876\n",
      "Step 69/391, Loss: 0.0761\n",
      "Step 70/391, Loss: 0.1280\n",
      "Step 71/391, Loss: 0.0515\n",
      "Step 72/391, Loss: 0.1062\n",
      "Step 73/391, Loss: 0.0419\n",
      "Step 74/391, Loss: 0.1252\n",
      "Step 75/391, Loss: 0.1522\n",
      "Step 76/391, Loss: 0.0991\n",
      "Step 77/391, Loss: 0.0645\n",
      "Step 78/391, Loss: 0.1374\n",
      "Step 79/391, Loss: 0.0594\n",
      "Step 80/391, Loss: 0.0427\n",
      "Step 81/391, Loss: 0.0782\n",
      "Step 82/391, Loss: 0.0803\n",
      "Step 83/391, Loss: 0.0779\n",
      "Step 84/391, Loss: 0.1255\n",
      "Step 85/391, Loss: 0.1338\n",
      "Step 86/391, Loss: 0.1807\n",
      "Step 87/391, Loss: 0.1189\n",
      "Step 88/391, Loss: 0.1412\n",
      "Step 89/391, Loss: 0.0989\n",
      "Step 90/391, Loss: 0.0483\n",
      "Step 91/391, Loss: 0.0799\n",
      "Step 92/391, Loss: 0.1684\n",
      "Step 93/391, Loss: 0.0721\n",
      "Step 94/391, Loss: 0.0782\n",
      "Step 95/391, Loss: 0.0778\n",
      "Step 96/391, Loss: 0.1688\n",
      "Step 97/391, Loss: 0.1584\n",
      "Step 98/391, Loss: 0.0363\n",
      "Step 99/391, Loss: 0.0600\n",
      "Step 100/391, Loss: 0.0578\n",
      "Step 101/391, Loss: 0.0828\n",
      "Step 102/391, Loss: 0.0299\n",
      "Step 103/391, Loss: 0.0775\n",
      "Step 104/391, Loss: 0.0184\n",
      "Step 105/391, Loss: 0.1578\n",
      "Step 106/391, Loss: 0.1157\n",
      "Step 107/391, Loss: 0.0659\n",
      "Step 108/391, Loss: 0.1421\n",
      "Step 109/391, Loss: 0.0162\n",
      "Step 110/391, Loss: 0.2027\n",
      "Step 111/391, Loss: 0.0726\n",
      "Step 112/391, Loss: 0.0469\n",
      "Step 113/391, Loss: 0.1175\n",
      "Step 114/391, Loss: 0.0471\n",
      "Step 115/391, Loss: 0.1504\n",
      "Step 116/391, Loss: 0.1322\n",
      "Step 117/391, Loss: 0.0465\n",
      "Step 118/391, Loss: 0.0640\n",
      "Step 119/391, Loss: 0.1206\n",
      "Step 120/391, Loss: 0.1319\n",
      "Step 121/391, Loss: 0.2203\n",
      "Step 122/391, Loss: 0.0824\n",
      "Step 123/391, Loss: 0.0696\n",
      "Step 124/391, Loss: 0.0805\n",
      "Step 125/391, Loss: 0.1241\n",
      "Step 126/391, Loss: 0.0584\n",
      "Step 127/391, Loss: 0.0806\n",
      "Step 128/391, Loss: 0.1350\n",
      "Step 129/391, Loss: 0.0354\n",
      "Step 130/391, Loss: 0.1380\n",
      "Step 131/391, Loss: 0.0504\n",
      "Step 132/391, Loss: 0.0829\n",
      "Step 133/391, Loss: 0.1796\n",
      "Step 134/391, Loss: 0.0377\n",
      "Step 135/391, Loss: 0.1577\n",
      "Step 136/391, Loss: 0.0600\n",
      "Step 137/391, Loss: 0.0499\n",
      "Step 138/391, Loss: 0.1566\n",
      "Step 139/391, Loss: 0.0348\n",
      "Step 140/391, Loss: 0.1392\n",
      "Step 141/391, Loss: 0.0990\n",
      "Step 142/391, Loss: 0.0549\n",
      "Step 143/391, Loss: 0.0902\n",
      "Step 144/391, Loss: 0.1194\n",
      "Step 145/391, Loss: 0.0516\n",
      "Step 146/391, Loss: 0.0948\n",
      "Step 147/391, Loss: 0.1015\n",
      "Step 148/391, Loss: 0.0416\n",
      "Step 149/391, Loss: 0.0840\n",
      "Step 150/391, Loss: 0.2528\n",
      "Step 151/391, Loss: 0.0515\n",
      "Step 152/391, Loss: 0.1672\n",
      "Step 153/391, Loss: 0.0691\n",
      "Step 154/391, Loss: 0.1552\n",
      "Step 155/391, Loss: 0.0520\n",
      "Step 156/391, Loss: 0.0924\n",
      "Step 157/391, Loss: 0.1068\n",
      "Step 158/391, Loss: 0.0683\n",
      "Step 159/391, Loss: 0.0623\n",
      "Step 160/391, Loss: 0.0970\n",
      "Step 161/391, Loss: 0.0744\n",
      "Step 162/391, Loss: 0.0577\n",
      "Step 163/391, Loss: 0.1393\n",
      "Step 164/391, Loss: 0.0927\n",
      "Step 165/391, Loss: 0.0890\n",
      "Step 166/391, Loss: 0.1387\n",
      "Step 167/391, Loss: 0.1252\n",
      "Step 168/391, Loss: 0.0521\n",
      "Step 169/391, Loss: 0.1055\n",
      "Step 170/391, Loss: 0.0865\n",
      "Step 171/391, Loss: 0.0749\n",
      "Step 172/391, Loss: 0.1158\n",
      "Step 173/391, Loss: 0.0606\n",
      "Step 174/391, Loss: 0.1876\n",
      "Step 175/391, Loss: 0.1210\n",
      "Step 176/391, Loss: 0.2065\n",
      "Step 177/391, Loss: 0.0574\n",
      "Step 178/391, Loss: 0.0624\n",
      "Step 179/391, Loss: 0.0855\n",
      "Step 180/391, Loss: 0.0837\n",
      "Step 181/391, Loss: 0.1124\n",
      "Step 182/391, Loss: 0.1000\n",
      "Step 183/391, Loss: 0.2109\n",
      "Step 184/391, Loss: 0.0679\n",
      "Step 185/391, Loss: 0.0941\n",
      "Step 186/391, Loss: 0.0474\n",
      "Step 187/391, Loss: 0.1092\n",
      "Step 188/391, Loss: 0.1214\n",
      "Step 189/391, Loss: 0.1397\n",
      "Step 190/391, Loss: 0.0804\n",
      "Step 191/391, Loss: 0.1843\n",
      "Step 192/391, Loss: 0.3012\n",
      "Step 193/391, Loss: 0.0626\n",
      "Step 194/391, Loss: 0.1374\n",
      "Step 195/391, Loss: 0.1117\n",
      "Step 196/391, Loss: 0.1421\n",
      "Step 197/391, Loss: 0.0455\n",
      "Step 198/391, Loss: 0.1334\n",
      "Step 199/391, Loss: 0.1016\n",
      "Step 200/391, Loss: 0.1076\n",
      "Step 201/391, Loss: 0.0411\n",
      "Step 202/391, Loss: 0.1336\n",
      "Step 203/391, Loss: 0.1047\n",
      "Step 204/391, Loss: 0.0750\n",
      "Step 205/391, Loss: 0.0248\n",
      "Step 206/391, Loss: 0.0673\n",
      "Step 207/391, Loss: 0.1710\n",
      "Step 208/391, Loss: 0.1352\n",
      "Step 209/391, Loss: 0.0301\n",
      "Step 210/391, Loss: 0.2803\n",
      "Step 211/391, Loss: 0.0403\n",
      "Step 212/391, Loss: 0.0819\n",
      "Step 213/391, Loss: 0.1058\n",
      "Step 214/391, Loss: 0.1375\n",
      "Step 215/391, Loss: 0.0464\n",
      "Step 216/391, Loss: 0.0816\n",
      "Step 217/391, Loss: 0.0927\n",
      "Step 218/391, Loss: 0.1029\n",
      "Step 219/391, Loss: 0.0670\n",
      "Step 220/391, Loss: 0.0305\n",
      "Step 221/391, Loss: 0.0597\n",
      "Step 222/391, Loss: 0.1185\n",
      "Step 223/391, Loss: 0.1634\n",
      "Step 224/391, Loss: 0.0818\n",
      "Step 225/391, Loss: 0.0751\n",
      "Step 226/391, Loss: 0.0535\n",
      "Step 227/391, Loss: 0.1462\n",
      "Step 228/391, Loss: 0.1126\n",
      "Step 229/391, Loss: 0.0116\n",
      "Step 230/391, Loss: 0.2148\n",
      "Step 231/391, Loss: 0.1545\n",
      "Step 232/391, Loss: 0.0940\n",
      "Step 233/391, Loss: 0.0489\n",
      "Step 234/391, Loss: 0.0830\n",
      "Step 235/391, Loss: 0.0885\n",
      "Step 236/391, Loss: 0.1441\n",
      "Step 237/391, Loss: 0.1118\n",
      "Step 238/391, Loss: 0.0404\n",
      "Step 239/391, Loss: 0.1385\n",
      "Step 240/391, Loss: 0.0231\n",
      "Step 241/391, Loss: 0.0952\n",
      "Step 242/391, Loss: 0.0765\n",
      "Step 243/391, Loss: 0.0879\n",
      "Step 244/391, Loss: 0.0752\n",
      "Step 245/391, Loss: 0.0907\n",
      "Step 246/391, Loss: 0.0983\n",
      "Step 247/391, Loss: 0.1658\n",
      "Step 248/391, Loss: 0.0634\n",
      "Step 249/391, Loss: 0.1675\n",
      "Step 250/391, Loss: 0.1035\n",
      "Step 251/391, Loss: 0.0803\n",
      "Step 252/391, Loss: 0.0567\n",
      "Step 253/391, Loss: 0.0864\n",
      "Step 254/391, Loss: 0.1414\n",
      "Step 255/391, Loss: 0.0828\n",
      "Step 256/391, Loss: 0.1045\n",
      "Step 257/391, Loss: 0.0540\n",
      "Step 258/391, Loss: 0.0961\n",
      "Step 259/391, Loss: 0.1630\n",
      "Step 260/391, Loss: 0.1044\n",
      "Step 261/391, Loss: 0.0377\n",
      "Step 262/391, Loss: 0.0474\n",
      "Step 263/391, Loss: 0.0771\n",
      "Step 264/391, Loss: 0.1240\n",
      "Step 265/391, Loss: 0.0462\n",
      "Step 266/391, Loss: 0.0937\n",
      "Step 267/391, Loss: 0.0741\n",
      "Step 268/391, Loss: 0.1072\n",
      "Step 269/391, Loss: 0.1081\n",
      "Step 270/391, Loss: 0.0489\n",
      "Step 271/391, Loss: 0.0384\n",
      "Step 272/391, Loss: 0.0392\n",
      "Step 273/391, Loss: 0.0844\n",
      "Step 274/391, Loss: 0.0857\n",
      "Step 275/391, Loss: 0.1378\n",
      "Step 276/391, Loss: 0.1482\n",
      "Step 277/391, Loss: 0.0612\n",
      "Step 278/391, Loss: 0.1338\n",
      "Step 279/391, Loss: 0.1124\n",
      "Step 280/391, Loss: 0.0671\n",
      "Step 281/391, Loss: 0.1588\n",
      "Step 282/391, Loss: 0.1839\n",
      "Step 283/391, Loss: 0.1639\n",
      "Step 284/391, Loss: 0.0261\n",
      "Step 285/391, Loss: 0.0603\n",
      "Step 286/391, Loss: 0.0598\n",
      "Step 287/391, Loss: 0.0636\n",
      "Step 288/391, Loss: 0.0721\n",
      "Step 289/391, Loss: 0.0717\n",
      "Step 290/391, Loss: 0.0896\n",
      "Step 291/391, Loss: 0.0614\n",
      "Step 292/391, Loss: 0.0510\n",
      "Step 293/391, Loss: 0.2031\n",
      "Step 294/391, Loss: 0.0751\n",
      "Step 295/391, Loss: 0.0965\n",
      "Step 296/391, Loss: 0.1111\n",
      "Step 297/391, Loss: 0.1745\n",
      "Step 298/391, Loss: 0.0676\n",
      "Step 299/391, Loss: 0.1205\n",
      "Step 300/391, Loss: 0.1498\n",
      "Step 301/391, Loss: 0.0491\n",
      "Step 302/391, Loss: 0.1609\n",
      "Step 303/391, Loss: 0.0934\n",
      "Step 304/391, Loss: 0.0716\n",
      "Step 305/391, Loss: 0.1209\n",
      "Step 306/391, Loss: 0.1184\n",
      "Step 307/391, Loss: 0.0659\n",
      "Step 308/391, Loss: 0.0746\n",
      "Step 309/391, Loss: 0.1020\n",
      "Step 310/391, Loss: 0.1301\n",
      "Step 311/391, Loss: 0.1626\n",
      "Step 312/391, Loss: 0.0960\n",
      "Step 313/391, Loss: 0.1845\n",
      "Step 314/391, Loss: 0.0432\n",
      "Step 315/391, Loss: 0.0312\n",
      "Step 316/391, Loss: 0.0490\n",
      "Step 317/391, Loss: 0.1161\n",
      "Step 318/391, Loss: 0.0437\n",
      "Step 319/391, Loss: 0.1731\n",
      "Step 320/391, Loss: 0.1072\n",
      "Step 321/391, Loss: 0.1303\n",
      "Step 322/391, Loss: 0.1145\n",
      "Step 323/391, Loss: 0.1011\n",
      "Step 324/391, Loss: 0.0482\n",
      "Step 325/391, Loss: 0.1000\n",
      "Step 326/391, Loss: 0.1037\n",
      "Step 327/391, Loss: 0.1522\n",
      "Step 328/391, Loss: 0.0692\n",
      "Step 329/391, Loss: 0.0734\n",
      "Step 330/391, Loss: 0.1427\n",
      "Step 331/391, Loss: 0.1017\n",
      "Step 332/391, Loss: 0.1477\n",
      "Step 333/391, Loss: 0.0870\n",
      "Step 334/391, Loss: 0.0648\n",
      "Step 335/391, Loss: 0.1086\n",
      "Step 336/391, Loss: 0.1243\n",
      "Step 337/391, Loss: 0.0973\n",
      "Step 338/391, Loss: 0.0585\n",
      "Step 339/391, Loss: 0.0718\n",
      "Step 340/391, Loss: 0.0577\n",
      "Step 341/391, Loss: 0.1433\n",
      "Step 342/391, Loss: 0.1008\n",
      "Step 343/391, Loss: 0.0995\n",
      "Step 344/391, Loss: 0.0705\n",
      "Step 345/391, Loss: 0.1625\n",
      "Step 346/391, Loss: 0.0546\n",
      "Step 347/391, Loss: 0.0764\n",
      "Step 348/391, Loss: 0.0705\n",
      "Step 349/391, Loss: 0.1772\n",
      "Step 350/391, Loss: 0.1234\n",
      "Step 351/391, Loss: 0.0962\n",
      "Step 352/391, Loss: 0.0875\n",
      "Step 353/391, Loss: 0.0947\n",
      "Step 354/391, Loss: 0.1380\n",
      "Step 355/391, Loss: 0.1747\n",
      "Step 356/391, Loss: 0.1124\n",
      "Step 357/391, Loss: 0.1075\n",
      "Step 358/391, Loss: 0.0896\n",
      "Step 359/391, Loss: 0.1634\n",
      "Step 360/391, Loss: 0.0447\n",
      "Step 361/391, Loss: 0.1652\n",
      "Step 362/391, Loss: 0.0451\n",
      "Step 363/391, Loss: 0.1536\n",
      "Step 364/391, Loss: 0.2327\n",
      "Step 365/391, Loss: 0.0882\n",
      "Step 366/391, Loss: 0.0384\n",
      "Step 367/391, Loss: 0.0964\n",
      "Step 368/391, Loss: 0.1447\n",
      "Step 369/391, Loss: 0.1234\n",
      "Step 370/391, Loss: 0.0431\n",
      "Step 371/391, Loss: 0.1337\n",
      "Step 372/391, Loss: 0.1311\n",
      "Step 373/391, Loss: 0.0263\n",
      "Step 374/391, Loss: 0.0830\n",
      "Step 375/391, Loss: 0.0956\n",
      "Step 376/391, Loss: 0.1764\n",
      "Step 377/391, Loss: 0.1823\n",
      "Step 378/391, Loss: 0.1308\n",
      "Step 379/391, Loss: 0.1179\n",
      "Step 380/391, Loss: 0.1421\n",
      "Step 381/391, Loss: 0.0833\n",
      "Step 382/391, Loss: 0.0846\n",
      "Step 383/391, Loss: 0.0570\n",
      "Step 384/391, Loss: 0.0410\n",
      "Step 385/391, Loss: 0.0527\n",
      "Step 386/391, Loss: 0.0575\n",
      "Step 387/391, Loss: 0.1385\n",
      "Step 388/391, Loss: 0.1010\n",
      "Step 389/391, Loss: 0.1920\n",
      "Step 390/391, Loss: 0.1955\n",
      "Step 391/391, Loss: 0.1694\n",
      "Epoch 5/25, Average Train Loss: 0.0999\n",
      "Epoch 5/25, Average Validation Loss: 0.1011\n",
      "Model saved at epoch 5 with validation loss: 0.1011\n",
      "Step 1/391, Loss: 0.0569\n",
      "Step 2/391, Loss: 0.0723\n",
      "Step 3/391, Loss: 0.0953\n",
      "Step 4/391, Loss: 0.1271\n",
      "Step 5/391, Loss: 0.0237\n",
      "Step 6/391, Loss: 0.0686\n",
      "Step 7/391, Loss: 0.0327\n",
      "Step 8/391, Loss: 0.1116\n",
      "Step 9/391, Loss: 0.0240\n",
      "Step 10/391, Loss: 0.0738\n",
      "Step 11/391, Loss: 0.1226\n",
      "Step 12/391, Loss: 0.0216\n",
      "Step 13/391, Loss: 0.1104\n",
      "Step 14/391, Loss: 0.0806\n",
      "Step 15/391, Loss: 0.0948\n",
      "Step 16/391, Loss: 0.0614\n",
      "Step 17/391, Loss: 0.1255\n",
      "Step 18/391, Loss: 0.0680\n",
      "Step 19/391, Loss: 0.0430\n",
      "Step 20/391, Loss: 0.0921\n",
      "Step 21/391, Loss: 0.0925\n",
      "Step 22/391, Loss: 0.0259\n",
      "Step 23/391, Loss: 0.0480\n",
      "Step 24/391, Loss: 0.0418\n",
      "Step 25/391, Loss: 0.0709\n",
      "Step 26/391, Loss: 0.1465\n",
      "Step 27/391, Loss: 0.0937\n",
      "Step 28/391, Loss: 0.0286\n",
      "Step 29/391, Loss: 0.0619\n",
      "Step 30/391, Loss: 0.0901\n",
      "Step 31/391, Loss: 0.0581\n",
      "Step 32/391, Loss: 0.0286\n",
      "Step 33/391, Loss: 0.0308\n",
      "Step 34/391, Loss: 0.0515\n",
      "Step 35/391, Loss: 0.1006\n",
      "Step 36/391, Loss: 0.0261\n",
      "Step 37/391, Loss: 0.1274\n",
      "Step 38/391, Loss: 0.0406\n",
      "Step 39/391, Loss: 0.0974\n",
      "Step 40/391, Loss: 0.0853\n",
      "Step 41/391, Loss: 0.0665\n",
      "Step 42/391, Loss: 0.0619\n",
      "Step 43/391, Loss: 0.0240\n",
      "Step 44/391, Loss: 0.2364\n",
      "Step 45/391, Loss: 0.0728\n",
      "Step 46/391, Loss: 0.0691\n",
      "Step 47/391, Loss: 0.1067\n",
      "Step 48/391, Loss: 0.0983\n",
      "Step 49/391, Loss: 0.0499\n",
      "Step 50/391, Loss: 0.0848\n",
      "Step 51/391, Loss: 0.0751\n",
      "Step 52/391, Loss: 0.0460\n",
      "Step 53/391, Loss: 0.0876\n",
      "Step 54/391, Loss: 0.0509\n",
      "Step 55/391, Loss: 0.0743\n",
      "Step 56/391, Loss: 0.0595\n",
      "Step 57/391, Loss: 0.1334\n",
      "Step 58/391, Loss: 0.0399\n",
      "Step 59/391, Loss: 0.0293\n",
      "Step 60/391, Loss: 0.0664\n",
      "Step 61/391, Loss: 0.0896\n",
      "Step 62/391, Loss: 0.0719\n",
      "Step 63/391, Loss: 0.0880\n",
      "Step 64/391, Loss: 0.0318\n",
      "Step 65/391, Loss: 0.0546\n",
      "Step 66/391, Loss: 0.0778\n",
      "Step 67/391, Loss: 0.0965\n",
      "Step 68/391, Loss: 0.0788\n",
      "Step 69/391, Loss: 0.0448\n",
      "Step 70/391, Loss: 0.0374\n",
      "Step 71/391, Loss: 0.0596\n",
      "Step 72/391, Loss: 0.0313\n",
      "Step 73/391, Loss: 0.0827\n",
      "Step 74/391, Loss: 0.0554\n",
      "Step 75/391, Loss: 0.1034\n",
      "Step 76/391, Loss: 0.0911\n",
      "Step 77/391, Loss: 0.1742\n",
      "Step 78/391, Loss: 0.1142\n",
      "Step 79/391, Loss: 0.0855\n",
      "Step 80/391, Loss: 0.1147\n",
      "Step 81/391, Loss: 0.1446\n",
      "Step 82/391, Loss: 0.0819\n",
      "Step 83/391, Loss: 0.1566\n",
      "Step 84/391, Loss: 0.1082\n",
      "Step 85/391, Loss: 0.0626\n",
      "Step 86/391, Loss: 0.0343\n",
      "Step 87/391, Loss: 0.0503\n",
      "Step 88/391, Loss: 0.0564\n",
      "Step 89/391, Loss: 0.0810\n",
      "Step 90/391, Loss: 0.1259\n",
      "Step 91/391, Loss: 0.0564\n",
      "Step 92/391, Loss: 0.0449\n",
      "Step 93/391, Loss: 0.0748\n",
      "Step 94/391, Loss: 0.1024\n",
      "Step 95/391, Loss: 0.0227\n",
      "Step 96/391, Loss: 0.1639\n",
      "Step 97/391, Loss: 0.0352\n",
      "Step 98/391, Loss: 0.0771\n",
      "Step 99/391, Loss: 0.0523\n",
      "Step 100/391, Loss: 0.1104\n",
      "Step 101/391, Loss: 0.2039\n",
      "Step 102/391, Loss: 0.1152\n",
      "Step 103/391, Loss: 0.1224\n",
      "Step 104/391, Loss: 0.1386\n",
      "Step 105/391, Loss: 0.1188\n",
      "Step 106/391, Loss: 0.0276\n",
      "Step 107/391, Loss: 0.0205\n",
      "Step 108/391, Loss: 0.0528\n",
      "Step 109/391, Loss: 0.2282\n",
      "Step 110/391, Loss: 0.0960\n",
      "Step 111/391, Loss: 0.1640\n",
      "Step 112/391, Loss: 0.1352\n",
      "Step 113/391, Loss: 0.0820\n",
      "Step 114/391, Loss: 0.1471\n",
      "Step 115/391, Loss: 0.0595\n",
      "Step 116/391, Loss: 0.0484\n",
      "Step 117/391, Loss: 0.0558\n",
      "Step 118/391, Loss: 0.0824\n",
      "Step 119/391, Loss: 0.1748\n",
      "Step 120/391, Loss: 0.1013\n",
      "Step 121/391, Loss: 0.1060\n",
      "Step 122/391, Loss: 0.1228\n",
      "Step 123/391, Loss: 0.0297\n",
      "Step 124/391, Loss: 0.1321\n",
      "Step 125/391, Loss: 0.0775\n",
      "Step 126/391, Loss: 0.0423\n",
      "Step 127/391, Loss: 0.0752\n",
      "Step 128/391, Loss: 0.1348\n",
      "Step 129/391, Loss: 0.0345\n",
      "Step 130/391, Loss: 0.1930\n",
      "Step 131/391, Loss: 0.0314\n",
      "Step 132/391, Loss: 0.1339\n",
      "Step 133/391, Loss: 0.1648\n",
      "Step 134/391, Loss: 0.1184\n",
      "Step 135/391, Loss: 0.0401\n",
      "Step 136/391, Loss: 0.0257\n",
      "Step 137/391, Loss: 0.0377\n",
      "Step 138/391, Loss: 0.1351\n",
      "Step 139/391, Loss: 0.0693\n",
      "Step 140/391, Loss: 0.0683\n",
      "Step 141/391, Loss: 0.1543\n",
      "Step 142/391, Loss: 0.0822\n",
      "Step 143/391, Loss: 0.1167\n",
      "Step 144/391, Loss: 0.0891\n",
      "Step 145/391, Loss: 0.0479\n",
      "Step 146/391, Loss: 0.0234\n",
      "Step 147/391, Loss: 0.1000\n",
      "Step 148/391, Loss: 0.0746\n",
      "Step 149/391, Loss: 0.0724\n",
      "Step 150/391, Loss: 0.0595\n",
      "Step 151/391, Loss: 0.1367\n",
      "Step 152/391, Loss: 0.1520\n",
      "Step 153/391, Loss: 0.0855\n",
      "Step 154/391, Loss: 0.0589\n",
      "Step 155/391, Loss: 0.0850\n",
      "Step 156/391, Loss: 0.0689\n",
      "Step 157/391, Loss: 0.0663\n",
      "Step 158/391, Loss: 0.1237\n",
      "Step 159/391, Loss: 0.1962\n",
      "Step 160/391, Loss: 0.0796\n",
      "Step 161/391, Loss: 0.0552\n",
      "Step 162/391, Loss: 0.2856\n",
      "Step 163/391, Loss: 0.0459\n",
      "Step 164/391, Loss: 0.1815\n",
      "Step 165/391, Loss: 0.1298\n",
      "Step 166/391, Loss: 0.0484\n",
      "Step 167/391, Loss: 0.1396\n",
      "Step 168/391, Loss: 0.0345\n",
      "Step 169/391, Loss: 0.0533\n",
      "Step 170/391, Loss: 0.0520\n",
      "Step 171/391, Loss: 0.2044\n",
      "Step 172/391, Loss: 0.0259\n",
      "Step 173/391, Loss: 0.0677\n",
      "Step 174/391, Loss: 0.0527\n",
      "Step 175/391, Loss: 0.0891\n",
      "Step 176/391, Loss: 0.0631\n",
      "Step 177/391, Loss: 0.2687\n",
      "Step 178/391, Loss: 0.1092\n",
      "Step 179/391, Loss: 0.1158\n",
      "Step 180/391, Loss: 0.0544\n",
      "Step 181/391, Loss: 0.0355\n",
      "Step 182/391, Loss: 0.1038\n",
      "Step 183/391, Loss: 0.1465\n",
      "Step 184/391, Loss: 0.0296\n",
      "Step 185/391, Loss: 0.0248\n",
      "Step 186/391, Loss: 0.1118\n",
      "Step 187/391, Loss: 0.1677\n",
      "Step 188/391, Loss: 0.0636\n",
      "Step 189/391, Loss: 0.1251\n",
      "Step 190/391, Loss: 0.0454\n",
      "Step 191/391, Loss: 0.0724\n",
      "Step 192/391, Loss: 0.1231\n",
      "Step 193/391, Loss: 0.0315\n",
      "Step 194/391, Loss: 0.0854\n",
      "Step 195/391, Loss: 0.0965\n",
      "Step 196/391, Loss: 0.1061\n",
      "Step 197/391, Loss: 0.0720\n",
      "Step 198/391, Loss: 0.0972\n",
      "Step 199/391, Loss: 0.0307\n",
      "Step 200/391, Loss: 0.2232\n",
      "Step 201/391, Loss: 0.0687\n",
      "Step 202/391, Loss: 0.0656\n",
      "Step 203/391, Loss: 0.0159\n",
      "Step 204/391, Loss: 0.1023\n",
      "Step 205/391, Loss: 0.0811\n",
      "Step 206/391, Loss: 0.1104\n",
      "Step 207/391, Loss: 0.1689\n",
      "Step 208/391, Loss: 0.0510\n",
      "Step 209/391, Loss: 0.0876\n",
      "Step 210/391, Loss: 0.0579\n",
      "Step 211/391, Loss: 0.1137\n",
      "Step 212/391, Loss: 0.0501\n",
      "Step 213/391, Loss: 0.0523\n",
      "Step 214/391, Loss: 0.2099\n",
      "Step 215/391, Loss: 0.0221\n",
      "Step 216/391, Loss: 0.1969\n",
      "Step 217/391, Loss: 0.0254\n",
      "Step 218/391, Loss: 0.0739\n",
      "Step 219/391, Loss: 0.0677\n",
      "Step 220/391, Loss: 0.1970\n",
      "Step 221/391, Loss: 0.1351\n",
      "Step 222/391, Loss: 0.1060\n",
      "Step 223/391, Loss: 0.1663\n",
      "Step 224/391, Loss: 0.1445\n",
      "Step 225/391, Loss: 0.0763\n",
      "Step 226/391, Loss: 0.0713\n",
      "Step 227/391, Loss: 0.0738\n",
      "Step 228/391, Loss: 0.1555\n",
      "Step 229/391, Loss: 0.0885\n",
      "Step 230/391, Loss: 0.1213\n",
      "Step 231/391, Loss: 0.0867\n",
      "Step 232/391, Loss: 0.1399\n",
      "Step 233/391, Loss: 0.1457\n",
      "Step 234/391, Loss: 0.1820\n",
      "Step 235/391, Loss: 0.1050\n",
      "Step 236/391, Loss: 0.0600\n",
      "Step 237/391, Loss: 0.1546\n",
      "Step 238/391, Loss: 0.0687\n",
      "Step 239/391, Loss: 0.0777\n",
      "Step 240/391, Loss: 0.1349\n",
      "Step 241/391, Loss: 0.0828\n",
      "Step 242/391, Loss: 0.0920\n",
      "Step 243/391, Loss: 0.0919\n",
      "Step 244/391, Loss: 0.1735\n",
      "Step 245/391, Loss: 0.1020\n",
      "Step 246/391, Loss: 0.1339\n",
      "Step 247/391, Loss: 0.0426\n",
      "Step 248/391, Loss: 0.1168\n",
      "Step 249/391, Loss: 0.0977\n",
      "Step 250/391, Loss: 0.1061\n",
      "Step 251/391, Loss: 0.0515\n",
      "Step 252/391, Loss: 0.0709\n",
      "Step 253/391, Loss: 0.1072\n",
      "Step 254/391, Loss: 0.0401\n",
      "Step 255/391, Loss: 0.1304\n",
      "Step 256/391, Loss: 0.0153\n",
      "Step 257/391, Loss: 0.0801\n",
      "Step 258/391, Loss: 0.1483\n",
      "Step 259/391, Loss: 0.1034\n",
      "Step 260/391, Loss: 0.1005\n",
      "Step 261/391, Loss: 0.0646\n",
      "Step 262/391, Loss: 0.1329\n",
      "Step 263/391, Loss: 0.0419\n",
      "Step 264/391, Loss: 0.1864\n",
      "Step 265/391, Loss: 0.0772\n",
      "Step 266/391, Loss: 0.0656\n",
      "Step 267/391, Loss: 0.1764\n",
      "Step 268/391, Loss: 0.0464\n",
      "Step 269/391, Loss: 0.1138\n",
      "Step 270/391, Loss: 0.1942\n",
      "Step 271/391, Loss: 0.0935\n",
      "Step 272/391, Loss: 0.0911\n",
      "Step 273/391, Loss: 0.0842\n",
      "Step 274/391, Loss: 0.1128\n",
      "Step 275/391, Loss: 0.0671\n",
      "Step 276/391, Loss: 0.0455\n",
      "Step 277/391, Loss: 0.0498\n",
      "Step 278/391, Loss: 0.0214\n",
      "Step 279/391, Loss: 0.0958\n",
      "Step 280/391, Loss: 0.1204\n",
      "Step 281/391, Loss: 0.0918\n",
      "Step 282/391, Loss: 0.1977\n",
      "Step 283/391, Loss: 0.0754\n",
      "Step 284/391, Loss: 0.1164\n",
      "Step 285/391, Loss: 0.1120\n",
      "Step 286/391, Loss: 0.1258\n",
      "Step 287/391, Loss: 0.0513\n",
      "Step 288/391, Loss: 0.1055\n",
      "Step 289/391, Loss: 0.0461\n",
      "Step 290/391, Loss: 0.0332\n",
      "Step 291/391, Loss: 0.0771\n",
      "Step 292/391, Loss: 0.1398\n",
      "Step 293/391, Loss: 0.0796\n",
      "Step 294/391, Loss: 0.0468\n",
      "Step 295/391, Loss: 0.1125\n",
      "Step 296/391, Loss: 0.0780\n",
      "Step 297/391, Loss: 0.0471\n",
      "Step 298/391, Loss: 0.0711\n",
      "Step 299/391, Loss: 0.0956\n",
      "Step 300/391, Loss: 0.1324\n",
      "Step 301/391, Loss: 0.0504\n",
      "Step 302/391, Loss: 0.0817\n",
      "Step 303/391, Loss: 0.0238\n",
      "Step 304/391, Loss: 0.1736\n",
      "Step 305/391, Loss: 0.1185\n",
      "Step 306/391, Loss: 0.0906\n",
      "Step 307/391, Loss: 0.0501\n",
      "Step 308/391, Loss: 0.0598\n",
      "Step 309/391, Loss: 0.1167\n",
      "Step 310/391, Loss: 0.0879\n",
      "Step 311/391, Loss: 0.0365\n",
      "Step 312/391, Loss: 0.0767\n",
      "Step 313/391, Loss: 0.0850\n",
      "Step 314/391, Loss: 0.0958\n",
      "Step 315/391, Loss: 0.1123\n",
      "Step 316/391, Loss: 0.1154\n",
      "Step 317/391, Loss: 0.1173\n",
      "Step 318/391, Loss: 0.0788\n",
      "Step 319/391, Loss: 0.1710\n",
      "Step 320/391, Loss: 0.0920\n",
      "Step 321/391, Loss: 0.1884\n",
      "Step 322/391, Loss: 0.0358\n",
      "Step 323/391, Loss: 0.1060\n",
      "Step 324/391, Loss: 0.0691\n",
      "Step 325/391, Loss: 0.1523\n",
      "Step 326/391, Loss: 0.0748\n",
      "Step 327/391, Loss: 0.1553\n",
      "Step 328/391, Loss: 0.0607\n",
      "Step 329/391, Loss: 0.0407\n",
      "Step 330/391, Loss: 0.0902\n",
      "Step 331/391, Loss: 0.1086\n",
      "Step 332/391, Loss: 0.1429\n",
      "Step 333/391, Loss: 0.1377\n",
      "Step 334/391, Loss: 0.0548\n",
      "Step 335/391, Loss: 0.0632\n",
      "Step 336/391, Loss: 0.1343\n",
      "Step 337/391, Loss: 0.0862\n",
      "Step 338/391, Loss: 0.0420\n",
      "Step 339/391, Loss: 0.0797\n",
      "Step 340/391, Loss: 0.1533\n",
      "Step 341/391, Loss: 0.1034\n",
      "Step 342/391, Loss: 0.0758\n",
      "Step 343/391, Loss: 0.0425\n",
      "Step 344/391, Loss: 0.1481\n",
      "Step 345/391, Loss: 0.0887\n",
      "Step 346/391, Loss: 0.1361\n",
      "Step 347/391, Loss: 0.1084\n",
      "Step 348/391, Loss: 0.0617\n",
      "Step 349/391, Loss: 0.0474\n",
      "Step 350/391, Loss: 0.1147\n",
      "Step 351/391, Loss: 0.0696\n",
      "Step 352/391, Loss: 0.0841\n",
      "Step 353/391, Loss: 0.0343\n",
      "Step 354/391, Loss: 0.1638\n",
      "Step 355/391, Loss: 0.0774\n",
      "Step 356/391, Loss: 0.1041\n",
      "Step 357/391, Loss: 0.0827\n",
      "Step 358/391, Loss: 0.1464\n",
      "Step 359/391, Loss: 0.1074\n",
      "Step 360/391, Loss: 0.1008\n",
      "Step 361/391, Loss: 0.0916\n",
      "Step 362/391, Loss: 0.1027\n",
      "Step 363/391, Loss: 0.0879\n",
      "Step 364/391, Loss: 0.0334\n",
      "Step 365/391, Loss: 0.1758\n",
      "Step 366/391, Loss: 0.1256\n",
      "Step 367/391, Loss: 0.0666\n",
      "Step 368/391, Loss: 0.0764\n",
      "Step 369/391, Loss: 0.1821\n",
      "Step 370/391, Loss: 0.0812\n",
      "Step 371/391, Loss: 0.1865\n",
      "Step 372/391, Loss: 0.0789\n",
      "Step 373/391, Loss: 0.1247\n",
      "Step 374/391, Loss: 0.0953\n",
      "Step 375/391, Loss: 0.1153\n",
      "Step 376/391, Loss: 0.1179\n",
      "Step 377/391, Loss: 0.0716\n",
      "Step 378/391, Loss: 0.0552\n",
      "Step 379/391, Loss: 0.1440\n",
      "Step 380/391, Loss: 0.0695\n",
      "Step 381/391, Loss: 0.1395\n",
      "Step 382/391, Loss: 0.0960\n",
      "Step 383/391, Loss: 0.0785\n",
      "Step 384/391, Loss: 0.0751\n",
      "Step 385/391, Loss: 0.1422\n",
      "Step 386/391, Loss: 0.2199\n",
      "Step 387/391, Loss: 0.0862\n",
      "Step 388/391, Loss: 0.1578\n",
      "Step 389/391, Loss: 0.0159\n",
      "Step 390/391, Loss: 0.1769\n",
      "Step 391/391, Loss: 0.2389\n",
      "Epoch 6/25, Average Train Loss: 0.0927\n",
      "Epoch 6/25, Average Validation Loss: 0.1010\n",
      "Model saved at epoch 6 with validation loss: 0.1010\n",
      "Step 1/391, Loss: 0.1222\n",
      "Step 2/391, Loss: 0.0750\n",
      "Step 3/391, Loss: 0.0518\n",
      "Step 4/391, Loss: 0.1371\n",
      "Step 5/391, Loss: 0.0789\n",
      "Step 6/391, Loss: 0.0284\n",
      "Step 7/391, Loss: 0.0487\n",
      "Step 8/391, Loss: 0.1580\n",
      "Step 9/391, Loss: 0.1256\n",
      "Step 10/391, Loss: 0.0306\n",
      "Step 11/391, Loss: 0.0929\n",
      "Step 12/391, Loss: 0.0276\n",
      "Step 13/391, Loss: 0.1395\n",
      "Step 14/391, Loss: 0.0439\n",
      "Step 15/391, Loss: 0.0806\n",
      "Step 16/391, Loss: 0.0726\n",
      "Step 17/391, Loss: 0.0204\n",
      "Step 18/391, Loss: 0.1068\n",
      "Step 19/391, Loss: 0.0777\n",
      "Step 20/391, Loss: 0.1536\n",
      "Step 21/391, Loss: 0.0862\n",
      "Step 22/391, Loss: 0.0285\n",
      "Step 23/391, Loss: 0.0685\n",
      "Step 24/391, Loss: 0.1021\n",
      "Step 25/391, Loss: 0.0826\n",
      "Step 26/391, Loss: 0.0400\n",
      "Step 27/391, Loss: 0.0962\n",
      "Step 28/391, Loss: 0.0700\n",
      "Step 29/391, Loss: 0.0915\n",
      "Step 30/391, Loss: 0.0525\n",
      "Step 31/391, Loss: 0.0702\n",
      "Step 32/391, Loss: 0.0558\n",
      "Step 33/391, Loss: 0.0844\n",
      "Step 34/391, Loss: 0.0532\n",
      "Step 35/391, Loss: 0.1061\n",
      "Step 36/391, Loss: 0.0952\n",
      "Step 37/391, Loss: 0.1247\n",
      "Step 38/391, Loss: 0.1241\n",
      "Step 39/391, Loss: 0.1067\n",
      "Step 40/391, Loss: 0.0935\n",
      "Step 41/391, Loss: 0.0532\n",
      "Step 42/391, Loss: 0.0251\n",
      "Step 43/391, Loss: 0.1063\n",
      "Step 44/391, Loss: 0.0739\n",
      "Step 45/391, Loss: 0.0628\n",
      "Step 46/391, Loss: 0.0591\n",
      "Step 47/391, Loss: 0.0664\n",
      "Step 48/391, Loss: 0.1074\n",
      "Step 49/391, Loss: 0.0669\n",
      "Step 50/391, Loss: 0.0517\n",
      "Step 51/391, Loss: 0.0271\n",
      "Step 52/391, Loss: 0.2255\n",
      "Step 53/391, Loss: 0.0832\n",
      "Step 54/391, Loss: 0.0663\n",
      "Step 55/391, Loss: 0.1023\n",
      "Step 56/391, Loss: 0.1227\n",
      "Step 57/391, Loss: 0.0618\n",
      "Step 58/391, Loss: 0.0781\n",
      "Step 59/391, Loss: 0.0900\n",
      "Step 60/391, Loss: 0.0688\n",
      "Step 61/391, Loss: 0.1486\n",
      "Step 62/391, Loss: 0.0751\n",
      "Step 63/391, Loss: 0.0437\n",
      "Step 64/391, Loss: 0.0497\n",
      "Step 65/391, Loss: 0.1443\n",
      "Step 66/391, Loss: 0.1133\n",
      "Step 67/391, Loss: 0.0468\n",
      "Step 68/391, Loss: 0.0719\n",
      "Step 69/391, Loss: 0.0920\n",
      "Step 70/391, Loss: 0.0660\n",
      "Step 71/391, Loss: 0.0299\n",
      "Step 72/391, Loss: 0.1360\n",
      "Step 73/391, Loss: 0.0818\n",
      "Step 74/391, Loss: 0.0954\n",
      "Step 75/391, Loss: 0.1390\n",
      "Step 76/391, Loss: 0.0836\n",
      "Step 77/391, Loss: 0.0426\n",
      "Step 78/391, Loss: 0.0547\n",
      "Step 79/391, Loss: 0.1335\n",
      "Step 80/391, Loss: 0.1617\n",
      "Step 81/391, Loss: 0.0792\n",
      "Step 82/391, Loss: 0.1045\n",
      "Step 83/391, Loss: 0.0352\n",
      "Step 84/391, Loss: 0.0860\n",
      "Step 85/391, Loss: 0.1020\n",
      "Step 86/391, Loss: 0.0805\n",
      "Step 87/391, Loss: 0.0464\n",
      "Step 88/391, Loss: 0.0898\n",
      "Step 89/391, Loss: 0.0630\n",
      "Step 90/391, Loss: 0.1924\n",
      "Step 91/391, Loss: 0.1252\n",
      "Step 92/391, Loss: 0.0525\n",
      "Step 93/391, Loss: 0.0735\n",
      "Step 94/391, Loss: 0.0579\n",
      "Step 95/391, Loss: 0.0929\n",
      "Step 96/391, Loss: 0.0494\n",
      "Step 97/391, Loss: 0.1353\n",
      "Step 98/391, Loss: 0.0298\n",
      "Step 99/391, Loss: 0.0928\n",
      "Step 100/391, Loss: 0.0579\n",
      "Step 101/391, Loss: 0.0364\n",
      "Step 102/391, Loss: 0.0303\n",
      "Step 103/391, Loss: 0.0437\n",
      "Step 104/391, Loss: 0.0522\n",
      "Step 105/391, Loss: 0.1700\n",
      "Step 106/391, Loss: 0.0637\n",
      "Step 107/391, Loss: 0.0546\n",
      "Step 108/391, Loss: 0.1719\n",
      "Step 109/391, Loss: 0.1846\n",
      "Step 110/391, Loss: 0.0680\n",
      "Step 111/391, Loss: 0.1388\n",
      "Step 112/391, Loss: 0.0935\n",
      "Step 113/391, Loss: 0.0222\n",
      "Step 114/391, Loss: 0.0907\n",
      "Step 115/391, Loss: 0.0835\n",
      "Step 116/391, Loss: 0.1115\n",
      "Step 117/391, Loss: 0.1496\n",
      "Step 118/391, Loss: 0.0474\n",
      "Step 119/391, Loss: 0.0440\n",
      "Step 120/391, Loss: 0.0587\n",
      "Step 121/391, Loss: 0.1350\n",
      "Step 122/391, Loss: 0.1174\n",
      "Step 123/391, Loss: 0.0447\n",
      "Step 124/391, Loss: 0.0881\n",
      "Step 125/391, Loss: 0.1235\n",
      "Step 126/391, Loss: 0.0546\n",
      "Step 127/391, Loss: 0.0982\n",
      "Step 128/391, Loss: 0.0825\n",
      "Step 129/391, Loss: 0.0944\n",
      "Step 130/391, Loss: 0.0942\n",
      "Step 131/391, Loss: 0.0783\n",
      "Step 132/391, Loss: 0.1058\n",
      "Step 133/391, Loss: 0.1285\n",
      "Step 134/391, Loss: 0.1446\n",
      "Step 135/391, Loss: 0.1122\n",
      "Step 136/391, Loss: 0.0779\n",
      "Step 137/391, Loss: 0.0431\n",
      "Step 138/391, Loss: 0.0379\n",
      "Step 139/391, Loss: 0.0634\n",
      "Step 140/391, Loss: 0.1306\n",
      "Step 141/391, Loss: 0.1545\n",
      "Step 142/391, Loss: 0.0263\n",
      "Step 143/391, Loss: 0.0926\n",
      "Step 144/391, Loss: 0.0462\n",
      "Step 145/391, Loss: 0.0513\n",
      "Step 146/391, Loss: 0.0747\n",
      "Step 147/391, Loss: 0.0884\n",
      "Step 148/391, Loss: 0.1819\n",
      "Step 149/391, Loss: 0.0518\n",
      "Step 150/391, Loss: 0.0952\n",
      "Step 151/391, Loss: 0.0379\n",
      "Step 152/391, Loss: 0.0850\n",
      "Step 153/391, Loss: 0.1404\n",
      "Step 154/391, Loss: 0.0544\n",
      "Step 155/391, Loss: 0.0516\n",
      "Step 156/391, Loss: 0.0560\n",
      "Step 157/391, Loss: 0.1644\n",
      "Step 158/391, Loss: 0.0713\n",
      "Step 159/391, Loss: 0.0681\n",
      "Step 160/391, Loss: 0.0577\n",
      "Step 161/391, Loss: 0.0576\n",
      "Step 162/391, Loss: 0.1510\n",
      "Step 163/391, Loss: 0.0702\n",
      "Step 164/391, Loss: 0.0205\n",
      "Step 165/391, Loss: 0.0911\n",
      "Step 166/391, Loss: 0.0582\n",
      "Step 167/391, Loss: 0.1603\n",
      "Step 168/391, Loss: 0.1225\n",
      "Step 169/391, Loss: 0.1858\n",
      "Step 170/391, Loss: 0.1378\n",
      "Step 171/391, Loss: 0.0655\n",
      "Step 172/391, Loss: 0.0179\n",
      "Step 173/391, Loss: 0.1660\n",
      "Step 174/391, Loss: 0.0821\n",
      "Step 175/391, Loss: 0.0341\n",
      "Step 176/391, Loss: 0.0636\n",
      "Step 177/391, Loss: 0.1635\n",
      "Step 178/391, Loss: 0.0626\n",
      "Step 179/391, Loss: 0.0366\n",
      "Step 180/391, Loss: 0.0604\n",
      "Step 181/391, Loss: 0.0707\n",
      "Step 182/391, Loss: 0.1523\n",
      "Step 183/391, Loss: 0.1339\n",
      "Step 184/391, Loss: 0.0635\n",
      "Step 185/391, Loss: 0.1209\n",
      "Step 186/391, Loss: 0.0951\n",
      "Step 187/391, Loss: 0.0996\n",
      "Step 188/391, Loss: 0.0884\n",
      "Step 189/391, Loss: 0.0176\n",
      "Step 190/391, Loss: 0.1513\n",
      "Step 191/391, Loss: 0.1281\n",
      "Step 192/391, Loss: 0.0684\n",
      "Step 193/391, Loss: 0.0400\n",
      "Step 194/391, Loss: 0.0181\n",
      "Step 195/391, Loss: 0.1869\n",
      "Step 196/391, Loss: 0.0961\n",
      "Step 197/391, Loss: 0.0382\n",
      "Step 198/391, Loss: 0.1333\n",
      "Step 199/391, Loss: 0.0403\n",
      "Step 200/391, Loss: 0.0959\n",
      "Step 201/391, Loss: 0.0377\n",
      "Step 202/391, Loss: 0.1275\n",
      "Step 203/391, Loss: 0.0925\n",
      "Step 204/391, Loss: 0.0687\n",
      "Step 205/391, Loss: 0.2152\n",
      "Step 206/391, Loss: 0.0767\n",
      "Step 207/391, Loss: 0.0752\n",
      "Step 208/391, Loss: 0.0380\n",
      "Step 209/391, Loss: 0.0782\n",
      "Step 210/391, Loss: 0.0733\n",
      "Step 211/391, Loss: 0.2468\n",
      "Step 212/391, Loss: 0.0341\n",
      "Step 213/391, Loss: 0.1594\n",
      "Step 214/391, Loss: 0.0471\n",
      "Step 215/391, Loss: 0.0364\n",
      "Step 216/391, Loss: 0.0438\n",
      "Step 217/391, Loss: 0.1443\n",
      "Step 218/391, Loss: 0.1724\n",
      "Step 219/391, Loss: 0.1309\n",
      "Step 220/391, Loss: 0.0975\n",
      "Step 221/391, Loss: 0.0426\n",
      "Step 222/391, Loss: 0.1003\n",
      "Step 223/391, Loss: 0.0553\n",
      "Step 224/391, Loss: 0.0767\n",
      "Step 225/391, Loss: 0.0744\n",
      "Step 226/391, Loss: 0.0555\n",
      "Step 227/391, Loss: 0.0957\n",
      "Step 228/391, Loss: 0.0527\n",
      "Step 229/391, Loss: 0.1462\n",
      "Step 230/391, Loss: 0.0661\n",
      "Step 231/391, Loss: 0.0744\n",
      "Step 232/391, Loss: 0.0224\n",
      "Step 233/391, Loss: 0.0467\n",
      "Step 234/391, Loss: 0.0713\n",
      "Step 235/391, Loss: 0.0494\n",
      "Step 236/391, Loss: 0.1264\n",
      "Step 237/391, Loss: 0.0543\n",
      "Step 238/391, Loss: 0.0926\n",
      "Step 239/391, Loss: 0.0311\n",
      "Step 240/391, Loss: 0.1196\n",
      "Step 241/391, Loss: 0.0743\n",
      "Step 242/391, Loss: 0.0542\n",
      "Step 243/391, Loss: 0.0932\n",
      "Step 244/391, Loss: 0.1447\n",
      "Step 245/391, Loss: 0.0291\n",
      "Step 246/391, Loss: 0.1496\n",
      "Step 247/391, Loss: 0.0779\n",
      "Step 248/391, Loss: 0.0950\n",
      "Step 249/391, Loss: 0.0577\n",
      "Step 250/391, Loss: 0.0891\n",
      "Step 251/391, Loss: 0.0536\n",
      "Step 252/391, Loss: 0.0997\n",
      "Step 253/391, Loss: 0.0696\n",
      "Step 254/391, Loss: 0.0695\n",
      "Step 255/391, Loss: 0.1120\n",
      "Step 256/391, Loss: 0.0450\n",
      "Step 257/391, Loss: 0.1067\n",
      "Step 258/391, Loss: 0.0627\n",
      "Step 259/391, Loss: 0.1111\n",
      "Step 260/391, Loss: 0.0200\n",
      "Step 261/391, Loss: 0.0977\n",
      "Step 262/391, Loss: 0.0974\n",
      "Step 263/391, Loss: 0.0315\n",
      "Step 264/391, Loss: 0.1299\n",
      "Step 265/391, Loss: 0.1059\n",
      "Step 266/391, Loss: 0.1181\n",
      "Step 267/391, Loss: 0.1307\n",
      "Step 268/391, Loss: 0.1351\n",
      "Step 269/391, Loss: 0.1028\n",
      "Step 270/391, Loss: 0.1377\n",
      "Step 271/391, Loss: 0.0339\n",
      "Step 272/391, Loss: 0.0950\n",
      "Step 273/391, Loss: 0.0573\n",
      "Step 274/391, Loss: 0.0991\n",
      "Step 275/391, Loss: 0.0434\n",
      "Step 276/391, Loss: 0.1610\n",
      "Step 277/391, Loss: 0.0923\n",
      "Step 278/391, Loss: 0.0694\n",
      "Step 279/391, Loss: 0.0561\n",
      "Step 280/391, Loss: 0.0880\n",
      "Step 281/391, Loss: 0.0518\n",
      "Step 282/391, Loss: 0.1682\n",
      "Step 283/391, Loss: 0.0926\n",
      "Step 284/391, Loss: 0.1222\n",
      "Step 285/391, Loss: 0.0644\n",
      "Step 286/391, Loss: 0.0965\n",
      "Step 287/391, Loss: 0.0307\n",
      "Step 288/391, Loss: 0.0620\n",
      "Step 289/391, Loss: 0.0603\n",
      "Step 290/391, Loss: 0.0772\n",
      "Step 291/391, Loss: 0.0686\n",
      "Step 292/391, Loss: 0.1164\n",
      "Step 293/391, Loss: 0.0591\n",
      "Step 294/391, Loss: 0.1371\n",
      "Step 295/391, Loss: 0.0816\n",
      "Step 296/391, Loss: 0.0912\n",
      "Step 297/391, Loss: 0.1364\n",
      "Step 298/391, Loss: 0.0761\n",
      "Step 299/391, Loss: 0.0839\n",
      "Step 300/391, Loss: 0.0912\n",
      "Step 301/391, Loss: 0.0291\n",
      "Step 302/391, Loss: 0.1090\n",
      "Step 303/391, Loss: 0.0304\n",
      "Step 304/391, Loss: 0.0622\n",
      "Step 305/391, Loss: 0.0236\n",
      "Step 306/391, Loss: 0.0345\n",
      "Step 307/391, Loss: 0.1020\n",
      "Step 308/391, Loss: 0.0590\n",
      "Step 309/391, Loss: 0.0334\n",
      "Step 310/391, Loss: 0.0759\n",
      "Step 311/391, Loss: 0.1444\n",
      "Step 312/391, Loss: 0.0814\n",
      "Step 313/391, Loss: 0.2062\n",
      "Step 314/391, Loss: 0.0251\n",
      "Step 315/391, Loss: 0.1197\n",
      "Step 316/391, Loss: 0.1559\n",
      "Step 317/391, Loss: 0.0377\n",
      "Step 318/391, Loss: 0.0479\n",
      "Step 319/391, Loss: 0.0999\n",
      "Step 320/391, Loss: 0.1150\n",
      "Step 321/391, Loss: 0.1003\n",
      "Step 322/391, Loss: 0.0607\n",
      "Step 323/391, Loss: 0.0408\n",
      "Step 324/391, Loss: 0.0932\n",
      "Step 325/391, Loss: 0.1002\n",
      "Step 326/391, Loss: 0.1178\n",
      "Step 327/391, Loss: 0.0145\n",
      "Step 328/391, Loss: 0.0342\n",
      "Step 329/391, Loss: 0.1676\n",
      "Step 330/391, Loss: 0.0856\n",
      "Step 331/391, Loss: 0.0696\n",
      "Step 332/391, Loss: 0.0943\n",
      "Step 333/391, Loss: 0.0961\n",
      "Step 334/391, Loss: 0.0400\n",
      "Step 335/391, Loss: 0.1129\n",
      "Step 336/391, Loss: 0.1473\n",
      "Step 337/391, Loss: 0.1181\n",
      "Step 338/391, Loss: 0.0401\n",
      "Step 339/391, Loss: 0.1258\n",
      "Step 340/391, Loss: 0.0821\n",
      "Step 341/391, Loss: 0.0847\n",
      "Step 342/391, Loss: 0.0397\n",
      "Step 343/391, Loss: 0.1773\n",
      "Step 344/391, Loss: 0.1198\n",
      "Step 345/391, Loss: 0.0772\n",
      "Step 346/391, Loss: 0.0551\n",
      "Step 347/391, Loss: 0.0629\n",
      "Step 348/391, Loss: 0.0121\n",
      "Step 349/391, Loss: 0.1575\n",
      "Step 350/391, Loss: 0.1966\n",
      "Step 351/391, Loss: 0.0745\n",
      "Step 352/391, Loss: 0.0641\n",
      "Step 353/391, Loss: 0.0886\n",
      "Step 354/391, Loss: 0.1099\n",
      "Step 355/391, Loss: 0.0960\n",
      "Step 356/391, Loss: 0.1165\n",
      "Step 357/391, Loss: 0.0554\n",
      "Step 358/391, Loss: 0.1548\n",
      "Step 359/391, Loss: 0.0901\n",
      "Step 360/391, Loss: 0.0264\n",
      "Step 361/391, Loss: 0.0986\n",
      "Step 362/391, Loss: 0.1278\n",
      "Step 363/391, Loss: 0.0728\n",
      "Step 364/391, Loss: 0.0270\n",
      "Step 365/391, Loss: 0.0854\n",
      "Step 366/391, Loss: 0.0281\n",
      "Step 367/391, Loss: 0.0456\n",
      "Step 368/391, Loss: 0.1152\n",
      "Step 369/391, Loss: 0.0836\n",
      "Step 370/391, Loss: 0.0863\n",
      "Step 371/391, Loss: 0.0618\n",
      "Step 372/391, Loss: 0.1007\n",
      "Step 373/391, Loss: 0.0554\n",
      "Step 374/391, Loss: 0.0850\n",
      "Step 375/391, Loss: 0.0531\n",
      "Step 376/391, Loss: 0.0587\n",
      "Step 377/391, Loss: 0.1568\n",
      "Step 378/391, Loss: 0.0821\n",
      "Step 379/391, Loss: 0.1190\n",
      "Step 380/391, Loss: 0.0935\n",
      "Step 381/391, Loss: 0.0493\n",
      "Step 382/391, Loss: 0.0887\n",
      "Step 383/391, Loss: 0.0533\n",
      "Step 384/391, Loss: 0.0674\n",
      "Step 385/391, Loss: 0.1564\n",
      "Step 386/391, Loss: 0.0605\n",
      "Step 387/391, Loss: 0.0327\n",
      "Step 388/391, Loss: 0.0297\n",
      "Step 389/391, Loss: 0.0530\n",
      "Step 390/391, Loss: 0.0778\n",
      "Step 391/391, Loss: 0.1522\n",
      "Epoch 7/25, Average Train Loss: 0.0859\n",
      "Epoch 7/25, Average Validation Loss: 0.0863\n",
      "Model saved at epoch 7 with validation loss: 0.0863\n",
      "Step 1/391, Loss: 0.0693\n",
      "Step 2/391, Loss: 0.0450\n",
      "Step 3/391, Loss: 0.0958\n",
      "Step 4/391, Loss: 0.0730\n",
      "Step 5/391, Loss: 0.0576\n",
      "Step 6/391, Loss: 0.1455\n",
      "Step 7/391, Loss: 0.0466\n",
      "Step 8/391, Loss: 0.0356\n",
      "Step 9/391, Loss: 0.0833\n",
      "Step 10/391, Loss: 0.0410\n",
      "Step 11/391, Loss: 0.0890\n",
      "Step 12/391, Loss: 0.0506\n",
      "Step 13/391, Loss: 0.0624\n",
      "Step 14/391, Loss: 0.1093\n",
      "Step 15/391, Loss: 0.0483\n",
      "Step 16/391, Loss: 0.0230\n",
      "Step 17/391, Loss: 0.0563\n",
      "Step 18/391, Loss: 0.0403\n",
      "Step 19/391, Loss: 0.0654\n",
      "Step 20/391, Loss: 0.0488\n",
      "Step 21/391, Loss: 0.0626\n",
      "Step 22/391, Loss: 0.0457\n",
      "Step 23/391, Loss: 0.0185\n",
      "Step 24/391, Loss: 0.0484\n",
      "Step 25/391, Loss: 0.0515\n",
      "Step 26/391, Loss: 0.0911\n",
      "Step 27/391, Loss: 0.0691\n",
      "Step 28/391, Loss: 0.1274\n",
      "Step 29/391, Loss: 0.1396\n",
      "Step 30/391, Loss: 0.0435\n",
      "Step 31/391, Loss: 0.0573\n",
      "Step 32/391, Loss: 0.0849\n",
      "Step 33/391, Loss: 0.0301\n",
      "Step 34/391, Loss: 0.0223\n",
      "Step 35/391, Loss: 0.0634\n",
      "Step 36/391, Loss: 0.0415\n",
      "Step 37/391, Loss: 0.0457\n",
      "Step 38/391, Loss: 0.0611\n",
      "Step 39/391, Loss: 0.0242\n",
      "Step 40/391, Loss: 0.0790\n",
      "Step 41/391, Loss: 0.1174\n",
      "Step 42/391, Loss: 0.0945\n",
      "Step 43/391, Loss: 0.1451\n",
      "Step 44/391, Loss: 0.0870\n",
      "Step 45/391, Loss: 0.0408\n",
      "Step 46/391, Loss: 0.1077\n",
      "Step 47/391, Loss: 0.0417\n",
      "Step 48/391, Loss: 0.0513\n",
      "Step 49/391, Loss: 0.0627\n",
      "Step 50/391, Loss: 0.0783\n",
      "Step 51/391, Loss: 0.0990\n",
      "Step 52/391, Loss: 0.0684\n",
      "Step 53/391, Loss: 0.0299\n",
      "Step 54/391, Loss: 0.0285\n",
      "Step 55/391, Loss: 0.0354\n",
      "Step 56/391, Loss: 0.0592\n",
      "Step 57/391, Loss: 0.0586\n",
      "Step 58/391, Loss: 0.0313\n",
      "Step 59/391, Loss: 0.0388\n",
      "Step 60/391, Loss: 0.0197\n",
      "Step 61/391, Loss: 0.0977\n",
      "Step 62/391, Loss: 0.0768\n",
      "Step 63/391, Loss: 0.0371\n",
      "Step 64/391, Loss: 0.1466\n",
      "Step 65/391, Loss: 0.0154\n",
      "Step 66/391, Loss: 0.1353\n",
      "Step 67/391, Loss: 0.0324\n",
      "Step 68/391, Loss: 0.0148\n",
      "Step 69/391, Loss: 0.0645\n",
      "Step 70/391, Loss: 0.1104\n",
      "Step 71/391, Loss: 0.0776\n",
      "Step 72/391, Loss: 0.1026\n",
      "Step 73/391, Loss: 0.0171\n",
      "Step 74/391, Loss: 0.0586\n",
      "Step 75/391, Loss: 0.0632\n",
      "Step 76/391, Loss: 0.1118\n",
      "Step 77/391, Loss: 0.0895\n",
      "Step 78/391, Loss: 0.0294\n",
      "Step 79/391, Loss: 0.0673\n",
      "Step 80/391, Loss: 0.1703\n",
      "Step 81/391, Loss: 0.0904\n",
      "Step 82/391, Loss: 0.1023\n",
      "Step 83/391, Loss: 0.1397\n",
      "Step 84/391, Loss: 0.0830\n",
      "Step 85/391, Loss: 0.0424\n",
      "Step 86/391, Loss: 0.0814\n",
      "Step 87/391, Loss: 0.0926\n",
      "Step 88/391, Loss: 0.0371\n",
      "Step 89/391, Loss: 0.0305\n",
      "Step 90/391, Loss: 0.0964\n",
      "Step 91/391, Loss: 0.0493\n",
      "Step 92/391, Loss: 0.1331\n",
      "Step 93/391, Loss: 0.0692\n",
      "Step 94/391, Loss: 0.0791\n",
      "Step 95/391, Loss: 0.1245\n",
      "Step 96/391, Loss: 0.0295\n",
      "Step 97/391, Loss: 0.0472\n",
      "Step 98/391, Loss: 0.0404\n",
      "Step 99/391, Loss: 0.0446\n",
      "Step 100/391, Loss: 0.0958\n",
      "Step 101/391, Loss: 0.0525\n",
      "Step 102/391, Loss: 0.1132\n",
      "Step 103/391, Loss: 0.1018\n",
      "Step 104/391, Loss: 0.0220\n",
      "Step 105/391, Loss: 0.0352\n",
      "Step 106/391, Loss: 0.0454\n",
      "Step 107/391, Loss: 0.0778\n",
      "Step 108/391, Loss: 0.0883\n",
      "Step 109/391, Loss: 0.0721\n",
      "Step 110/391, Loss: 0.1850\n",
      "Step 111/391, Loss: 0.2506\n",
      "Step 112/391, Loss: 0.0307\n",
      "Step 113/391, Loss: 0.0125\n",
      "Step 114/391, Loss: 0.0843\n",
      "Step 115/391, Loss: 0.0629\n",
      "Step 116/391, Loss: 0.1241\n",
      "Step 117/391, Loss: 0.0892\n",
      "Step 118/391, Loss: 0.0419\n",
      "Step 119/391, Loss: 0.0911\n",
      "Step 120/391, Loss: 0.0249\n",
      "Step 121/391, Loss: 0.0882\n",
      "Step 122/391, Loss: 0.0925\n",
      "Step 123/391, Loss: 0.0886\n",
      "Step 124/391, Loss: 0.0699\n",
      "Step 125/391, Loss: 0.0314\n",
      "Step 126/391, Loss: 0.0295\n",
      "Step 127/391, Loss: 0.0391\n",
      "Step 128/391, Loss: 0.0207\n",
      "Step 129/391, Loss: 0.0218\n",
      "Step 130/391, Loss: 0.0776\n",
      "Step 131/391, Loss: 0.0909\n",
      "Step 132/391, Loss: 0.1152\n",
      "Step 133/391, Loss: 0.0457\n",
      "Step 134/391, Loss: 0.0612\n",
      "Step 135/391, Loss: 0.0783\n",
      "Step 136/391, Loss: 0.1443\n",
      "Step 137/391, Loss: 0.0632\n",
      "Step 138/391, Loss: 0.1200\n",
      "Step 139/391, Loss: 0.0494\n",
      "Step 140/391, Loss: 0.0534\n",
      "Step 141/391, Loss: 0.0448\n",
      "Step 142/391, Loss: 0.0249\n",
      "Step 143/391, Loss: 0.0400\n",
      "Step 144/391, Loss: 0.0924\n",
      "Step 145/391, Loss: 0.0435\n",
      "Step 146/391, Loss: 0.0592\n",
      "Step 147/391, Loss: 0.0259\n",
      "Step 148/391, Loss: 0.0339\n",
      "Step 149/391, Loss: 0.0879\n",
      "Step 150/391, Loss: 0.1335\n",
      "Step 151/391, Loss: 0.0503\n",
      "Step 152/391, Loss: 0.1186\n",
      "Step 153/391, Loss: 0.1069\n",
      "Step 154/391, Loss: 0.1703\n",
      "Step 155/391, Loss: 0.1051\n",
      "Step 156/391, Loss: 0.0432\n",
      "Step 157/391, Loss: 0.0690\n",
      "Step 158/391, Loss: 0.0499\n",
      "Step 159/391, Loss: 0.2028\n",
      "Step 160/391, Loss: 0.1099\n",
      "Step 161/391, Loss: 0.0488\n",
      "Step 162/391, Loss: 0.0446\n",
      "Step 163/391, Loss: 0.0263\n",
      "Step 164/391, Loss: 0.0418\n",
      "Step 165/391, Loss: 0.1032\n",
      "Step 166/391, Loss: 0.1182\n",
      "Step 167/391, Loss: 0.0974\n",
      "Step 168/391, Loss: 0.0875\n",
      "Step 169/391, Loss: 0.0323\n",
      "Step 170/391, Loss: 0.0968\n",
      "Step 171/391, Loss: 0.0498\n",
      "Step 172/391, Loss: 0.0440\n",
      "Step 173/391, Loss: 0.0241\n",
      "Step 174/391, Loss: 0.0634\n",
      "Step 175/391, Loss: 0.0441\n",
      "Step 176/391, Loss: 0.1116\n",
      "Step 177/391, Loss: 0.0582\n",
      "Step 178/391, Loss: 0.1557\n",
      "Step 179/391, Loss: 0.0194\n",
      "Step 180/391, Loss: 0.0347\n",
      "Step 181/391, Loss: 0.0779\n",
      "Step 182/391, Loss: 0.0745\n",
      "Step 183/391, Loss: 0.0865\n",
      "Step 184/391, Loss: 0.0594\n",
      "Step 185/391, Loss: 0.0485\n",
      "Step 186/391, Loss: 0.0630\n",
      "Step 187/391, Loss: 0.0316\n",
      "Step 188/391, Loss: 0.0767\n",
      "Step 189/391, Loss: 0.1740\n",
      "Step 190/391, Loss: 0.0691\n",
      "Step 191/391, Loss: 0.0401\n",
      "Step 192/391, Loss: 0.1186\n",
      "Step 193/391, Loss: 0.0324\n",
      "Step 194/391, Loss: 0.1172\n",
      "Step 195/391, Loss: 0.0463\n",
      "Step 196/391, Loss: 0.0636\n",
      "Step 197/391, Loss: 0.0889\n",
      "Step 198/391, Loss: 0.0455\n",
      "Step 199/391, Loss: 0.0528\n",
      "Step 200/391, Loss: 0.0259\n",
      "Step 201/391, Loss: 0.0742\n",
      "Step 202/391, Loss: 0.0134\n",
      "Step 203/391, Loss: 0.0355\n",
      "Step 204/391, Loss: 0.1015\n",
      "Step 205/391, Loss: 0.1045\n",
      "Step 206/391, Loss: 0.0650\n",
      "Step 207/391, Loss: 0.0841\n",
      "Step 208/391, Loss: 0.0558\n",
      "Step 209/391, Loss: 0.1342\n",
      "Step 210/391, Loss: 0.0700\n",
      "Step 211/391, Loss: 0.1380\n",
      "Step 212/391, Loss: 0.0252\n",
      "Step 213/391, Loss: 0.1726\n",
      "Step 214/391, Loss: 0.0857\n",
      "Step 215/391, Loss: 0.0427\n",
      "Step 216/391, Loss: 0.1236\n",
      "Step 217/391, Loss: 0.0229\n",
      "Step 218/391, Loss: 0.0383\n",
      "Step 219/391, Loss: 0.0845\n",
      "Step 220/391, Loss: 0.0755\n",
      "Step 221/391, Loss: 0.0751\n",
      "Step 222/391, Loss: 0.1163\n",
      "Step 223/391, Loss: 0.0727\n",
      "Step 224/391, Loss: 0.1189\n",
      "Step 225/391, Loss: 0.1416\n",
      "Step 226/391, Loss: 0.0743\n",
      "Step 227/391, Loss: 0.0727\n",
      "Step 228/391, Loss: 0.0248\n",
      "Step 229/391, Loss: 0.0555\n",
      "Step 230/391, Loss: 0.0921\n",
      "Step 231/391, Loss: 0.0140\n",
      "Step 232/391, Loss: 0.0653\n",
      "Step 233/391, Loss: 0.0359\n",
      "Step 234/391, Loss: 0.0951\n",
      "Step 235/391, Loss: 0.0280\n",
      "Step 236/391, Loss: 0.1375\n",
      "Step 237/391, Loss: 0.0243\n",
      "Step 238/391, Loss: 0.0671\n",
      "Step 239/391, Loss: 0.1181\n",
      "Step 240/391, Loss: 0.1231\n",
      "Step 241/391, Loss: 0.0693\n",
      "Step 242/391, Loss: 0.0517\n",
      "Step 243/391, Loss: 0.1092\n",
      "Step 244/391, Loss: 0.1134\n",
      "Step 245/391, Loss: 0.0911\n",
      "Step 246/391, Loss: 0.0344\n",
      "Step 247/391, Loss: 0.0837\n",
      "Step 248/391, Loss: 0.0440\n",
      "Step 249/391, Loss: 0.1497\n",
      "Step 250/391, Loss: 0.0199\n",
      "Step 251/391, Loss: 0.0595\n",
      "Step 252/391, Loss: 0.0656\n",
      "Step 253/391, Loss: 0.0368\n",
      "Step 254/391, Loss: 0.0743\n",
      "Step 255/391, Loss: 0.0250\n",
      "Step 256/391, Loss: 0.1024\n",
      "Step 257/391, Loss: 0.0824\n",
      "Step 258/391, Loss: 0.0299\n",
      "Step 259/391, Loss: 0.0669\n",
      "Step 260/391, Loss: 0.0811\n",
      "Step 261/391, Loss: 0.1084\n",
      "Step 262/391, Loss: 0.0962\n",
      "Step 263/391, Loss: 0.0692\n",
      "Step 264/391, Loss: 0.0347\n",
      "Step 265/391, Loss: 0.1798\n",
      "Step 266/391, Loss: 0.1843\n",
      "Step 267/391, Loss: 0.0592\n",
      "Step 268/391, Loss: 0.0745\n",
      "Step 269/391, Loss: 0.0354\n",
      "Step 270/391, Loss: 0.0562\n",
      "Step 271/391, Loss: 0.0781\n",
      "Step 272/391, Loss: 0.1224\n",
      "Step 273/391, Loss: 0.1710\n",
      "Step 274/391, Loss: 0.1326\n",
      "Step 275/391, Loss: 0.0543\n",
      "Step 276/391, Loss: 0.1198\n",
      "Step 277/391, Loss: 0.0797\n",
      "Step 278/391, Loss: 0.0233\n",
      "Step 279/391, Loss: 0.1347\n",
      "Step 280/391, Loss: 0.0438\n",
      "Step 281/391, Loss: 0.0563\n",
      "Step 282/391, Loss: 0.1027\n",
      "Step 283/391, Loss: 0.0931\n",
      "Step 284/391, Loss: 0.0815\n",
      "Step 285/391, Loss: 0.0253\n",
      "Step 286/391, Loss: 0.0447\n",
      "Step 287/391, Loss: 0.1456\n",
      "Step 288/391, Loss: 0.1058\n",
      "Step 289/391, Loss: 0.0621\n",
      "Step 290/391, Loss: 0.1637\n",
      "Step 291/391, Loss: 0.0557\n",
      "Step 292/391, Loss: 0.0536\n",
      "Step 293/391, Loss: 0.0485\n",
      "Step 294/391, Loss: 0.0695\n",
      "Step 295/391, Loss: 0.0841\n",
      "Step 296/391, Loss: 0.1146\n",
      "Step 297/391, Loss: 0.1165\n",
      "Step 298/391, Loss: 0.1860\n",
      "Step 299/391, Loss: 0.1195\n",
      "Step 300/391, Loss: 0.0441\n",
      "Step 301/391, Loss: 0.0219\n",
      "Step 302/391, Loss: 0.0778\n",
      "Step 303/391, Loss: 0.0342\n",
      "Step 304/391, Loss: 0.0651\n",
      "Step 305/391, Loss: 0.0709\n",
      "Step 306/391, Loss: 0.0840\n",
      "Step 307/391, Loss: 0.0203\n",
      "Step 308/391, Loss: 0.0597\n",
      "Step 309/391, Loss: 0.1666\n",
      "Step 310/391, Loss: 0.0467\n",
      "Step 311/391, Loss: 0.0227\n",
      "Step 312/391, Loss: 0.0635\n",
      "Step 313/391, Loss: 0.1327\n",
      "Step 314/391, Loss: 0.0766\n",
      "Step 315/391, Loss: 0.0674\n",
      "Step 316/391, Loss: 0.0867\n",
      "Step 317/391, Loss: 0.1116\n",
      "Step 318/391, Loss: 0.0940\n",
      "Step 319/391, Loss: 0.0319\n",
      "Step 320/391, Loss: 0.0672\n",
      "Step 321/391, Loss: 0.0723\n",
      "Step 322/391, Loss: 0.0872\n",
      "Step 323/391, Loss: 0.0689\n",
      "Step 324/391, Loss: 0.1259\n",
      "Step 325/391, Loss: 0.0545\n",
      "Step 326/391, Loss: 0.0951\n",
      "Step 327/391, Loss: 0.0700\n",
      "Step 328/391, Loss: 0.0580\n",
      "Step 329/391, Loss: 0.0604\n",
      "Step 330/391, Loss: 0.0331\n",
      "Step 331/391, Loss: 0.0506\n",
      "Step 332/391, Loss: 0.0557\n",
      "Step 333/391, Loss: 0.1427\n",
      "Step 334/391, Loss: 0.1088\n",
      "Step 335/391, Loss: 0.1346\n",
      "Step 336/391, Loss: 0.1761\n",
      "Step 337/391, Loss: 0.0655\n",
      "Step 338/391, Loss: 0.0823\n",
      "Step 339/391, Loss: 0.0353\n",
      "Step 340/391, Loss: 0.0996\n",
      "Step 341/391, Loss: 0.0714\n",
      "Step 342/391, Loss: 0.0358\n",
      "Step 343/391, Loss: 0.1797\n",
      "Step 344/391, Loss: 0.0968\n",
      "Step 345/391, Loss: 0.1292\n",
      "Step 346/391, Loss: 0.1168\n",
      "Step 347/391, Loss: 0.0462\n",
      "Step 348/391, Loss: 0.1169\n",
      "Step 349/391, Loss: 0.0945\n",
      "Step 350/391, Loss: 0.1212\n",
      "Step 351/391, Loss: 0.0228\n",
      "Step 352/391, Loss: 0.1182\n",
      "Step 353/391, Loss: 0.0661\n",
      "Step 354/391, Loss: 0.0728\n",
      "Step 355/391, Loss: 0.0720\n",
      "Step 356/391, Loss: 0.0431\n",
      "Step 357/391, Loss: 0.0901\n",
      "Step 358/391, Loss: 0.0656\n",
      "Step 359/391, Loss: 0.0443\n",
      "Step 360/391, Loss: 0.0814\n",
      "Step 361/391, Loss: 0.0579\n",
      "Step 362/391, Loss: 0.0754\n",
      "Step 363/391, Loss: 0.1048\n",
      "Step 364/391, Loss: 0.0514\n",
      "Step 365/391, Loss: 0.0359\n",
      "Step 366/391, Loss: 0.0792\n",
      "Step 367/391, Loss: 0.0625\n",
      "Step 368/391, Loss: 0.0651\n",
      "Step 369/391, Loss: 0.0661\n",
      "Step 370/391, Loss: 0.0434\n",
      "Step 371/391, Loss: 0.0376\n",
      "Step 372/391, Loss: 0.0277\n",
      "Step 373/391, Loss: 0.1320\n",
      "Step 374/391, Loss: 0.0247\n",
      "Step 375/391, Loss: 0.0200\n",
      "Step 376/391, Loss: 0.1566\n",
      "Step 377/391, Loss: 0.1144\n",
      "Step 378/391, Loss: 0.0678\n",
      "Step 379/391, Loss: 0.0641\n",
      "Step 380/391, Loss: 0.0840\n",
      "Step 381/391, Loss: 0.0944\n",
      "Step 382/391, Loss: 0.1981\n",
      "Step 383/391, Loss: 0.0391\n",
      "Step 384/391, Loss: 0.0988\n",
      "Step 385/391, Loss: 0.0829\n",
      "Step 386/391, Loss: 0.1267\n",
      "Step 387/391, Loss: 0.0625\n",
      "Step 388/391, Loss: 0.0608\n",
      "Step 389/391, Loss: 0.0567\n",
      "Step 390/391, Loss: 0.0431\n",
      "Step 391/391, Loss: 0.0535\n",
      "Epoch 8/25, Average Train Loss: 0.0749\n",
      "Epoch 8/25, Average Validation Loss: 0.0798\n",
      "Model saved at epoch 8 with validation loss: 0.0798\n",
      "Step 1/391, Loss: 0.0620\n",
      "Step 2/391, Loss: 0.0480\n",
      "Step 3/391, Loss: 0.0850\n",
      "Step 4/391, Loss: 0.0622\n",
      "Step 5/391, Loss: 0.1054\n",
      "Step 6/391, Loss: 0.1049\n",
      "Step 7/391, Loss: 0.0510\n",
      "Step 8/391, Loss: 0.0952\n",
      "Step 9/391, Loss: 0.1664\n",
      "Step 10/391, Loss: 0.1244\n",
      "Step 11/391, Loss: 0.0149\n",
      "Step 12/391, Loss: 0.0825\n",
      "Step 13/391, Loss: 0.0909\n",
      "Step 14/391, Loss: 0.0669\n",
      "Step 15/391, Loss: 0.1092\n",
      "Step 16/391, Loss: 0.0847\n",
      "Step 17/391, Loss: 0.0457\n",
      "Step 18/391, Loss: 0.0417\n",
      "Step 19/391, Loss: 0.1089\n",
      "Step 20/391, Loss: 0.0335\n",
      "Step 21/391, Loss: 0.0779\n",
      "Step 22/391, Loss: 0.1409\n",
      "Step 23/391, Loss: 0.0162\n",
      "Step 24/391, Loss: 0.0597\n",
      "Step 25/391, Loss: 0.0472\n",
      "Step 26/391, Loss: 0.0383\n",
      "Step 27/391, Loss: 0.0703\n",
      "Step 28/391, Loss: 0.0569\n",
      "Step 29/391, Loss: 0.1433\n",
      "Step 30/391, Loss: 0.0132\n",
      "Step 31/391, Loss: 0.0068\n",
      "Step 32/391, Loss: 0.0419\n",
      "Step 33/391, Loss: 0.0567\n",
      "Step 34/391, Loss: 0.0628\n",
      "Step 35/391, Loss: 0.0177\n",
      "Step 36/391, Loss: 0.1052\n",
      "Step 37/391, Loss: 0.0620\n",
      "Step 38/391, Loss: 0.0668\n",
      "Step 39/391, Loss: 0.0531\n",
      "Step 40/391, Loss: 0.0384\n",
      "Step 41/391, Loss: 0.1061\n",
      "Step 42/391, Loss: 0.0780\n",
      "Step 43/391, Loss: 0.0421\n",
      "Step 44/391, Loss: 0.0720\n",
      "Step 45/391, Loss: 0.0152\n",
      "Step 46/391, Loss: 0.0454\n",
      "Step 47/391, Loss: 0.0499\n",
      "Step 48/391, Loss: 0.0423\n",
      "Step 49/391, Loss: 0.1265\n",
      "Step 50/391, Loss: 0.0391\n",
      "Step 51/391, Loss: 0.0793\n",
      "Step 52/391, Loss: 0.0576\n",
      "Step 53/391, Loss: 0.0406\n",
      "Step 54/391, Loss: 0.0796\n",
      "Step 55/391, Loss: 0.0239\n",
      "Step 56/391, Loss: 0.0157\n",
      "Step 57/391, Loss: 0.0392\n",
      "Step 58/391, Loss: 0.0475\n",
      "Step 59/391, Loss: 0.1100\n",
      "Step 60/391, Loss: 0.0902\n",
      "Step 61/391, Loss: 0.0434\n",
      "Step 62/391, Loss: 0.1106\n",
      "Step 63/391, Loss: 0.0614\n",
      "Step 64/391, Loss: 0.0712\n",
      "Step 65/391, Loss: 0.0657\n",
      "Step 66/391, Loss: 0.0532\n",
      "Step 67/391, Loss: 0.0175\n",
      "Step 68/391, Loss: 0.1303\n",
      "Step 69/391, Loss: 0.0757\n",
      "Step 70/391, Loss: 0.0675\n",
      "Step 71/391, Loss: 0.0862\n",
      "Step 72/391, Loss: 0.1074\n",
      "Step 73/391, Loss: 0.2134\n",
      "Step 74/391, Loss: 0.0382\n",
      "Step 75/391, Loss: 0.1274\n",
      "Step 76/391, Loss: 0.0916\n",
      "Step 77/391, Loss: 0.0654\n",
      "Step 78/391, Loss: 0.0676\n",
      "Step 79/391, Loss: 0.0787\n",
      "Step 80/391, Loss: 0.0558\n",
      "Step 81/391, Loss: 0.0537\n",
      "Step 82/391, Loss: 0.0288\n",
      "Step 83/391, Loss: 0.1191\n",
      "Step 84/391, Loss: 0.1021\n",
      "Step 85/391, Loss: 0.0583\n",
      "Step 86/391, Loss: 0.0150\n",
      "Step 87/391, Loss: 0.0942\n",
      "Step 88/391, Loss: 0.0248\n",
      "Step 89/391, Loss: 0.0871\n",
      "Step 90/391, Loss: 0.0361\n",
      "Step 91/391, Loss: 0.0060\n",
      "Step 92/391, Loss: 0.0912\n",
      "Step 93/391, Loss: 0.1308\n",
      "Step 94/391, Loss: 0.0265\n",
      "Step 95/391, Loss: 0.0103\n",
      "Step 96/391, Loss: 0.0811\n",
      "Step 97/391, Loss: 0.0951\n",
      "Step 98/391, Loss: 0.0712\n",
      "Step 99/391, Loss: 0.1187\n",
      "Step 100/391, Loss: 0.0641\n",
      "Step 101/391, Loss: 0.0477\n",
      "Step 102/391, Loss: 0.0647\n",
      "Step 103/391, Loss: 0.0731\n",
      "Step 104/391, Loss: 0.0615\n",
      "Step 105/391, Loss: 0.0163\n",
      "Step 106/391, Loss: 0.0343\n",
      "Step 107/391, Loss: 0.0786\n",
      "Step 108/391, Loss: 0.0526\n",
      "Step 109/391, Loss: 0.0843\n",
      "Step 110/391, Loss: 0.0081\n",
      "Step 111/391, Loss: 0.0150\n",
      "Step 112/391, Loss: 0.1020\n",
      "Step 113/391, Loss: 0.0525\n",
      "Step 114/391, Loss: 0.0924\n",
      "Step 115/391, Loss: 0.0881\n",
      "Step 116/391, Loss: 0.0156\n",
      "Step 117/391, Loss: 0.0605\n",
      "Step 118/391, Loss: 0.0608\n",
      "Step 119/391, Loss: 0.2017\n",
      "Step 120/391, Loss: 0.0133\n",
      "Step 121/391, Loss: 0.1034\n",
      "Step 122/391, Loss: 0.0520\n",
      "Step 123/391, Loss: 0.0459\n",
      "Step 124/391, Loss: 0.1876\n",
      "Step 125/391, Loss: 0.0240\n",
      "Step 126/391, Loss: 0.1184\n",
      "Step 127/391, Loss: 0.0830\n",
      "Step 128/391, Loss: 0.1134\n",
      "Step 129/391, Loss: 0.0672\n",
      "Step 130/391, Loss: 0.0924\n",
      "Step 131/391, Loss: 0.0829\n",
      "Step 132/391, Loss: 0.0779\n",
      "Step 133/391, Loss: 0.0740\n",
      "Step 134/391, Loss: 0.0472\n",
      "Step 135/391, Loss: 0.0395\n",
      "Step 136/391, Loss: 0.0453\n",
      "Step 137/391, Loss: 0.1196\n",
      "Step 138/391, Loss: 0.0795\n",
      "Step 139/391, Loss: 0.0545\n",
      "Step 140/391, Loss: 0.0749\n",
      "Step 141/391, Loss: 0.0187\n",
      "Step 142/391, Loss: 0.0578\n",
      "Step 143/391, Loss: 0.1311\n",
      "Step 144/391, Loss: 0.0830\n",
      "Step 145/391, Loss: 0.0261\n",
      "Step 146/391, Loss: 0.0975\n",
      "Step 147/391, Loss: 0.0263\n",
      "Step 148/391, Loss: 0.0255\n",
      "Step 149/391, Loss: 0.0168\n",
      "Step 150/391, Loss: 0.0799\n",
      "Step 151/391, Loss: 0.0650\n",
      "Step 152/391, Loss: 0.0095\n",
      "Step 153/391, Loss: 0.0439\n",
      "Step 154/391, Loss: 0.0428\n",
      "Step 155/391, Loss: 0.0658\n",
      "Step 156/391, Loss: 0.1409\n",
      "Step 157/391, Loss: 0.0362\n",
      "Step 158/391, Loss: 0.0588\n",
      "Step 159/391, Loss: 0.1452\n",
      "Step 160/391, Loss: 0.1324\n",
      "Step 161/391, Loss: 0.0171\n",
      "Step 162/391, Loss: 0.0994\n",
      "Step 163/391, Loss: 0.0205\n",
      "Step 164/391, Loss: 0.0822\n",
      "Step 165/391, Loss: 0.0550\n",
      "Step 166/391, Loss: 0.0714\n",
      "Step 167/391, Loss: 0.1257\n",
      "Step 168/391, Loss: 0.0913\n",
      "Step 169/391, Loss: 0.0879\n",
      "Step 170/391, Loss: 0.0840\n",
      "Step 171/391, Loss: 0.0521\n",
      "Step 172/391, Loss: 0.0235\n",
      "Step 173/391, Loss: 0.1165\n",
      "Step 174/391, Loss: 0.0320\n",
      "Step 175/391, Loss: 0.0285\n",
      "Step 176/391, Loss: 0.1702\n",
      "Step 177/391, Loss: 0.0564\n",
      "Step 178/391, Loss: 0.1404\n",
      "Step 179/391, Loss: 0.0801\n",
      "Step 180/391, Loss: 0.0973\n",
      "Step 181/391, Loss: 0.0285\n",
      "Step 182/391, Loss: 0.0349\n",
      "Step 183/391, Loss: 0.1301\n",
      "Step 184/391, Loss: 0.0648\n",
      "Step 185/391, Loss: 0.0661\n",
      "Step 186/391, Loss: 0.0939\n",
      "Step 187/391, Loss: 0.0648\n",
      "Step 188/391, Loss: 0.0043\n",
      "Step 189/391, Loss: 0.0470\n",
      "Step 190/391, Loss: 0.0808\n",
      "Step 191/391, Loss: 0.0758\n",
      "Step 192/391, Loss: 0.0758\n",
      "Step 193/391, Loss: 0.0588\n",
      "Step 194/391, Loss: 0.1996\n",
      "Step 195/391, Loss: 0.1064\n",
      "Step 196/391, Loss: 0.0486\n",
      "Step 197/391, Loss: 0.0994\n",
      "Step 198/391, Loss: 0.1900\n",
      "Step 199/391, Loss: 0.0936\n",
      "Step 200/391, Loss: 0.1395\n",
      "Step 201/391, Loss: 0.0300\n",
      "Step 202/391, Loss: 0.0729\n",
      "Step 203/391, Loss: 0.0283\n",
      "Step 204/391, Loss: 0.1274\n",
      "Step 205/391, Loss: 0.1016\n",
      "Step 206/391, Loss: 0.0909\n",
      "Step 207/391, Loss: 0.0848\n",
      "Step 208/391, Loss: 0.0661\n",
      "Step 209/391, Loss: 0.0332\n",
      "Step 210/391, Loss: 0.0591\n",
      "Step 211/391, Loss: 0.0571\n",
      "Step 212/391, Loss: 0.1410\n",
      "Step 213/391, Loss: 0.0674\n",
      "Step 214/391, Loss: 0.0623\n",
      "Step 215/391, Loss: 0.0945\n",
      "Step 216/391, Loss: 0.0551\n",
      "Step 217/391, Loss: 0.1208\n",
      "Step 218/391, Loss: 0.0644\n",
      "Step 219/391, Loss: 0.0192\n",
      "Step 220/391, Loss: 0.0584\n",
      "Step 221/391, Loss: 0.0332\n",
      "Step 222/391, Loss: 0.0474\n",
      "Step 223/391, Loss: 0.0990\n",
      "Step 224/391, Loss: 0.0757\n",
      "Step 225/391, Loss: 0.0618\n",
      "Step 226/391, Loss: 0.1817\n",
      "Step 227/391, Loss: 0.0324\n",
      "Step 228/391, Loss: 0.1068\n",
      "Step 229/391, Loss: 0.0509\n",
      "Step 230/391, Loss: 0.0462\n",
      "Step 231/391, Loss: 0.0550\n",
      "Step 232/391, Loss: 0.0974\n",
      "Step 233/391, Loss: 0.0877\n",
      "Step 234/391, Loss: 0.0186\n",
      "Step 235/391, Loss: 0.0259\n",
      "Step 236/391, Loss: 0.0443\n",
      "Step 237/391, Loss: 0.0572\n",
      "Step 238/391, Loss: 0.0578\n",
      "Step 239/391, Loss: 0.0526\n",
      "Step 240/391, Loss: 0.0682\n",
      "Step 241/391, Loss: 0.0755\n",
      "Step 242/391, Loss: 0.1152\n",
      "Step 243/391, Loss: 0.0124\n",
      "Step 244/391, Loss: 0.0571\n",
      "Step 245/391, Loss: 0.0541\n",
      "Step 246/391, Loss: 0.0826\n",
      "Step 247/391, Loss: 0.1184\n",
      "Step 248/391, Loss: 0.0338\n",
      "Step 249/391, Loss: 0.1158\n",
      "Step 250/391, Loss: 0.0284\n",
      "Step 251/391, Loss: 0.0497\n",
      "Step 252/391, Loss: 0.0170\n",
      "Step 253/391, Loss: 0.0234\n",
      "Step 254/391, Loss: 0.0492\n",
      "Step 255/391, Loss: 0.0733\n",
      "Step 256/391, Loss: 0.0897\n",
      "Step 257/391, Loss: 0.0622\n",
      "Step 258/391, Loss: 0.0202\n",
      "Step 259/391, Loss: 0.0187\n",
      "Step 260/391, Loss: 0.0482\n",
      "Step 261/391, Loss: 0.0131\n",
      "Step 262/391, Loss: 0.0101\n",
      "Step 263/391, Loss: 0.0709\n",
      "Step 264/391, Loss: 0.0294\n",
      "Step 265/391, Loss: 0.1566\n",
      "Step 266/391, Loss: 0.1068\n",
      "Step 267/391, Loss: 0.1620\n",
      "Step 268/391, Loss: 0.0225\n",
      "Step 269/391, Loss: 0.1113\n",
      "Step 270/391, Loss: 0.0787\n",
      "Step 271/391, Loss: 0.1113\n",
      "Step 272/391, Loss: 0.0287\n",
      "Step 273/391, Loss: 0.1213\n",
      "Step 274/391, Loss: 0.0830\n",
      "Step 275/391, Loss: 0.2328\n",
      "Step 276/391, Loss: 0.0264\n",
      "Step 277/391, Loss: 0.0996\n",
      "Step 278/391, Loss: 0.0976\n",
      "Step 279/391, Loss: 0.2091\n",
      "Step 280/391, Loss: 0.0761\n",
      "Step 281/391, Loss: 0.0177\n",
      "Step 282/391, Loss: 0.0530\n",
      "Step 283/391, Loss: 0.1867\n",
      "Step 284/391, Loss: 0.0561\n",
      "Step 285/391, Loss: 0.0372\n",
      "Step 286/391, Loss: 0.1465\n",
      "Step 287/391, Loss: 0.0631\n",
      "Step 288/391, Loss: 0.0802\n",
      "Step 289/391, Loss: 0.1282\n",
      "Step 290/391, Loss: 0.0781\n",
      "Step 291/391, Loss: 0.0684\n",
      "Step 292/391, Loss: 0.0937\n",
      "Step 293/391, Loss: 0.0860\n",
      "Step 294/391, Loss: 0.0474\n",
      "Step 295/391, Loss: 0.0302\n",
      "Step 296/391, Loss: 0.1905\n",
      "Step 297/391, Loss: 0.0519\n",
      "Step 298/391, Loss: 0.1233\n",
      "Step 299/391, Loss: 0.0615\n",
      "Step 300/391, Loss: 0.0793\n",
      "Step 301/391, Loss: 0.0497\n",
      "Step 302/391, Loss: 0.1096\n",
      "Step 303/391, Loss: 0.0897\n",
      "Step 304/391, Loss: 0.0553\n",
      "Step 305/391, Loss: 0.0395\n",
      "Step 306/391, Loss: 0.1166\n",
      "Step 307/391, Loss: 0.0500\n",
      "Step 308/391, Loss: 0.1307\n",
      "Step 309/391, Loss: 0.0692\n",
      "Step 310/391, Loss: 0.2789\n",
      "Step 311/391, Loss: 0.0822\n",
      "Step 312/391, Loss: 0.0402\n",
      "Step 313/391, Loss: 0.0636\n",
      "Step 314/391, Loss: 0.0482\n",
      "Step 315/391, Loss: 0.0710\n",
      "Step 316/391, Loss: 0.0777\n",
      "Step 317/391, Loss: 0.0229\n",
      "Step 318/391, Loss: 0.0398\n",
      "Step 319/391, Loss: 0.0665\n",
      "Step 320/391, Loss: 0.0236\n",
      "Step 321/391, Loss: 0.0544\n",
      "Step 322/391, Loss: 0.0587\n",
      "Step 323/391, Loss: 0.0215\n",
      "Step 324/391, Loss: 0.1102\n",
      "Step 325/391, Loss: 0.0952\n",
      "Step 326/391, Loss: 0.1429\n",
      "Step 327/391, Loss: 0.0936\n",
      "Step 328/391, Loss: 0.0641\n",
      "Step 329/391, Loss: 0.1941\n",
      "Step 330/391, Loss: 0.1331\n",
      "Step 331/391, Loss: 0.0382\n",
      "Step 332/391, Loss: 0.0549\n",
      "Step 333/391, Loss: 0.1309\n",
      "Step 334/391, Loss: 0.0362\n",
      "Step 335/391, Loss: 0.0346\n",
      "Step 336/391, Loss: 0.0592\n",
      "Step 337/391, Loss: 0.0336\n",
      "Step 338/391, Loss: 0.0586\n",
      "Step 339/391, Loss: 0.0757\n",
      "Step 340/391, Loss: 0.0603\n",
      "Step 341/391, Loss: 0.0688\n",
      "Step 342/391, Loss: 0.0603\n",
      "Step 343/391, Loss: 0.1310\n",
      "Step 344/391, Loss: 0.0136\n",
      "Step 345/391, Loss: 0.0162\n",
      "Step 346/391, Loss: 0.1050\n",
      "Step 347/391, Loss: 0.0704\n",
      "Step 348/391, Loss: 0.0277\n",
      "Step 349/391, Loss: 0.0825\n",
      "Step 350/391, Loss: 0.1202\n",
      "Step 351/391, Loss: 0.1655\n",
      "Step 352/391, Loss: 0.0197\n",
      "Step 353/391, Loss: 0.1149\n",
      "Step 354/391, Loss: 0.0470\n",
      "Step 355/391, Loss: 0.0984\n",
      "Step 356/391, Loss: 0.0181\n",
      "Step 357/391, Loss: 0.1264\n",
      "Step 358/391, Loss: 0.0357\n",
      "Step 359/391, Loss: 0.0966\n",
      "Step 360/391, Loss: 0.0567\n",
      "Step 361/391, Loss: 0.0503\n",
      "Step 362/391, Loss: 0.1109\n",
      "Step 363/391, Loss: 0.1024\n",
      "Step 364/391, Loss: 0.1133\n",
      "Step 365/391, Loss: 0.0438\n",
      "Step 366/391, Loss: 0.0226\n",
      "Step 367/391, Loss: 0.1039\n",
      "Step 368/391, Loss: 0.0510\n",
      "Step 369/391, Loss: 0.0705\n",
      "Step 370/391, Loss: 0.0543\n",
      "Step 371/391, Loss: 0.1244\n",
      "Step 372/391, Loss: 0.2085\n",
      "Step 373/391, Loss: 0.0636\n",
      "Step 374/391, Loss: 0.0244\n",
      "Step 375/391, Loss: 0.0415\n",
      "Step 376/391, Loss: 0.1110\n",
      "Step 377/391, Loss: 0.0763\n",
      "Step 378/391, Loss: 0.0820\n",
      "Step 379/391, Loss: 0.1413\n",
      "Step 380/391, Loss: 0.0907\n",
      "Step 381/391, Loss: 0.0262\n",
      "Step 382/391, Loss: 0.0722\n",
      "Step 383/391, Loss: 0.0842\n",
      "Step 384/391, Loss: 0.0606\n",
      "Step 385/391, Loss: 0.0823\n",
      "Step 386/391, Loss: 0.0976\n",
      "Step 387/391, Loss: 0.0392\n",
      "Step 388/391, Loss: 0.1273\n",
      "Step 389/391, Loss: 0.0659\n",
      "Step 390/391, Loss: 0.1350\n",
      "Step 391/391, Loss: 0.1357\n",
      "Epoch 9/25, Average Train Loss: 0.0737\n",
      "Epoch 9/25, Average Validation Loss: 0.0832\n",
      "Step 1/391, Loss: 0.2015\n",
      "Step 2/391, Loss: 0.1074\n",
      "Step 3/391, Loss: 0.0219\n",
      "Step 4/391, Loss: 0.0845\n",
      "Step 5/391, Loss: 0.1111\n",
      "Step 6/391, Loss: 0.0498\n",
      "Step 7/391, Loss: 0.0505\n",
      "Step 8/391, Loss: 0.0480\n",
      "Step 9/391, Loss: 0.0136\n",
      "Step 10/391, Loss: 0.0802\n",
      "Step 11/391, Loss: 0.0833\n",
      "Step 12/391, Loss: 0.0240\n",
      "Step 13/391, Loss: 0.0719\n",
      "Step 14/391, Loss: 0.0618\n",
      "Step 15/391, Loss: 0.1145\n",
      "Step 16/391, Loss: 0.0695\n",
      "Step 17/391, Loss: 0.0831\n",
      "Step 18/391, Loss: 0.1064\n",
      "Step 19/391, Loss: 0.0368\n",
      "Step 20/391, Loss: 0.0513\n",
      "Step 21/391, Loss: 0.1132\n",
      "Step 22/391, Loss: 0.0190\n",
      "Step 23/391, Loss: 0.0165\n",
      "Step 24/391, Loss: 0.0531\n",
      "Step 25/391, Loss: 0.0556\n",
      "Step 26/391, Loss: 0.0404\n",
      "Step 27/391, Loss: 0.1376\n",
      "Step 28/391, Loss: 0.0598\n",
      "Step 29/391, Loss: 0.0673\n",
      "Step 30/391, Loss: 0.0456\n",
      "Step 31/391, Loss: 0.0561\n",
      "Step 32/391, Loss: 0.1273\n",
      "Step 33/391, Loss: 0.1250\n",
      "Step 34/391, Loss: 0.0812\n",
      "Step 35/391, Loss: 0.0599\n",
      "Step 36/391, Loss: 0.0845\n",
      "Step 37/391, Loss: 0.0386\n",
      "Step 38/391, Loss: 0.0320\n",
      "Step 39/391, Loss: 0.0400\n",
      "Step 40/391, Loss: 0.1092\n",
      "Step 41/391, Loss: 0.0374\n",
      "Step 42/391, Loss: 0.0249\n",
      "Step 43/391, Loss: 0.0518\n",
      "Step 44/391, Loss: 0.0391\n",
      "Step 45/391, Loss: 0.0279\n",
      "Step 46/391, Loss: 0.1575\n",
      "Step 47/391, Loss: 0.0985\n",
      "Step 48/391, Loss: 0.0675\n",
      "Step 49/391, Loss: 0.1065\n",
      "Step 50/391, Loss: 0.1174\n",
      "Step 51/391, Loss: 0.0825\n",
      "Step 52/391, Loss: 0.1727\n",
      "Step 53/391, Loss: 0.0456\n",
      "Step 54/391, Loss: 0.0845\n",
      "Step 55/391, Loss: 0.0591\n",
      "Step 56/391, Loss: 0.0386\n",
      "Step 57/391, Loss: 0.1114\n",
      "Step 58/391, Loss: 0.0422\n",
      "Step 59/391, Loss: 0.0724\n",
      "Step 60/391, Loss: 0.0515\n",
      "Step 61/391, Loss: 0.0480\n",
      "Step 62/391, Loss: 0.0216\n",
      "Step 63/391, Loss: 0.1521\n",
      "Step 64/391, Loss: 0.0692\n",
      "Step 65/391, Loss: 0.0671\n",
      "Step 66/391, Loss: 0.0863\n",
      "Step 67/391, Loss: 0.1541\n",
      "Step 68/391, Loss: 0.0440\n",
      "Step 69/391, Loss: 0.0807\n",
      "Step 70/391, Loss: 0.0515\n",
      "Step 71/391, Loss: 0.0879\n",
      "Step 72/391, Loss: 0.0158\n",
      "Step 73/391, Loss: 0.0598\n",
      "Step 74/391, Loss: 0.0436\n",
      "Step 75/391, Loss: 0.0243\n",
      "Step 76/391, Loss: 0.1066\n",
      "Step 77/391, Loss: 0.0776\n",
      "Step 78/391, Loss: 0.0895\n",
      "Step 79/391, Loss: 0.2166\n",
      "Step 80/391, Loss: 0.1089\n",
      "Step 81/391, Loss: 0.0594\n",
      "Step 82/391, Loss: 0.0649\n",
      "Step 83/391, Loss: 0.0439\n",
      "Step 84/391, Loss: 0.0561\n",
      "Step 85/391, Loss: 0.1428\n",
      "Step 86/391, Loss: 0.0227\n",
      "Step 87/391, Loss: 0.0796\n",
      "Step 88/391, Loss: 0.0427\n",
      "Step 89/391, Loss: 0.0224\n",
      "Step 90/391, Loss: 0.0685\n",
      "Step 91/391, Loss: 0.0208\n",
      "Step 92/391, Loss: 0.1053\n",
      "Step 93/391, Loss: 0.0484\n",
      "Step 94/391, Loss: 0.1104\n",
      "Step 95/391, Loss: 0.0454\n",
      "Step 96/391, Loss: 0.1206\n",
      "Step 97/391, Loss: 0.0629\n",
      "Step 98/391, Loss: 0.0244\n",
      "Step 99/391, Loss: 0.0658\n",
      "Step 100/391, Loss: 0.0279\n",
      "Step 101/391, Loss: 0.0762\n",
      "Step 102/391, Loss: 0.0686\n",
      "Step 103/391, Loss: 0.0460\n",
      "Step 104/391, Loss: 0.0421\n",
      "Step 105/391, Loss: 0.0501\n",
      "Step 106/391, Loss: 0.0839\n",
      "Step 107/391, Loss: 0.0517\n",
      "Step 108/391, Loss: 0.0464\n",
      "Step 109/391, Loss: 0.0485\n",
      "Step 110/391, Loss: 0.0702\n",
      "Step 111/391, Loss: 0.1052\n",
      "Step 112/391, Loss: 0.1084\n",
      "Step 113/391, Loss: 0.0507\n",
      "Step 114/391, Loss: 0.0867\n",
      "Step 115/391, Loss: 0.0331\n",
      "Step 116/391, Loss: 0.0480\n",
      "Step 117/391, Loss: 0.0210\n",
      "Step 118/391, Loss: 0.0560\n",
      "Step 119/391, Loss: 0.0373\n",
      "Step 120/391, Loss: 0.0648\n",
      "Step 121/391, Loss: 0.0171\n",
      "Step 122/391, Loss: 0.0918\n",
      "Step 123/391, Loss: 0.0770\n",
      "Step 124/391, Loss: 0.0457\n",
      "Step 125/391, Loss: 0.0347\n",
      "Step 126/391, Loss: 0.0695\n",
      "Step 127/391, Loss: 0.0669\n",
      "Step 128/391, Loss: 0.0643\n",
      "Step 129/391, Loss: 0.0914\n",
      "Step 130/391, Loss: 0.0344\n",
      "Step 131/391, Loss: 0.0402\n",
      "Step 132/391, Loss: 0.0293\n",
      "Step 133/391, Loss: 0.0100\n",
      "Step 134/391, Loss: 0.1029\n",
      "Step 135/391, Loss: 0.0230\n",
      "Step 136/391, Loss: 0.0408\n",
      "Step 137/391, Loss: 0.0255\n",
      "Step 138/391, Loss: 0.0320\n",
      "Step 139/391, Loss: 0.0575\n",
      "Step 140/391, Loss: 0.0115\n",
      "Step 141/391, Loss: 0.0928\n",
      "Step 142/391, Loss: 0.0206\n",
      "Step 143/391, Loss: 0.1022\n",
      "Step 144/391, Loss: 0.0181\n",
      "Step 145/391, Loss: 0.0799\n",
      "Step 146/391, Loss: 0.0251\n",
      "Step 147/391, Loss: 0.0975\n",
      "Step 148/391, Loss: 0.0102\n",
      "Step 149/391, Loss: 0.0299\n",
      "Step 150/391, Loss: 0.1301\n",
      "Step 151/391, Loss: 0.0439\n",
      "Step 152/391, Loss: 0.0987\n",
      "Step 153/391, Loss: 0.0431\n",
      "Step 154/391, Loss: 0.0540\n",
      "Step 155/391, Loss: 0.0458\n",
      "Step 156/391, Loss: 0.0111\n",
      "Step 157/391, Loss: 0.0326\n",
      "Step 158/391, Loss: 0.0968\n",
      "Step 159/391, Loss: 0.0339\n",
      "Step 160/391, Loss: 0.0411\n",
      "Step 161/391, Loss: 0.0671\n",
      "Step 162/391, Loss: 0.0253\n",
      "Step 163/391, Loss: 0.0949\n",
      "Step 164/391, Loss: 0.0474\n",
      "Step 165/391, Loss: 0.0928\n",
      "Step 166/391, Loss: 0.0692\n",
      "Step 167/391, Loss: 0.0553\n",
      "Step 168/391, Loss: 0.1112\n",
      "Step 169/391, Loss: 0.0840\n",
      "Step 170/391, Loss: 0.0501\n",
      "Step 171/391, Loss: 0.1372\n",
      "Step 172/391, Loss: 0.0335\n",
      "Step 173/391, Loss: 0.0550\n",
      "Step 174/391, Loss: 0.0559\n",
      "Step 175/391, Loss: 0.0787\n",
      "Step 176/391, Loss: 0.1029\n",
      "Step 177/391, Loss: 0.0820\n",
      "Step 178/391, Loss: 0.1413\n",
      "Step 179/391, Loss: 0.0670\n",
      "Step 180/391, Loss: 0.0238\n",
      "Step 181/391, Loss: 0.1034\n",
      "Step 182/391, Loss: 0.0769\n",
      "Step 183/391, Loss: 0.0369\n",
      "Step 184/391, Loss: 0.0081\n",
      "Step 185/391, Loss: 0.1121\n",
      "Step 186/391, Loss: 0.0936\n",
      "Step 187/391, Loss: 0.0708\n",
      "Step 188/391, Loss: 0.0369\n",
      "Step 189/391, Loss: 0.0877\n",
      "Step 190/391, Loss: 0.0424\n",
      "Step 191/391, Loss: 0.1061\n",
      "Step 192/391, Loss: 0.0428\n",
      "Step 193/391, Loss: 0.0699\n",
      "Step 194/391, Loss: 0.1568\n",
      "Step 195/391, Loss: 0.1140\n",
      "Step 196/391, Loss: 0.0564\n",
      "Step 197/391, Loss: 0.0186\n",
      "Step 198/391, Loss: 0.0282\n",
      "Step 199/391, Loss: 0.0907\n",
      "Step 200/391, Loss: 0.0397\n",
      "Step 201/391, Loss: 0.0678\n",
      "Step 202/391, Loss: 0.0179\n",
      "Step 203/391, Loss: 0.1307\n",
      "Step 204/391, Loss: 0.0511\n",
      "Step 205/391, Loss: 0.0841\n",
      "Step 206/391, Loss: 0.0470\n",
      "Step 207/391, Loss: 0.1622\n",
      "Step 208/391, Loss: 0.0613\n",
      "Step 209/391, Loss: 0.0486\n",
      "Step 210/391, Loss: 0.0912\n",
      "Step 211/391, Loss: 0.1492\n",
      "Step 212/391, Loss: 0.0235\n",
      "Step 213/391, Loss: 0.0847\n",
      "Step 214/391, Loss: 0.0523\n",
      "Step 215/391, Loss: 0.1732\n",
      "Step 216/391, Loss: 0.0658\n",
      "Step 217/391, Loss: 0.2948\n",
      "Step 218/391, Loss: 0.1189\n",
      "Step 219/391, Loss: 0.0711\n",
      "Step 220/391, Loss: 0.0529\n",
      "Step 221/391, Loss: 0.0117\n",
      "Step 222/391, Loss: 0.0634\n",
      "Step 223/391, Loss: 0.0643\n",
      "Step 224/391, Loss: 0.0317\n",
      "Step 225/391, Loss: 0.1371\n",
      "Step 226/391, Loss: 0.0985\n",
      "Step 227/391, Loss: 0.0468\n",
      "Step 228/391, Loss: 0.0546\n",
      "Step 229/391, Loss: 0.0630\n",
      "Step 230/391, Loss: 0.1059\n",
      "Step 231/391, Loss: 0.0859\n",
      "Step 232/391, Loss: 0.0500\n",
      "Step 233/391, Loss: 0.0965\n",
      "Step 234/391, Loss: 0.0703\n",
      "Step 235/391, Loss: 0.0273\n",
      "Step 236/391, Loss: 0.0565\n",
      "Step 237/391, Loss: 0.1175\n",
      "Step 238/391, Loss: 0.0971\n",
      "Step 239/391, Loss: 0.0746\n",
      "Step 240/391, Loss: 0.1293\n",
      "Step 241/391, Loss: 0.0689\n",
      "Step 242/391, Loss: 0.1396\n",
      "Step 243/391, Loss: 0.0291\n",
      "Step 244/391, Loss: 0.0599\n",
      "Step 245/391, Loss: 0.0575\n",
      "Step 246/391, Loss: 0.0537\n",
      "Step 247/391, Loss: 0.1014\n",
      "Step 248/391, Loss: 0.0837\n",
      "Step 249/391, Loss: 0.0361\n",
      "Step 250/391, Loss: 0.0758\n",
      "Step 251/391, Loss: 0.1013\n",
      "Step 252/391, Loss: 0.0272\n",
      "Step 253/391, Loss: 0.0583\n",
      "Step 254/391, Loss: 0.0643\n",
      "Step 255/391, Loss: 0.0991\n",
      "Step 256/391, Loss: 0.0914\n",
      "Step 257/391, Loss: 0.0765\n",
      "Step 258/391, Loss: 0.1108\n",
      "Step 259/391, Loss: 0.0573\n",
      "Step 260/391, Loss: 0.0406\n",
      "Step 261/391, Loss: 0.0550\n",
      "Step 262/391, Loss: 0.0291\n",
      "Step 263/391, Loss: 0.0536\n",
      "Step 264/391, Loss: 0.0081\n",
      "Step 265/391, Loss: 0.0794\n",
      "Step 266/391, Loss: 0.0580\n",
      "Step 267/391, Loss: 0.0510\n",
      "Step 268/391, Loss: 0.1128\n",
      "Step 269/391, Loss: 0.0285\n",
      "Step 270/391, Loss: 0.0473\n",
      "Step 271/391, Loss: 0.1682\n",
      "Step 272/391, Loss: 0.1354\n",
      "Step 273/391, Loss: 0.0620\n",
      "Step 274/391, Loss: 0.0260\n",
      "Step 275/391, Loss: 0.0499\n",
      "Step 276/391, Loss: 0.0703\n",
      "Step 277/391, Loss: 0.1093\n",
      "Step 278/391, Loss: 0.0482\n",
      "Step 279/391, Loss: 0.1297\n",
      "Step 280/391, Loss: 0.0533\n",
      "Step 281/391, Loss: 0.0696\n",
      "Step 282/391, Loss: 0.1378\n",
      "Step 283/391, Loss: 0.0856\n",
      "Step 284/391, Loss: 0.0603\n",
      "Step 285/391, Loss: 0.0670\n",
      "Step 286/391, Loss: 0.0494\n",
      "Step 287/391, Loss: 0.0634\n",
      "Step 288/391, Loss: 0.0161\n",
      "Step 289/391, Loss: 0.1017\n",
      "Step 290/391, Loss: 0.0402\n",
      "Step 291/391, Loss: 0.0307\n",
      "Step 292/391, Loss: 0.0768\n",
      "Step 293/391, Loss: 0.0636\n",
      "Step 294/391, Loss: 0.0865\n",
      "Step 295/391, Loss: 0.0117\n",
      "Step 296/391, Loss: 0.0474\n",
      "Step 297/391, Loss: 0.0145\n",
      "Step 298/391, Loss: 0.0260\n",
      "Step 299/391, Loss: 0.0449\n",
      "Step 300/391, Loss: 0.0934\n",
      "Step 301/391, Loss: 0.0184\n",
      "Step 302/391, Loss: 0.0444\n",
      "Step 303/391, Loss: 0.0463\n",
      "Step 304/391, Loss: 0.0627\n",
      "Step 305/391, Loss: 0.0589\n",
      "Step 306/391, Loss: 0.1614\n",
      "Step 307/391, Loss: 0.0135\n",
      "Step 308/391, Loss: 0.0838\n",
      "Step 309/391, Loss: 0.0193\n",
      "Step 310/391, Loss: 0.0464\n",
      "Step 311/391, Loss: 0.0984\n",
      "Step 312/391, Loss: 0.0769\n",
      "Step 313/391, Loss: 0.1106\n",
      "Step 314/391, Loss: 0.0381\n",
      "Step 315/391, Loss: 0.0320\n",
      "Step 316/391, Loss: 0.1103\n",
      "Step 317/391, Loss: 0.0805\n",
      "Step 318/391, Loss: 0.0228\n",
      "Step 319/391, Loss: 0.1845\n",
      "Step 320/391, Loss: 0.0164\n",
      "Step 321/391, Loss: 0.1109\n",
      "Step 322/391, Loss: 0.0458\n",
      "Step 323/391, Loss: 0.0247\n",
      "Step 324/391, Loss: 0.1164\n",
      "Step 325/391, Loss: 0.1072\n",
      "Step 326/391, Loss: 0.0548\n",
      "Step 327/391, Loss: 0.0618\n",
      "Step 328/391, Loss: 0.0417\n",
      "Step 329/391, Loss: 0.0331\n",
      "Step 330/391, Loss: 0.0894\n",
      "Step 331/391, Loss: 0.0639\n",
      "Step 332/391, Loss: 0.0885\n",
      "Step 333/391, Loss: 0.0461\n",
      "Step 334/391, Loss: 0.0638\n",
      "Step 335/391, Loss: 0.0201\n",
      "Step 336/391, Loss: 0.0568\n",
      "Step 337/391, Loss: 0.0572\n",
      "Step 338/391, Loss: 0.0673\n",
      "Step 339/391, Loss: 0.0591\n",
      "Step 340/391, Loss: 0.0695\n",
      "Step 341/391, Loss: 0.1240\n",
      "Step 342/391, Loss: 0.0275\n",
      "Step 343/391, Loss: 0.0307\n",
      "Step 344/391, Loss: 0.0856\n",
      "Step 345/391, Loss: 0.0863\n",
      "Step 346/391, Loss: 0.0853\n",
      "Step 347/391, Loss: 0.1286\n",
      "Step 348/391, Loss: 0.0574\n",
      "Step 349/391, Loss: 0.0954\n",
      "Step 350/391, Loss: 0.0881\n",
      "Step 351/391, Loss: 0.0822\n",
      "Step 352/391, Loss: 0.0914\n",
      "Step 353/391, Loss: 0.0496\n",
      "Step 354/391, Loss: 0.0783\n",
      "Step 355/391, Loss: 0.1241\n",
      "Step 356/391, Loss: 0.0396\n",
      "Step 357/391, Loss: 0.0542\n",
      "Step 358/391, Loss: 0.0440\n",
      "Step 359/391, Loss: 0.0184\n",
      "Step 360/391, Loss: 0.1033\n",
      "Step 361/391, Loss: 0.0622\n",
      "Step 362/391, Loss: 0.0900\n",
      "Step 363/391, Loss: 0.0661\n",
      "Step 364/391, Loss: 0.0691\n",
      "Step 365/391, Loss: 0.0068\n",
      "Step 366/391, Loss: 0.0507\n",
      "Step 367/391, Loss: 0.0413\n",
      "Step 368/391, Loss: 0.1014\n",
      "Step 369/391, Loss: 0.0958\n",
      "Step 370/391, Loss: 0.0607\n",
      "Step 371/391, Loss: 0.0575\n",
      "Step 372/391, Loss: 0.0417\n",
      "Step 373/391, Loss: 0.0710\n",
      "Step 374/391, Loss: 0.0346\n",
      "Step 375/391, Loss: 0.0361\n",
      "Step 376/391, Loss: 0.0624\n",
      "Step 377/391, Loss: 0.0100\n",
      "Step 378/391, Loss: 0.0522\n",
      "Step 379/391, Loss: 0.0599\n",
      "Step 380/391, Loss: 0.0402\n",
      "Step 381/391, Loss: 0.0293\n",
      "Step 382/391, Loss: 0.0956\n",
      "Step 383/391, Loss: 0.1174\n",
      "Step 384/391, Loss: 0.0705\n",
      "Step 385/391, Loss: 0.0588\n",
      "Step 386/391, Loss: 0.0411\n",
      "Step 387/391, Loss: 0.0179\n",
      "Step 388/391, Loss: 0.0341\n",
      "Step 389/391, Loss: 0.0379\n",
      "Step 390/391, Loss: 0.0632\n",
      "Step 391/391, Loss: 0.0214\n",
      "Epoch 10/25, Average Train Loss: 0.0676\n",
      "Epoch 10/25, Average Validation Loss: 0.0845\n",
      "Step 1/391, Loss: 0.0526\n",
      "Step 2/391, Loss: 0.0368\n",
      "Step 3/391, Loss: 0.0434\n",
      "Step 4/391, Loss: 0.0470\n",
      "Step 5/391, Loss: 0.0505\n",
      "Step 6/391, Loss: 0.0180\n",
      "Step 7/391, Loss: 0.0514\n",
      "Step 8/391, Loss: 0.0468\n",
      "Step 9/391, Loss: 0.0747\n",
      "Step 10/391, Loss: 0.0568\n",
      "Step 11/391, Loss: 0.0366\n",
      "Step 12/391, Loss: 0.0119\n",
      "Step 13/391, Loss: 0.1081\n",
      "Step 14/391, Loss: 0.0055\n",
      "Step 15/391, Loss: 0.0667\n",
      "Step 16/391, Loss: 0.0380\n",
      "Step 17/391, Loss: 0.0712\n",
      "Step 18/391, Loss: 0.0153\n",
      "Step 19/391, Loss: 0.0712\n",
      "Step 20/391, Loss: 0.0412\n",
      "Step 21/391, Loss: 0.0757\n",
      "Step 22/391, Loss: 0.0230\n",
      "Step 23/391, Loss: 0.0275\n",
      "Step 24/391, Loss: 0.1231\n",
      "Step 25/391, Loss: 0.1000\n",
      "Step 26/391, Loss: 0.0363\n",
      "Step 27/391, Loss: 0.0571\n",
      "Step 28/391, Loss: 0.0140\n",
      "Step 29/391, Loss: 0.0921\n",
      "Step 30/391, Loss: 0.0806\n",
      "Step 31/391, Loss: 0.0611\n",
      "Step 32/391, Loss: 0.0171\n",
      "Step 33/391, Loss: 0.0620\n",
      "Step 34/391, Loss: 0.0243\n",
      "Step 35/391, Loss: 0.0957\n",
      "Step 36/391, Loss: 0.0514\n",
      "Step 37/391, Loss: 0.0291\n",
      "Step 38/391, Loss: 0.0684\n",
      "Step 39/391, Loss: 0.0055\n",
      "Step 40/391, Loss: 0.0409\n",
      "Step 41/391, Loss: 0.0675\n",
      "Step 42/391, Loss: 0.0461\n",
      "Step 43/391, Loss: 0.1139\n",
      "Step 44/391, Loss: 0.0367\n",
      "Step 45/391, Loss: 0.0269\n",
      "Step 46/391, Loss: 0.0079\n",
      "Step 47/391, Loss: 0.0716\n",
      "Step 48/391, Loss: 0.0374\n",
      "Step 49/391, Loss: 0.0590\n",
      "Step 50/391, Loss: 0.0667\n",
      "Step 51/391, Loss: 0.0864\n",
      "Step 52/391, Loss: 0.0798\n",
      "Step 53/391, Loss: 0.0430\n",
      "Step 54/391, Loss: 0.0262\n",
      "Step 55/391, Loss: 0.0715\n",
      "Step 56/391, Loss: 0.0987\n",
      "Step 57/391, Loss: 0.0287\n",
      "Step 58/391, Loss: 0.0078\n",
      "Step 59/391, Loss: 0.0569\n",
      "Step 60/391, Loss: 0.0501\n",
      "Step 61/391, Loss: 0.0247\n",
      "Step 62/391, Loss: 0.0191\n",
      "Step 63/391, Loss: 0.0660\n",
      "Step 64/391, Loss: 0.1286\n",
      "Step 65/391, Loss: 0.0478\n",
      "Step 66/391, Loss: 0.0235\n",
      "Step 67/391, Loss: 0.0240\n",
      "Step 68/391, Loss: 0.0333\n",
      "Step 69/391, Loss: 0.0773\n",
      "Step 70/391, Loss: 0.0067\n",
      "Step 71/391, Loss: 0.0068\n",
      "Step 72/391, Loss: 0.0137\n",
      "Step 73/391, Loss: 0.0662\n",
      "Step 74/391, Loss: 0.0797\n",
      "Step 75/391, Loss: 0.0881\n",
      "Step 76/391, Loss: 0.0124\n",
      "Step 77/391, Loss: 0.1054\n",
      "Step 78/391, Loss: 0.0384\n",
      "Step 79/391, Loss: 0.1202\n",
      "Step 80/391, Loss: 0.0039\n",
      "Step 81/391, Loss: 0.0246\n",
      "Step 82/391, Loss: 0.0859\n",
      "Step 83/391, Loss: 0.0354\n",
      "Step 84/391, Loss: 0.1476\n",
      "Step 85/391, Loss: 0.0257\n",
      "Step 86/391, Loss: 0.1135\n",
      "Step 87/391, Loss: 0.0273\n",
      "Step 88/391, Loss: 0.0737\n",
      "Step 89/391, Loss: 0.0596\n",
      "Step 90/391, Loss: 0.0675\n",
      "Step 91/391, Loss: 0.0938\n",
      "Step 92/391, Loss: 0.0680\n",
      "Step 93/391, Loss: 0.0710\n",
      "Step 94/391, Loss: 0.1043\n",
      "Step 95/391, Loss: 0.0772\n",
      "Step 96/391, Loss: 0.1005\n",
      "Step 97/391, Loss: 0.0794\n",
      "Step 98/391, Loss: 0.0518\n",
      "Step 99/391, Loss: 0.0692\n",
      "Step 100/391, Loss: 0.0439\n",
      "Step 101/391, Loss: 0.0149\n",
      "Step 102/391, Loss: 0.0745\n",
      "Step 103/391, Loss: 0.0768\n",
      "Step 104/391, Loss: 0.0260\n",
      "Step 105/391, Loss: 0.0761\n",
      "Step 106/391, Loss: 0.0982\n",
      "Step 107/391, Loss: 0.0622\n",
      "Step 108/391, Loss: 0.0760\n",
      "Step 109/391, Loss: 0.0760\n",
      "Step 110/391, Loss: 0.0890\n",
      "Step 111/391, Loss: 0.0175\n",
      "Step 112/391, Loss: 0.0433\n",
      "Step 113/391, Loss: 0.0124\n",
      "Step 114/391, Loss: 0.0741\n",
      "Step 115/391, Loss: 0.0634\n",
      "Step 116/391, Loss: 0.0430\n",
      "Step 117/391, Loss: 0.0916\n",
      "Step 118/391, Loss: 0.0722\n",
      "Step 119/391, Loss: 0.0166\n",
      "Step 120/391, Loss: 0.0278\n",
      "Step 121/391, Loss: 0.0487\n",
      "Step 122/391, Loss: 0.0616\n",
      "Step 123/391, Loss: 0.0340\n",
      "Step 124/391, Loss: 0.0340\n",
      "Step 125/391, Loss: 0.0760\n",
      "Step 126/391, Loss: 0.0525\n",
      "Step 127/391, Loss: 0.0777\n",
      "Step 128/391, Loss: 0.0581\n",
      "Step 129/391, Loss: 0.0760\n",
      "Step 130/391, Loss: 0.0601\n",
      "Step 131/391, Loss: 0.0357\n",
      "Step 132/391, Loss: 0.0606\n",
      "Step 133/391, Loss: 0.0395\n",
      "Step 134/391, Loss: 0.0821\n",
      "Step 135/391, Loss: 0.0484\n",
      "Step 136/391, Loss: 0.0189\n",
      "Step 137/391, Loss: 0.1185\n",
      "Step 138/391, Loss: 0.1039\n",
      "Step 139/391, Loss: 0.0979\n",
      "Step 140/391, Loss: 0.0715\n",
      "Step 141/391, Loss: 0.0240\n",
      "Step 142/391, Loss: 0.0334\n",
      "Step 143/391, Loss: 0.0468\n",
      "Step 144/391, Loss: 0.1028\n",
      "Step 145/391, Loss: 0.0183\n",
      "Step 146/391, Loss: 0.0997\n",
      "Step 147/391, Loss: 0.0405\n",
      "Step 148/391, Loss: 0.0291\n",
      "Step 149/391, Loss: 0.1361\n",
      "Step 150/391, Loss: 0.0640\n",
      "Step 151/391, Loss: 0.0468\n",
      "Step 152/391, Loss: 0.0395\n",
      "Step 153/391, Loss: 0.0181\n",
      "Step 154/391, Loss: 0.1362\n",
      "Step 155/391, Loss: 0.1080\n",
      "Step 156/391, Loss: 0.0082\n",
      "Step 157/391, Loss: 0.0677\n",
      "Step 158/391, Loss: 0.0824\n",
      "Step 159/391, Loss: 0.0450\n",
      "Step 160/391, Loss: 0.0988\n",
      "Step 161/391, Loss: 0.0334\n",
      "Step 162/391, Loss: 0.0940\n",
      "Step 163/391, Loss: 0.1120\n",
      "Step 164/391, Loss: 0.0589\n",
      "Step 165/391, Loss: 0.0348\n",
      "Step 166/391, Loss: 0.0562\n",
      "Step 167/391, Loss: 0.0182\n",
      "Step 168/391, Loss: 0.0525\n",
      "Step 169/391, Loss: 0.0732\n",
      "Step 170/391, Loss: 0.0105\n",
      "Step 171/391, Loss: 0.1322\n",
      "Step 172/391, Loss: 0.1385\n",
      "Step 173/391, Loss: 0.0539\n",
      "Step 174/391, Loss: 0.0734\n",
      "Step 175/391, Loss: 0.0540\n",
      "Step 176/391, Loss: 0.0531\n",
      "Step 177/391, Loss: 0.0634\n",
      "Step 178/391, Loss: 0.0286\n",
      "Step 179/391, Loss: 0.0849\n",
      "Step 180/391, Loss: 0.0395\n",
      "Step 181/391, Loss: 0.0661\n",
      "Step 182/391, Loss: 0.2134\n",
      "Step 183/391, Loss: 0.0224\n",
      "Step 184/391, Loss: 0.0220\n",
      "Step 185/391, Loss: 0.0419\n",
      "Step 186/391, Loss: 0.0642\n",
      "Step 187/391, Loss: 0.0644\n",
      "Step 188/391, Loss: 0.0563\n",
      "Step 189/391, Loss: 0.0544\n",
      "Step 190/391, Loss: 0.0918\n",
      "Step 191/391, Loss: 0.0577\n",
      "Step 192/391, Loss: 0.1088\n",
      "Step 193/391, Loss: 0.0704\n",
      "Step 194/391, Loss: 0.0762\n",
      "Step 195/391, Loss: 0.0345\n",
      "Step 196/391, Loss: 0.1243\n",
      "Step 197/391, Loss: 0.0444\n",
      "Step 198/391, Loss: 0.0571\n",
      "Step 199/391, Loss: 0.0755\n",
      "Step 200/391, Loss: 0.0178\n",
      "Step 201/391, Loss: 0.0590\n",
      "Step 202/391, Loss: 0.1426\n",
      "Step 203/391, Loss: 0.0480\n",
      "Step 204/391, Loss: 0.0475\n",
      "Step 205/391, Loss: 0.0656\n",
      "Step 206/391, Loss: 0.0900\n",
      "Step 207/391, Loss: 0.1367\n",
      "Step 208/391, Loss: 0.0147\n",
      "Step 209/391, Loss: 0.0491\n",
      "Step 210/391, Loss: 0.1090\n",
      "Step 211/391, Loss: 0.0058\n",
      "Step 212/391, Loss: 0.0555\n",
      "Step 213/391, Loss: 0.0617\n",
      "Step 214/391, Loss: 0.0848\n",
      "Step 215/391, Loss: 0.0274\n",
      "Step 216/391, Loss: 0.0580\n",
      "Step 217/391, Loss: 0.0994\n",
      "Step 218/391, Loss: 0.0288\n",
      "Step 219/391, Loss: 0.0589\n",
      "Step 220/391, Loss: 0.0585\n",
      "Step 221/391, Loss: 0.0184\n",
      "Step 222/391, Loss: 0.1468\n",
      "Step 223/391, Loss: 0.0456\n",
      "Step 224/391, Loss: 0.1237\n",
      "Step 225/391, Loss: 0.1088\n",
      "Step 226/391, Loss: 0.0339\n",
      "Step 227/391, Loss: 0.0870\n",
      "Step 228/391, Loss: 0.0217\n",
      "Step 229/391, Loss: 0.0823\n",
      "Step 230/391, Loss: 0.0607\n",
      "Step 231/391, Loss: 0.0874\n",
      "Step 232/391, Loss: 0.0395\n",
      "Step 233/391, Loss: 0.0899\n",
      "Step 234/391, Loss: 0.0324\n",
      "Step 235/391, Loss: 0.0368\n",
      "Step 236/391, Loss: 0.0233\n",
      "Step 237/391, Loss: 0.0506\n",
      "Step 238/391, Loss: 0.0517\n",
      "Step 239/391, Loss: 0.0446\n",
      "Step 240/391, Loss: 0.0384\n",
      "Step 241/391, Loss: 0.0349\n",
      "Step 242/391, Loss: 0.1160\n",
      "Step 243/391, Loss: 0.0422\n",
      "Step 244/391, Loss: 0.0441\n",
      "Step 245/391, Loss: 0.0201\n",
      "Step 246/391, Loss: 0.1663\n",
      "Step 247/391, Loss: 0.1137\n",
      "Step 248/391, Loss: 0.0312\n",
      "Step 249/391, Loss: 0.0216\n",
      "Step 250/391, Loss: 0.0336\n",
      "Step 251/391, Loss: 0.0497\n",
      "Step 252/391, Loss: 0.0648\n",
      "Step 253/391, Loss: 0.0617\n",
      "Step 254/391, Loss: 0.0981\n",
      "Step 255/391, Loss: 0.0239\n",
      "Step 256/391, Loss: 0.0541\n",
      "Step 257/391, Loss: 0.1333\n",
      "Step 258/391, Loss: 0.0543\n",
      "Step 259/391, Loss: 0.0502\n",
      "Step 260/391, Loss: 0.0874\n",
      "Step 261/391, Loss: 0.0286\n",
      "Step 262/391, Loss: 0.0210\n",
      "Step 263/391, Loss: 0.0897\n",
      "Step 264/391, Loss: 0.0805\n",
      "Step 265/391, Loss: 0.0936\n",
      "Step 266/391, Loss: 0.0630\n",
      "Step 267/391, Loss: 0.0680\n",
      "Step 268/391, Loss: 0.0531\n",
      "Step 269/391, Loss: 0.0419\n",
      "Step 270/391, Loss: 0.0681\n",
      "Step 271/391, Loss: 0.1215\n",
      "Step 272/391, Loss: 0.0176\n",
      "Step 273/391, Loss: 0.0907\n",
      "Step 274/391, Loss: 0.0551\n",
      "Step 275/391, Loss: 0.0418\n",
      "Step 276/391, Loss: 0.1261\n",
      "Step 277/391, Loss: 0.1303\n",
      "Step 278/391, Loss: 0.0799\n",
      "Step 279/391, Loss: 0.0331\n",
      "Step 280/391, Loss: 0.0403\n",
      "Step 281/391, Loss: 0.0315\n",
      "Step 282/391, Loss: 0.0755\n",
      "Step 283/391, Loss: 0.0243\n",
      "Step 284/391, Loss: 0.0986\n",
      "Step 285/391, Loss: 0.0383\n",
      "Step 286/391, Loss: 0.0147\n",
      "Step 287/391, Loss: 0.0361\n",
      "Step 288/391, Loss: 0.0945\n",
      "Step 289/391, Loss: 0.0520\n",
      "Step 290/391, Loss: 0.0547\n",
      "Step 291/391, Loss: 0.0625\n",
      "Step 292/391, Loss: 0.0786\n",
      "Step 293/391, Loss: 0.0327\n",
      "Step 294/391, Loss: 0.0507\n",
      "Step 295/391, Loss: 0.0604\n",
      "Step 296/391, Loss: 0.0631\n",
      "Step 297/391, Loss: 0.0608\n",
      "Step 298/391, Loss: 0.0840\n",
      "Step 299/391, Loss: 0.0600\n",
      "Step 300/391, Loss: 0.0398\n",
      "Step 301/391, Loss: 0.0307\n",
      "Step 302/391, Loss: 0.0382\n",
      "Step 303/391, Loss: 0.0912\n",
      "Step 304/391, Loss: 0.0064\n",
      "Step 305/391, Loss: 0.0569\n",
      "Step 306/391, Loss: 0.0449\n",
      "Step 307/391, Loss: 0.0753\n",
      "Step 308/391, Loss: 0.0385\n",
      "Step 309/391, Loss: 0.0531\n",
      "Step 310/391, Loss: 0.0637\n",
      "Step 311/391, Loss: 0.0641\n",
      "Step 312/391, Loss: 0.0224\n",
      "Step 313/391, Loss: 0.1203\n",
      "Step 314/391, Loss: 0.0507\n",
      "Step 315/391, Loss: 0.1043\n",
      "Step 316/391, Loss: 0.0769\n",
      "Step 317/391, Loss: 0.0846\n",
      "Step 318/391, Loss: 0.0280\n",
      "Step 319/391, Loss: 0.1305\n",
      "Step 320/391, Loss: 0.0456\n",
      "Step 321/391, Loss: 0.0359\n",
      "Step 322/391, Loss: 0.1105\n",
      "Step 323/391, Loss: 0.0896\n",
      "Step 324/391, Loss: 0.0283\n",
      "Step 325/391, Loss: 0.1187\n",
      "Step 326/391, Loss: 0.0401\n",
      "Step 327/391, Loss: 0.0442\n",
      "Step 328/391, Loss: 0.1474\n",
      "Step 329/391, Loss: 0.0674\n",
      "Step 330/391, Loss: 0.1095\n",
      "Step 331/391, Loss: 0.1127\n",
      "Step 332/391, Loss: 0.1804\n",
      "Step 333/391, Loss: 0.0862\n",
      "Step 334/391, Loss: 0.0826\n",
      "Step 335/391, Loss: 0.0298\n",
      "Step 336/391, Loss: 0.0271\n",
      "Step 337/391, Loss: 0.0367\n",
      "Step 338/391, Loss: 0.0264\n",
      "Step 339/391, Loss: 0.0497\n",
      "Step 340/391, Loss: 0.1568\n",
      "Step 341/391, Loss: 0.0175\n",
      "Step 342/391, Loss: 0.0309\n",
      "Step 343/391, Loss: 0.0544\n",
      "Step 344/391, Loss: 0.0331\n",
      "Step 345/391, Loss: 0.0672\n",
      "Step 346/391, Loss: 0.0924\n",
      "Step 347/391, Loss: 0.0751\n",
      "Step 348/391, Loss: 0.0523\n",
      "Step 349/391, Loss: 0.0698\n",
      "Step 350/391, Loss: 0.0280\n",
      "Step 351/391, Loss: 0.0362\n",
      "Step 352/391, Loss: 0.1464\n",
      "Step 353/391, Loss: 0.0365\n",
      "Step 354/391, Loss: 0.0757\n",
      "Step 355/391, Loss: 0.0534\n",
      "Step 356/391, Loss: 0.0276\n",
      "Step 357/391, Loss: 0.0206\n",
      "Step 358/391, Loss: 0.0324\n",
      "Step 359/391, Loss: 0.0750\n",
      "Step 360/391, Loss: 0.0664\n",
      "Step 361/391, Loss: 0.0444\n",
      "Step 362/391, Loss: 0.0598\n",
      "Step 363/391, Loss: 0.0682\n",
      "Step 364/391, Loss: 0.0668\n",
      "Step 365/391, Loss: 0.0742\n",
      "Step 366/391, Loss: 0.0115\n",
      "Step 367/391, Loss: 0.0526\n",
      "Step 368/391, Loss: 0.0401\n",
      "Step 369/391, Loss: 0.0863\n",
      "Step 370/391, Loss: 0.0354\n",
      "Step 371/391, Loss: 0.0625\n",
      "Step 372/391, Loss: 0.0559\n",
      "Step 373/391, Loss: 0.1177\n",
      "Step 374/391, Loss: 0.1043\n",
      "Step 375/391, Loss: 0.0946\n",
      "Step 376/391, Loss: 0.0890\n",
      "Step 377/391, Loss: 0.0645\n",
      "Step 378/391, Loss: 0.1083\n",
      "Step 379/391, Loss: 0.0256\n",
      "Step 380/391, Loss: 0.0581\n",
      "Step 381/391, Loss: 0.0702\n",
      "Step 382/391, Loss: 0.0292\n",
      "Step 383/391, Loss: 0.0559\n",
      "Step 384/391, Loss: 0.0414\n",
      "Step 385/391, Loss: 0.0876\n",
      "Step 386/391, Loss: 0.0160\n",
      "Step 387/391, Loss: 0.0388\n",
      "Step 388/391, Loss: 0.0333\n",
      "Step 389/391, Loss: 0.0110\n",
      "Step 390/391, Loss: 0.0241\n",
      "Step 391/391, Loss: 0.0503\n",
      "Epoch 11/25, Average Train Loss: 0.0607\n",
      "Epoch 11/25, Average Validation Loss: 0.0852\n",
      "Step 1/391, Loss: 0.0324\n",
      "Step 2/391, Loss: 0.0360\n",
      "Step 3/391, Loss: 0.0956\n",
      "Step 4/391, Loss: 0.0206\n",
      "Step 5/391, Loss: 0.0458\n",
      "Step 6/391, Loss: 0.0338\n",
      "Step 7/391, Loss: 0.0118\n",
      "Step 8/391, Loss: 0.0464\n",
      "Step 9/391, Loss: 0.0071\n",
      "Step 10/391, Loss: 0.0447\n",
      "Step 11/391, Loss: 0.0438\n",
      "Step 12/391, Loss: 0.0672\n",
      "Step 13/391, Loss: 0.0544\n",
      "Step 14/391, Loss: 0.0650\n",
      "Step 15/391, Loss: 0.0132\n",
      "Step 16/391, Loss: 0.0281\n",
      "Step 17/391, Loss: 0.0609\n",
      "Step 18/391, Loss: 0.0532\n",
      "Step 19/391, Loss: 0.0395\n",
      "Step 20/391, Loss: 0.0342\n",
      "Step 21/391, Loss: 0.0253\n",
      "Step 22/391, Loss: 0.0195\n",
      "Step 23/391, Loss: 0.0303\n",
      "Step 24/391, Loss: 0.0863\n",
      "Step 25/391, Loss: 0.0986\n",
      "Step 26/391, Loss: 0.0437\n",
      "Step 27/391, Loss: 0.0508\n",
      "Step 28/391, Loss: 0.0236\n",
      "Step 29/391, Loss: 0.1481\n",
      "Step 30/391, Loss: 0.0576\n",
      "Step 31/391, Loss: 0.0472\n",
      "Step 32/391, Loss: 0.0234\n",
      "Step 33/391, Loss: 0.0503\n",
      "Step 34/391, Loss: 0.0309\n",
      "Step 35/391, Loss: 0.1615\n",
      "Step 36/391, Loss: 0.0595\n",
      "Step 37/391, Loss: 0.1852\n",
      "Step 38/391, Loss: 0.0653\n",
      "Step 39/391, Loss: 0.0815\n",
      "Step 40/391, Loss: 0.0737\n",
      "Step 41/391, Loss: 0.0364\n",
      "Step 42/391, Loss: 0.0363\n",
      "Step 43/391, Loss: 0.1859\n",
      "Step 44/391, Loss: 0.0074\n",
      "Step 45/391, Loss: 0.1079\n",
      "Step 46/391, Loss: 0.0338\n",
      "Step 47/391, Loss: 0.0499\n",
      "Step 48/391, Loss: 0.0390\n",
      "Step 49/391, Loss: 0.0557\n",
      "Step 50/391, Loss: 0.0674\n",
      "Step 51/391, Loss: 0.0455\n",
      "Step 52/391, Loss: 0.0351\n",
      "Step 53/391, Loss: 0.0626\n",
      "Step 54/391, Loss: 0.0463\n",
      "Step 55/391, Loss: 0.0971\n",
      "Step 56/391, Loss: 0.0035\n",
      "Step 57/391, Loss: 0.0784\n",
      "Step 58/391, Loss: 0.0588\n",
      "Step 59/391, Loss: 0.0322\n",
      "Step 60/391, Loss: 0.0854\n",
      "Step 61/391, Loss: 0.0208\n",
      "Step 62/391, Loss: 0.0069\n",
      "Step 63/391, Loss: 0.1143\n",
      "Step 64/391, Loss: 0.0166\n",
      "Step 65/391, Loss: 0.0255\n",
      "Step 66/391, Loss: 0.0373\n",
      "Step 67/391, Loss: 0.0327\n",
      "Step 68/391, Loss: 0.0652\n",
      "Step 69/391, Loss: 0.0923\n",
      "Step 70/391, Loss: 0.0247\n",
      "Step 71/391, Loss: 0.0127\n",
      "Step 72/391, Loss: 0.0473\n",
      "Step 73/391, Loss: 0.0456\n",
      "Step 74/391, Loss: 0.0641\n",
      "Step 75/391, Loss: 0.0238\n",
      "Step 76/391, Loss: 0.0050\n",
      "Step 77/391, Loss: 0.1156\n",
      "Step 78/391, Loss: 0.0509\n",
      "Step 79/391, Loss: 0.0630\n",
      "Step 80/391, Loss: 0.0238\n",
      "Step 81/391, Loss: 0.0599\n",
      "Step 82/391, Loss: 0.1215\n",
      "Step 83/391, Loss: 0.0924\n",
      "Step 84/391, Loss: 0.0559\n",
      "Step 85/391, Loss: 0.0645\n",
      "Step 86/391, Loss: 0.0793\n",
      "Step 87/391, Loss: 0.0414\n",
      "Step 88/391, Loss: 0.0631\n",
      "Step 89/391, Loss: 0.0287\n",
      "Step 90/391, Loss: 0.0307\n",
      "Step 91/391, Loss: 0.0162\n",
      "Step 92/391, Loss: 0.0444\n",
      "Step 93/391, Loss: 0.0155\n",
      "Step 94/391, Loss: 0.0705\n",
      "Step 95/391, Loss: 0.0664\n",
      "Step 96/391, Loss: 0.0418\n",
      "Step 97/391, Loss: 0.0623\n",
      "Step 98/391, Loss: 0.0066\n",
      "Step 99/391, Loss: 0.0293\n",
      "Step 100/391, Loss: 0.0411\n",
      "Step 101/391, Loss: 0.0584\n",
      "Step 102/391, Loss: 0.0700\n",
      "Step 103/391, Loss: 0.0446\n",
      "Step 104/391, Loss: 0.0105\n",
      "Step 105/391, Loss: 0.0961\n",
      "Step 106/391, Loss: 0.0600\n",
      "Step 107/391, Loss: 0.1462\n",
      "Step 108/391, Loss: 0.0731\n",
      "Step 109/391, Loss: 0.0953\n",
      "Step 110/391, Loss: 0.0456\n",
      "Step 111/391, Loss: 0.0349\n",
      "Step 112/391, Loss: 0.0782\n",
      "Step 113/391, Loss: 0.0237\n",
      "Step 114/391, Loss: 0.0261\n",
      "Step 115/391, Loss: 0.0871\n",
      "Step 116/391, Loss: 0.0373\n",
      "Step 117/391, Loss: 0.0485\n",
      "Step 118/391, Loss: 0.0232\n",
      "Step 119/391, Loss: 0.0223\n",
      "Step 120/391, Loss: 0.0412\n",
      "Step 121/391, Loss: 0.0656\n",
      "Step 122/391, Loss: 0.1505\n",
      "Step 123/391, Loss: 0.0731\n",
      "Step 124/391, Loss: 0.0221\n",
      "Step 125/391, Loss: 0.0486\n",
      "Step 126/391, Loss: 0.0297\n",
      "Step 127/391, Loss: 0.0457\n",
      "Step 128/391, Loss: 0.0234\n",
      "Step 129/391, Loss: 0.0634\n",
      "Step 130/391, Loss: 0.0812\n",
      "Step 131/391, Loss: 0.0913\n",
      "Step 132/391, Loss: 0.0432\n",
      "Step 133/391, Loss: 0.0647\n",
      "Step 134/391, Loss: 0.0952\n",
      "Step 135/391, Loss: 0.0787\n",
      "Step 136/391, Loss: 0.0200\n",
      "Step 137/391, Loss: 0.0502\n",
      "Step 138/391, Loss: 0.0413\n",
      "Step 139/391, Loss: 0.0719\n",
      "Step 140/391, Loss: 0.1464\n",
      "Step 141/391, Loss: 0.0471\n",
      "Step 142/391, Loss: 0.0672\n",
      "Step 143/391, Loss: 0.0246\n",
      "Step 144/391, Loss: 0.0377\n",
      "Step 145/391, Loss: 0.0546\n",
      "Step 146/391, Loss: 0.0368\n",
      "Step 147/391, Loss: 0.0832\n",
      "Step 148/391, Loss: 0.0403\n",
      "Step 149/391, Loss: 0.0761\n",
      "Step 150/391, Loss: 0.0256\n",
      "Step 151/391, Loss: 0.0060\n",
      "Step 152/391, Loss: 0.0716\n",
      "Step 153/391, Loss: 0.0518\n",
      "Step 154/391, Loss: 0.0884\n",
      "Step 155/391, Loss: 0.0842\n",
      "Step 156/391, Loss: 0.0846\n",
      "Step 157/391, Loss: 0.0080\n",
      "Step 158/391, Loss: 0.0341\n",
      "Step 159/391, Loss: 0.0528\n",
      "Step 160/391, Loss: 0.0230\n",
      "Step 161/391, Loss: 0.0614\n",
      "Step 162/391, Loss: 0.0589\n",
      "Step 163/391, Loss: 0.0117\n",
      "Step 164/391, Loss: 0.0691\n",
      "Step 165/391, Loss: 0.0320\n",
      "Step 166/391, Loss: 0.1329\n",
      "Step 167/391, Loss: 0.0552\n",
      "Step 168/391, Loss: 0.0313\n",
      "Step 169/391, Loss: 0.0933\n",
      "Step 170/391, Loss: 0.0152\n",
      "Step 171/391, Loss: 0.0542\n",
      "Step 172/391, Loss: 0.0250\n",
      "Step 173/391, Loss: 0.0261\n",
      "Step 174/391, Loss: 0.0707\n",
      "Step 175/391, Loss: 0.0422\n",
      "Step 176/391, Loss: 0.0685\n",
      "Step 177/391, Loss: 0.0552\n",
      "Step 178/391, Loss: 0.0919\n",
      "Step 179/391, Loss: 0.0389\n",
      "Step 180/391, Loss: 0.0412\n",
      "Step 181/391, Loss: 0.0675\n",
      "Step 182/391, Loss: 0.0413\n",
      "Step 183/391, Loss: 0.0577\n",
      "Step 184/391, Loss: 0.0436\n",
      "Step 185/391, Loss: 0.0125\n",
      "Step 186/391, Loss: 0.0123\n",
      "Step 187/391, Loss: 0.0090\n",
      "Step 188/391, Loss: 0.0667\n",
      "Step 189/391, Loss: 0.1143\n",
      "Step 190/391, Loss: 0.0320\n",
      "Step 191/391, Loss: 0.0302\n",
      "Step 192/391, Loss: 0.0585\n",
      "Step 193/391, Loss: 0.0111\n",
      "Step 194/391, Loss: 0.1896\n",
      "Step 195/391, Loss: 0.0608\n",
      "Step 196/391, Loss: 0.0703\n",
      "Step 197/391, Loss: 0.0886\n",
      "Step 198/391, Loss: 0.0133\n",
      "Step 199/391, Loss: 0.0442\n",
      "Step 200/391, Loss: 0.1372\n",
      "Step 201/391, Loss: 0.1714\n",
      "Step 202/391, Loss: 0.0267\n",
      "Step 203/391, Loss: 0.0820\n",
      "Step 204/391, Loss: 0.1418\n",
      "Step 205/391, Loss: 0.0831\n",
      "Step 206/391, Loss: 0.0443\n",
      "Step 207/391, Loss: 0.0744\n",
      "Step 208/391, Loss: 0.0371\n",
      "Step 209/391, Loss: 0.0493\n",
      "Step 210/391, Loss: 0.1018\n",
      "Step 211/391, Loss: 0.0482\n",
      "Step 212/391, Loss: 0.0231\n",
      "Step 213/391, Loss: 0.0359\n",
      "Step 214/391, Loss: 0.1202\n",
      "Step 215/391, Loss: 0.0388\n",
      "Step 216/391, Loss: 0.0261\n",
      "Step 217/391, Loss: 0.0404\n",
      "Step 218/391, Loss: 0.0941\n",
      "Step 219/391, Loss: 0.0308\n",
      "Step 220/391, Loss: 0.0361\n",
      "Step 221/391, Loss: 0.0606\n",
      "Step 222/391, Loss: 0.0290\n",
      "Step 223/391, Loss: 0.0343\n",
      "Step 224/391, Loss: 0.1409\n",
      "Step 225/391, Loss: 0.1632\n",
      "Step 226/391, Loss: 0.0848\n",
      "Step 227/391, Loss: 0.0376\n",
      "Step 228/391, Loss: 0.0617\n",
      "Step 229/391, Loss: 0.0233\n",
      "Step 230/391, Loss: 0.0187\n",
      "Step 231/391, Loss: 0.0674\n",
      "Step 232/391, Loss: 0.0619\n",
      "Step 233/391, Loss: 0.0684\n",
      "Step 234/391, Loss: 0.1123\n",
      "Step 235/391, Loss: 0.0082\n",
      "Step 236/391, Loss: 0.0986\n",
      "Step 237/391, Loss: 0.0860\n",
      "Step 238/391, Loss: 0.0068\n",
      "Step 239/391, Loss: 0.0221\n",
      "Step 240/391, Loss: 0.0465\n",
      "Step 241/391, Loss: 0.1378\n",
      "Step 242/391, Loss: 0.0618\n",
      "Step 243/391, Loss: 0.0268\n",
      "Step 244/391, Loss: 0.1004\n",
      "Step 245/391, Loss: 0.0758\n",
      "Step 246/391, Loss: 0.0732\n",
      "Step 247/391, Loss: 0.0360\n",
      "Step 248/391, Loss: 0.1223\n",
      "Step 249/391, Loss: 0.0780\n",
      "Step 250/391, Loss: 0.0963\n",
      "Step 251/391, Loss: 0.0461\n",
      "Step 252/391, Loss: 0.0149\n",
      "Step 253/391, Loss: 0.0503\n",
      "Step 254/391, Loss: 0.1296\n",
      "Step 255/391, Loss: 0.0747\n",
      "Step 256/391, Loss: 0.0805\n",
      "Step 257/391, Loss: 0.0675\n",
      "Step 258/391, Loss: 0.1257\n",
      "Step 259/391, Loss: 0.0693\n",
      "Step 260/391, Loss: 0.0406\n",
      "Step 261/391, Loss: 0.0314\n",
      "Step 262/391, Loss: 0.1058\n",
      "Step 263/391, Loss: 0.0629\n",
      "Step 264/391, Loss: 0.0376\n",
      "Step 265/391, Loss: 0.0730\n",
      "Step 266/391, Loss: 0.0078\n",
      "Step 267/391, Loss: 0.0254\n",
      "Step 268/391, Loss: 0.0483\n",
      "Step 269/391, Loss: 0.0214\n",
      "Step 270/391, Loss: 0.0587\n",
      "Step 271/391, Loss: 0.0765\n",
      "Step 272/391, Loss: 0.1429\n",
      "Step 273/391, Loss: 0.0294\n",
      "Step 274/391, Loss: 0.1153\n",
      "Step 275/391, Loss: 0.0180\n",
      "Step 276/391, Loss: 0.0461\n",
      "Step 277/391, Loss: 0.0467\n",
      "Step 278/391, Loss: 0.0395\n",
      "Step 279/391, Loss: 0.1140\n",
      "Step 280/391, Loss: 0.0189\n",
      "Step 281/391, Loss: 0.0735\n",
      "Step 282/391, Loss: 0.0605\n",
      "Step 283/391, Loss: 0.0867\n",
      "Step 284/391, Loss: 0.1035\n",
      "Step 285/391, Loss: 0.0143\n",
      "Step 286/391, Loss: 0.0547\n",
      "Step 287/391, Loss: 0.0590\n",
      "Step 288/391, Loss: 0.0802\n",
      "Step 289/391, Loss: 0.0415\n",
      "Step 290/391, Loss: 0.0536\n",
      "Step 291/391, Loss: 0.0107\n",
      "Step 292/391, Loss: 0.0748\n",
      "Step 293/391, Loss: 0.0543\n",
      "Step 294/391, Loss: 0.0704\n",
      "Step 295/391, Loss: 0.0353\n",
      "Step 296/391, Loss: 0.0534\n",
      "Step 297/391, Loss: 0.0551\n",
      "Step 298/391, Loss: 0.0631\n",
      "Step 299/391, Loss: 0.0727\n",
      "Step 300/391, Loss: 0.0516\n",
      "Step 301/391, Loss: 0.0206\n",
      "Step 302/391, Loss: 0.0491\n",
      "Step 303/391, Loss: 0.1240\n",
      "Step 304/391, Loss: 0.0446\n",
      "Step 305/391, Loss: 0.0353\n",
      "Step 306/391, Loss: 0.1069\n",
      "Step 307/391, Loss: 0.0647\n",
      "Step 308/391, Loss: 0.0326\n",
      "Step 309/391, Loss: 0.0383\n",
      "Step 310/391, Loss: 0.0335\n",
      "Step 311/391, Loss: 0.0387\n",
      "Step 312/391, Loss: 0.0836\n",
      "Step 313/391, Loss: 0.0183\n",
      "Step 314/391, Loss: 0.0637\n",
      "Step 315/391, Loss: 0.0307\n",
      "Step 316/391, Loss: 0.0352\n",
      "Step 317/391, Loss: 0.0202\n",
      "Step 318/391, Loss: 0.0647\n",
      "Step 319/391, Loss: 0.0100\n",
      "Step 320/391, Loss: 0.0739\n",
      "Step 321/391, Loss: 0.0408\n",
      "Step 322/391, Loss: 0.0512\n",
      "Step 323/391, Loss: 0.0547\n",
      "Step 324/391, Loss: 0.0460\n",
      "Step 325/391, Loss: 0.0551\n",
      "Step 326/391, Loss: 0.0336\n",
      "Step 327/391, Loss: 0.0579\n",
      "Step 328/391, Loss: 0.0403\n",
      "Step 329/391, Loss: 0.0091\n",
      "Step 330/391, Loss: 0.2257\n",
      "Step 331/391, Loss: 0.0406\n",
      "Step 332/391, Loss: 0.0601\n",
      "Step 333/391, Loss: 0.0503\n",
      "Step 334/391, Loss: 0.0957\n",
      "Step 335/391, Loss: 0.1118\n",
      "Step 336/391, Loss: 0.0387\n",
      "Step 337/391, Loss: 0.1481\n",
      "Step 338/391, Loss: 0.0736\n",
      "Step 339/391, Loss: 0.0226\n",
      "Step 340/391, Loss: 0.1062\n",
      "Step 341/391, Loss: 0.0420\n",
      "Step 342/391, Loss: 0.0635\n",
      "Step 343/391, Loss: 0.0824\n",
      "Step 344/391, Loss: 0.0272\n",
      "Step 345/391, Loss: 0.0524\n",
      "Step 346/391, Loss: 0.0202\n",
      "Step 347/391, Loss: 0.0086\n",
      "Step 348/391, Loss: 0.1812\n",
      "Step 349/391, Loss: 0.0204\n",
      "Step 350/391, Loss: 0.0612\n",
      "Step 351/391, Loss: 0.0353\n",
      "Step 352/391, Loss: 0.0258\n",
      "Step 353/391, Loss: 0.1078\n",
      "Step 354/391, Loss: 0.0397\n",
      "Step 355/391, Loss: 0.0675\n",
      "Step 356/391, Loss: 0.0723\n",
      "Step 357/391, Loss: 0.1323\n",
      "Step 358/391, Loss: 0.0408\n",
      "Step 359/391, Loss: 0.0304\n",
      "Step 360/391, Loss: 0.0821\n",
      "Step 361/391, Loss: 0.1235\n",
      "Step 362/391, Loss: 0.1491\n",
      "Step 363/391, Loss: 0.0991\n",
      "Step 364/391, Loss: 0.0232\n",
      "Step 365/391, Loss: 0.0274\n",
      "Step 366/391, Loss: 0.0192\n",
      "Step 367/391, Loss: 0.1011\n",
      "Step 368/391, Loss: 0.0308\n",
      "Step 369/391, Loss: 0.1123\n",
      "Step 370/391, Loss: 0.0505\n",
      "Step 371/391, Loss: 0.0597\n",
      "Step 372/391, Loss: 0.0284\n",
      "Step 373/391, Loss: 0.0873\n",
      "Step 374/391, Loss: 0.0377\n",
      "Step 375/391, Loss: 0.0780\n",
      "Step 376/391, Loss: 0.0310\n",
      "Step 377/391, Loss: 0.1069\n",
      "Step 378/391, Loss: 0.0857\n",
      "Step 379/391, Loss: 0.0970\n",
      "Step 380/391, Loss: 0.0386\n",
      "Step 381/391, Loss: 0.0327\n",
      "Step 382/391, Loss: 0.0485\n",
      "Step 383/391, Loss: 0.0501\n",
      "Step 384/391, Loss: 0.1009\n",
      "Step 385/391, Loss: 0.0330\n",
      "Step 386/391, Loss: 0.1080\n",
      "Step 387/391, Loss: 0.0203\n",
      "Step 388/391, Loss: 0.0377\n",
      "Step 389/391, Loss: 0.1148\n",
      "Step 390/391, Loss: 0.0541\n",
      "Step 391/391, Loss: 0.0634\n",
      "Epoch 12/25, Average Train Loss: 0.0585\n",
      "Epoch 12/25, Average Validation Loss: 0.0786\n",
      "Model saved at epoch 12 with validation loss: 0.0786\n",
      "Step 1/391, Loss: 0.0826\n",
      "Step 2/391, Loss: 0.0136\n",
      "Step 3/391, Loss: 0.0297\n",
      "Step 4/391, Loss: 0.1082\n",
      "Step 5/391, Loss: 0.0381\n",
      "Step 6/391, Loss: 0.0564\n",
      "Step 7/391, Loss: 0.0388\n",
      "Step 8/391, Loss: 0.0178\n",
      "Step 9/391, Loss: 0.1505\n",
      "Step 10/391, Loss: 0.0926\n",
      "Step 11/391, Loss: 0.1726\n",
      "Step 12/391, Loss: 0.0672\n",
      "Step 13/391, Loss: 0.0115\n",
      "Step 14/391, Loss: 0.0268\n",
      "Step 15/391, Loss: 0.0506\n",
      "Step 16/391, Loss: 0.0594\n",
      "Step 17/391, Loss: 0.0247\n",
      "Step 18/391, Loss: 0.0875\n",
      "Step 19/391, Loss: 0.0184\n",
      "Step 20/391, Loss: 0.0239\n",
      "Step 21/391, Loss: 0.0330\n",
      "Step 22/391, Loss: 0.0521\n",
      "Step 23/391, Loss: 0.0221\n",
      "Step 24/391, Loss: 0.0473\n",
      "Step 25/391, Loss: 0.0322\n",
      "Step 26/391, Loss: 0.1180\n",
      "Step 27/391, Loss: 0.0447\n",
      "Step 28/391, Loss: 0.0511\n",
      "Step 29/391, Loss: 0.0556\n",
      "Step 30/391, Loss: 0.0868\n",
      "Step 31/391, Loss: 0.0600\n",
      "Step 32/391, Loss: 0.0506\n",
      "Step 33/391, Loss: 0.0629\n",
      "Step 34/391, Loss: 0.0554\n",
      "Step 35/391, Loss: 0.0320\n",
      "Step 36/391, Loss: 0.0240\n",
      "Step 37/391, Loss: 0.0858\n",
      "Step 38/391, Loss: 0.0550\n",
      "Step 39/391, Loss: 0.0189\n",
      "Step 40/391, Loss: 0.0954\n",
      "Step 41/391, Loss: 0.0944\n",
      "Step 42/391, Loss: 0.0352\n",
      "Step 43/391, Loss: 0.0355\n",
      "Step 44/391, Loss: 0.0250\n",
      "Step 45/391, Loss: 0.0371\n",
      "Step 46/391, Loss: 0.0768\n",
      "Step 47/391, Loss: 0.1274\n",
      "Step 48/391, Loss: 0.0113\n",
      "Step 49/391, Loss: 0.1337\n",
      "Step 50/391, Loss: 0.1121\n",
      "Step 51/391, Loss: 0.0945\n",
      "Step 52/391, Loss: 0.0729\n",
      "Step 53/391, Loss: 0.1074\n",
      "Step 54/391, Loss: 0.0347\n",
      "Step 55/391, Loss: 0.0241\n",
      "Step 56/391, Loss: 0.0193\n",
      "Step 57/391, Loss: 0.0338\n",
      "Step 58/391, Loss: 0.0527\n",
      "Step 59/391, Loss: 0.0234\n",
      "Step 60/391, Loss: 0.1079\n",
      "Step 61/391, Loss: 0.0534\n",
      "Step 62/391, Loss: 0.1053\n",
      "Step 63/391, Loss: 0.0284\n",
      "Step 64/391, Loss: 0.0260\n",
      "Step 65/391, Loss: 0.0479\n",
      "Step 66/391, Loss: 0.0178\n",
      "Step 67/391, Loss: 0.0404\n",
      "Step 68/391, Loss: 0.0706\n",
      "Step 69/391, Loss: 0.0265\n",
      "Step 70/391, Loss: 0.0661\n",
      "Step 71/391, Loss: 0.0700\n",
      "Step 72/391, Loss: 0.0272\n",
      "Step 73/391, Loss: 0.0557\n",
      "Step 74/391, Loss: 0.0989\n",
      "Step 75/391, Loss: 0.0775\n",
      "Step 76/391, Loss: 0.0350\n",
      "Step 77/391, Loss: 0.0877\n",
      "Step 78/391, Loss: 0.0677\n",
      "Step 79/391, Loss: 0.0385\n",
      "Step 80/391, Loss: 0.1147\n",
      "Step 81/391, Loss: 0.0621\n",
      "Step 82/391, Loss: 0.0130\n",
      "Step 83/391, Loss: 0.0732\n",
      "Step 84/391, Loss: 0.0567\n",
      "Step 85/391, Loss: 0.0190\n",
      "Step 86/391, Loss: 0.0132\n",
      "Step 87/391, Loss: 0.0499\n",
      "Step 88/391, Loss: 0.0425\n",
      "Step 89/391, Loss: 0.0906\n",
      "Step 90/391, Loss: 0.0336\n",
      "Step 91/391, Loss: 0.0069\n",
      "Step 92/391, Loss: 0.0718\n",
      "Step 93/391, Loss: 0.0561\n",
      "Step 94/391, Loss: 0.0140\n",
      "Step 95/391, Loss: 0.0430\n",
      "Step 96/391, Loss: 0.1076\n",
      "Step 97/391, Loss: 0.0323\n",
      "Step 98/391, Loss: 0.0587\n",
      "Step 99/391, Loss: 0.0723\n",
      "Step 100/391, Loss: 0.0280\n",
      "Step 101/391, Loss: 0.0804\n",
      "Step 102/391, Loss: 0.0141\n",
      "Step 103/391, Loss: 0.0685\n",
      "Step 104/391, Loss: 0.0618\n",
      "Step 105/391, Loss: 0.0111\n",
      "Step 106/391, Loss: 0.1058\n",
      "Step 107/391, Loss: 0.0168\n",
      "Step 108/391, Loss: 0.0636\n",
      "Step 109/391, Loss: 0.0244\n",
      "Step 110/391, Loss: 0.0938\n",
      "Step 111/391, Loss: 0.0350\n",
      "Step 112/391, Loss: 0.0370\n",
      "Step 113/391, Loss: 0.1125\n",
      "Step 114/391, Loss: 0.1284\n",
      "Step 115/391, Loss: 0.0791\n",
      "Step 116/391, Loss: 0.1036\n",
      "Step 117/391, Loss: 0.0368\n",
      "Step 118/391, Loss: 0.0419\n",
      "Step 119/391, Loss: 0.0089\n",
      "Step 120/391, Loss: 0.1070\n",
      "Step 121/391, Loss: 0.0384\n",
      "Step 122/391, Loss: 0.0448\n",
      "Step 123/391, Loss: 0.0175\n",
      "Step 124/391, Loss: 0.0210\n",
      "Step 125/391, Loss: 0.1054\n",
      "Step 126/391, Loss: 0.0352\n",
      "Step 127/391, Loss: 0.0626\n",
      "Step 128/391, Loss: 0.0783\n",
      "Step 129/391, Loss: 0.0680\n",
      "Step 130/391, Loss: 0.0686\n",
      "Step 131/391, Loss: 0.0450\n",
      "Step 132/391, Loss: 0.0321\n",
      "Step 133/391, Loss: 0.0258\n",
      "Step 134/391, Loss: 0.0370\n",
      "Step 135/391, Loss: 0.0709\n",
      "Step 136/391, Loss: 0.0482\n",
      "Step 137/391, Loss: 0.0145\n",
      "Step 138/391, Loss: 0.0130\n",
      "Step 139/391, Loss: 0.0735\n",
      "Step 140/391, Loss: 0.0794\n",
      "Step 141/391, Loss: 0.0890\n",
      "Step 142/391, Loss: 0.1069\n",
      "Step 143/391, Loss: 0.1247\n",
      "Step 144/391, Loss: 0.0668\n",
      "Step 145/391, Loss: 0.0685\n",
      "Step 146/391, Loss: 0.0360\n",
      "Step 147/391, Loss: 0.0052\n",
      "Step 148/391, Loss: 0.0433\n",
      "Step 149/391, Loss: 0.0660\n",
      "Step 150/391, Loss: 0.0638\n",
      "Step 151/391, Loss: 0.0707\n",
      "Step 152/391, Loss: 0.0719\n",
      "Step 153/391, Loss: 0.1034\n",
      "Step 154/391, Loss: 0.0294\n",
      "Step 155/391, Loss: 0.0287\n",
      "Step 156/391, Loss: 0.0590\n",
      "Step 157/391, Loss: 0.0564\n",
      "Step 158/391, Loss: 0.0365\n",
      "Step 159/391, Loss: 0.0147\n",
      "Step 160/391, Loss: 0.1429\n",
      "Step 161/391, Loss: 0.0265\n",
      "Step 162/391, Loss: 0.0389\n",
      "Step 163/391, Loss: 0.2034\n",
      "Step 164/391, Loss: 0.1055\n",
      "Step 165/391, Loss: 0.0583\n",
      "Step 166/391, Loss: 0.0037\n",
      "Step 167/391, Loss: 0.0260\n",
      "Step 168/391, Loss: 0.0627\n",
      "Step 169/391, Loss: 0.0687\n",
      "Step 170/391, Loss: 0.0388\n",
      "Step 171/391, Loss: 0.1574\n",
      "Step 172/391, Loss: 0.0483\n",
      "Step 173/391, Loss: 0.0674\n",
      "Step 174/391, Loss: 0.0627\n",
      "Step 175/391, Loss: 0.0208\n",
      "Step 176/391, Loss: 0.0149\n",
      "Step 177/391, Loss: 0.0825\n",
      "Step 178/391, Loss: 0.0497\n",
      "Step 179/391, Loss: 0.0144\n",
      "Step 180/391, Loss: 0.0837\n",
      "Step 181/391, Loss: 0.0351\n",
      "Step 182/391, Loss: 0.0218\n",
      "Step 183/391, Loss: 0.1034\n",
      "Step 184/391, Loss: 0.0814\n",
      "Step 185/391, Loss: 0.0589\n",
      "Step 186/391, Loss: 0.0436\n",
      "Step 187/391, Loss: 0.0988\n",
      "Step 188/391, Loss: 0.0969\n",
      "Step 189/391, Loss: 0.0090\n",
      "Step 190/391, Loss: 0.0227\n",
      "Step 191/391, Loss: 0.0408\n",
      "Step 192/391, Loss: 0.0556\n",
      "Step 193/391, Loss: 0.0738\n",
      "Step 194/391, Loss: 0.0240\n",
      "Step 195/391, Loss: 0.1206\n",
      "Step 196/391, Loss: 0.0545\n",
      "Step 197/391, Loss: 0.0891\n",
      "Step 198/391, Loss: 0.0367\n",
      "Step 199/391, Loss: 0.0715\n",
      "Step 200/391, Loss: 0.0819\n",
      "Step 201/391, Loss: 0.0317\n",
      "Step 202/391, Loss: 0.0669\n",
      "Step 203/391, Loss: 0.0963\n",
      "Step 204/391, Loss: 0.0623\n",
      "Step 205/391, Loss: 0.0165\n",
      "Step 206/391, Loss: 0.0279\n",
      "Step 207/391, Loss: 0.0217\n",
      "Step 208/391, Loss: 0.0055\n",
      "Step 209/391, Loss: 0.0662\n",
      "Step 210/391, Loss: 0.0596\n",
      "Step 211/391, Loss: 0.0578\n",
      "Step 212/391, Loss: 0.0854\n",
      "Step 213/391, Loss: 0.0722\n",
      "Step 214/391, Loss: 0.0469\n",
      "Step 215/391, Loss: 0.0757\n",
      "Step 216/391, Loss: 0.1101\n",
      "Step 217/391, Loss: 0.0694\n",
      "Step 218/391, Loss: 0.0349\n",
      "Step 219/391, Loss: 0.0558\n",
      "Step 220/391, Loss: 0.1935\n",
      "Step 221/391, Loss: 0.2676\n",
      "Step 222/391, Loss: 0.0951\n",
      "Step 223/391, Loss: 0.1140\n",
      "Step 224/391, Loss: 0.0175\n",
      "Step 225/391, Loss: 0.0707\n",
      "Step 226/391, Loss: 0.0517\n",
      "Step 227/391, Loss: 0.0264\n",
      "Step 228/391, Loss: 0.0333\n",
      "Step 229/391, Loss: 0.0823\n",
      "Step 230/391, Loss: 0.1144\n",
      "Step 231/391, Loss: 0.0310\n",
      "Step 232/391, Loss: 0.0239\n",
      "Step 233/391, Loss: 0.1521\n",
      "Step 234/391, Loss: 0.0774\n",
      "Step 235/391, Loss: 0.0761\n",
      "Step 236/391, Loss: 0.1111\n",
      "Step 237/391, Loss: 0.1243\n",
      "Step 238/391, Loss: 0.0602\n",
      "Step 239/391, Loss: 0.0567\n",
      "Step 240/391, Loss: 0.0842\n",
      "Step 241/391, Loss: 0.0607\n",
      "Step 242/391, Loss: 0.0163\n",
      "Step 243/391, Loss: 0.0566\n",
      "Step 244/391, Loss: 0.1285\n",
      "Step 245/391, Loss: 0.0445\n",
      "Step 246/391, Loss: 0.0292\n",
      "Step 247/391, Loss: 0.0740\n",
      "Step 248/391, Loss: 0.0475\n",
      "Step 249/391, Loss: 0.1187\n",
      "Step 250/391, Loss: 0.0172\n",
      "Step 251/391, Loss: 0.1369\n",
      "Step 252/391, Loss: 0.0767\n",
      "Step 253/391, Loss: 0.0139\n",
      "Step 254/391, Loss: 0.0830\n",
      "Step 255/391, Loss: 0.0279\n",
      "Step 256/391, Loss: 0.0116\n",
      "Step 257/391, Loss: 0.0440\n",
      "Step 258/391, Loss: 0.0184\n",
      "Step 259/391, Loss: 0.0372\n",
      "Step 260/391, Loss: 0.0636\n",
      "Step 261/391, Loss: 0.0809\n",
      "Step 262/391, Loss: 0.0592\n",
      "Step 263/391, Loss: 0.0199\n",
      "Step 264/391, Loss: 0.0841\n",
      "Step 265/391, Loss: 0.0527\n",
      "Step 266/391, Loss: 0.0485\n",
      "Step 267/391, Loss: 0.0618\n",
      "Step 268/391, Loss: 0.0299\n",
      "Step 269/391, Loss: 0.0627\n",
      "Step 270/391, Loss: 0.0670\n",
      "Step 271/391, Loss: 0.0188\n",
      "Step 272/391, Loss: 0.0504\n",
      "Step 273/391, Loss: 0.0508\n",
      "Step 274/391, Loss: 0.0763\n",
      "Step 275/391, Loss: 0.0226\n",
      "Step 276/391, Loss: 0.0087\n",
      "Step 277/391, Loss: 0.0245\n",
      "Step 278/391, Loss: 0.0460\n",
      "Step 279/391, Loss: 0.0420\n",
      "Step 280/391, Loss: 0.0514\n",
      "Step 281/391, Loss: 0.1079\n",
      "Step 282/391, Loss: 0.0181\n",
      "Step 283/391, Loss: 0.0107\n",
      "Step 284/391, Loss: 0.0198\n",
      "Step 285/391, Loss: 0.0123\n",
      "Step 286/391, Loss: 0.0529\n",
      "Step 287/391, Loss: 0.0105\n",
      "Step 288/391, Loss: 0.0372\n",
      "Step 289/391, Loss: 0.0506\n",
      "Step 290/391, Loss: 0.0249\n",
      "Step 291/391, Loss: 0.1078\n",
      "Step 292/391, Loss: 0.0489\n",
      "Step 293/391, Loss: 0.0514\n",
      "Step 294/391, Loss: 0.0423\n",
      "Step 295/391, Loss: 0.0476\n",
      "Step 296/391, Loss: 0.0647\n",
      "Step 297/391, Loss: 0.0224\n",
      "Step 298/391, Loss: 0.1102\n",
      "Step 299/391, Loss: 0.1031\n",
      "Step 300/391, Loss: 0.0092\n",
      "Step 301/391, Loss: 0.0793\n",
      "Step 302/391, Loss: 0.0926\n",
      "Step 303/391, Loss: 0.1444\n",
      "Step 304/391, Loss: 0.1011\n",
      "Step 305/391, Loss: 0.0221\n",
      "Step 306/391, Loss: 0.0289\n",
      "Step 307/391, Loss: 0.0635\n",
      "Step 308/391, Loss: 0.0526\n",
      "Step 309/391, Loss: 0.0738\n",
      "Step 310/391, Loss: 0.0220\n",
      "Step 311/391, Loss: 0.0324\n",
      "Step 312/391, Loss: 0.1200\n",
      "Step 313/391, Loss: 0.0656\n",
      "Step 314/391, Loss: 0.0409\n",
      "Step 315/391, Loss: 0.0215\n",
      "Step 316/391, Loss: 0.0543\n",
      "Step 317/391, Loss: 0.0331\n",
      "Step 318/391, Loss: 0.0944\n",
      "Step 319/391, Loss: 0.1075\n",
      "Step 320/391, Loss: 0.0612\n",
      "Step 321/391, Loss: 0.0379\n",
      "Step 322/391, Loss: 0.0436\n",
      "Step 323/391, Loss: 0.0535\n",
      "Step 324/391, Loss: 0.0941\n",
      "Step 325/391, Loss: 0.0282\n",
      "Step 326/391, Loss: 0.0558\n",
      "Step 327/391, Loss: 0.0318\n",
      "Step 328/391, Loss: 0.0731\n",
      "Step 329/391, Loss: 0.0429\n",
      "Step 330/391, Loss: 0.0521\n",
      "Step 331/391, Loss: 0.0497\n",
      "Step 332/391, Loss: 0.0276\n",
      "Step 333/391, Loss: 0.0205\n",
      "Step 334/391, Loss: 0.1007\n",
      "Step 335/391, Loss: 0.0738\n",
      "Step 336/391, Loss: 0.0232\n",
      "Step 337/391, Loss: 0.0129\n",
      "Step 338/391, Loss: 0.0498\n",
      "Step 339/391, Loss: 0.1350\n",
      "Step 340/391, Loss: 0.0972\n",
      "Step 341/391, Loss: 0.0799\n",
      "Step 342/391, Loss: 0.0244\n",
      "Step 343/391, Loss: 0.0215\n",
      "Step 344/391, Loss: 0.0919\n",
      "Step 345/391, Loss: 0.1656\n",
      "Step 346/391, Loss: 0.0173\n",
      "Step 347/391, Loss: 0.0727\n",
      "Step 348/391, Loss: 0.0065\n",
      "Step 349/391, Loss: 0.0672\n",
      "Step 350/391, Loss: 0.0568\n",
      "Step 351/391, Loss: 0.1144\n",
      "Step 352/391, Loss: 0.0629\n",
      "Step 353/391, Loss: 0.0380\n",
      "Step 354/391, Loss: 0.0267\n",
      "Step 355/391, Loss: 0.1050\n",
      "Step 356/391, Loss: 0.0290\n",
      "Step 357/391, Loss: 0.0621\n",
      "Step 358/391, Loss: 0.0796\n",
      "Step 359/391, Loss: 0.0269\n",
      "Step 360/391, Loss: 0.1257\n",
      "Step 361/391, Loss: 0.0559\n",
      "Step 362/391, Loss: 0.1422\n",
      "Step 363/391, Loss: 0.0179\n",
      "Step 364/391, Loss: 0.0496\n",
      "Step 365/391, Loss: 0.0717\n",
      "Step 366/391, Loss: 0.0473\n",
      "Step 367/391, Loss: 0.0960\n",
      "Step 368/391, Loss: 0.0624\n",
      "Step 369/391, Loss: 0.0235\n",
      "Step 370/391, Loss: 0.0557\n",
      "Step 371/391, Loss: 0.0660\n",
      "Step 372/391, Loss: 0.0147\n",
      "Step 373/391, Loss: 0.0508\n",
      "Step 374/391, Loss: 0.0843\n",
      "Step 375/391, Loss: 0.0177\n",
      "Step 376/391, Loss: 0.1133\n",
      "Step 377/391, Loss: 0.0765\n",
      "Step 378/391, Loss: 0.1225\n",
      "Step 379/391, Loss: 0.1129\n",
      "Step 380/391, Loss: 0.0288\n",
      "Step 381/391, Loss: 0.0506\n",
      "Step 382/391, Loss: 0.0480\n",
      "Step 383/391, Loss: 0.0202\n",
      "Step 384/391, Loss: 0.1162\n",
      "Step 385/391, Loss: 0.1239\n",
      "Step 386/391, Loss: 0.0304\n",
      "Step 387/391, Loss: 0.0108\n",
      "Step 388/391, Loss: 0.0473\n",
      "Step 389/391, Loss: 0.0600\n",
      "Step 390/391, Loss: 0.0343\n",
      "Step 391/391, Loss: 0.0170\n",
      "Epoch 13/25, Average Train Loss: 0.0590\n",
      "Epoch 13/25, Average Validation Loss: 0.0774\n",
      "Model saved at epoch 13 with validation loss: 0.0774\n",
      "Step 1/391, Loss: 0.0266\n",
      "Step 2/391, Loss: 0.0462\n",
      "Step 3/391, Loss: 0.0545\n",
      "Step 4/391, Loss: 0.0346\n",
      "Step 5/391, Loss: 0.0158\n",
      "Step 6/391, Loss: 0.0076\n",
      "Step 7/391, Loss: 0.0445\n",
      "Step 8/391, Loss: 0.0816\n",
      "Step 9/391, Loss: 0.0084\n",
      "Step 10/391, Loss: 0.0471\n",
      "Step 11/391, Loss: 0.0692\n",
      "Step 12/391, Loss: 0.0572\n",
      "Step 13/391, Loss: 0.0097\n",
      "Step 14/391, Loss: 0.1052\n",
      "Step 15/391, Loss: 0.0185\n",
      "Step 16/391, Loss: 0.0865\n",
      "Step 17/391, Loss: 0.0276\n",
      "Step 18/391, Loss: 0.0227\n",
      "Step 19/391, Loss: 0.0271\n",
      "Step 20/391, Loss: 0.0847\n",
      "Step 21/391, Loss: 0.0204\n",
      "Step 22/391, Loss: 0.0468\n",
      "Step 23/391, Loss: 0.0659\n",
      "Step 24/391, Loss: 0.0515\n",
      "Step 25/391, Loss: 0.0780\n",
      "Step 26/391, Loss: 0.0811\n",
      "Step 27/391, Loss: 0.0647\n",
      "Step 28/391, Loss: 0.0180\n",
      "Step 29/391, Loss: 0.0393\n",
      "Step 30/391, Loss: 0.0155\n",
      "Step 31/391, Loss: 0.0137\n",
      "Step 32/391, Loss: 0.0626\n",
      "Step 33/391, Loss: 0.0720\n",
      "Step 34/391, Loss: 0.0166\n",
      "Step 35/391, Loss: 0.0257\n",
      "Step 36/391, Loss: 0.0331\n",
      "Step 37/391, Loss: 0.0355\n",
      "Step 38/391, Loss: 0.0313\n",
      "Step 39/391, Loss: 0.0432\n",
      "Step 40/391, Loss: 0.0567\n",
      "Step 41/391, Loss: 0.0495\n",
      "Step 42/391, Loss: 0.0129\n",
      "Step 43/391, Loss: 0.1379\n",
      "Step 44/391, Loss: 0.0181\n",
      "Step 45/391, Loss: 0.0168\n",
      "Step 46/391, Loss: 0.0229\n",
      "Step 47/391, Loss: 0.0998\n",
      "Step 48/391, Loss: 0.0650\n",
      "Step 49/391, Loss: 0.0367\n",
      "Step 50/391, Loss: 0.0308\n",
      "Step 51/391, Loss: 0.0380\n",
      "Step 52/391, Loss: 0.0144\n",
      "Step 53/391, Loss: 0.0248\n",
      "Step 54/391, Loss: 0.0616\n",
      "Step 55/391, Loss: 0.1063\n",
      "Step 56/391, Loss: 0.0538\n",
      "Step 57/391, Loss: 0.0799\n",
      "Step 58/391, Loss: 0.0393\n",
      "Step 59/391, Loss: 0.0323\n",
      "Step 60/391, Loss: 0.0467\n",
      "Step 61/391, Loss: 0.0422\n",
      "Step 62/391, Loss: 0.0142\n",
      "Step 63/391, Loss: 0.1105\n",
      "Step 64/391, Loss: 0.1477\n",
      "Step 65/391, Loss: 0.0614\n",
      "Step 66/391, Loss: 0.1048\n",
      "Step 67/391, Loss: 0.0175\n",
      "Step 68/391, Loss: 0.0181\n",
      "Step 69/391, Loss: 0.0347\n",
      "Step 70/391, Loss: 0.0505\n",
      "Step 71/391, Loss: 0.0296\n",
      "Step 72/391, Loss: 0.0073\n",
      "Step 73/391, Loss: 0.0322\n",
      "Step 74/391, Loss: 0.0088\n",
      "Step 75/391, Loss: 0.0317\n",
      "Step 76/391, Loss: 0.0323\n",
      "Step 77/391, Loss: 0.0281\n",
      "Step 78/391, Loss: 0.1106\n",
      "Step 79/391, Loss: 0.0102\n",
      "Step 80/391, Loss: 0.0371\n",
      "Step 81/391, Loss: 0.0457\n",
      "Step 82/391, Loss: 0.0663\n",
      "Step 83/391, Loss: 0.1274\n",
      "Step 84/391, Loss: 0.0284\n",
      "Step 85/391, Loss: 0.0437\n",
      "Step 86/391, Loss: 0.0654\n",
      "Step 87/391, Loss: 0.1079\n",
      "Step 88/391, Loss: 0.0321\n",
      "Step 89/391, Loss: 0.0230\n",
      "Step 90/391, Loss: 0.0077\n",
      "Step 91/391, Loss: 0.0580\n",
      "Step 92/391, Loss: 0.0256\n",
      "Step 93/391, Loss: 0.0715\n",
      "Step 94/391, Loss: 0.1077\n",
      "Step 95/391, Loss: 0.0216\n",
      "Step 96/391, Loss: 0.0528\n",
      "Step 97/391, Loss: 0.0351\n",
      "Step 98/391, Loss: 0.0733\n",
      "Step 99/391, Loss: 0.0111\n",
      "Step 100/391, Loss: 0.0145\n",
      "Step 101/391, Loss: 0.0402\n",
      "Step 102/391, Loss: 0.0241\n",
      "Step 103/391, Loss: 0.0908\n",
      "Step 104/391, Loss: 0.0319\n",
      "Step 105/391, Loss: 0.0231\n",
      "Step 106/391, Loss: 0.0148\n",
      "Step 107/391, Loss: 0.0383\n",
      "Step 108/391, Loss: 0.0506\n",
      "Step 109/391, Loss: 0.0093\n",
      "Step 110/391, Loss: 0.0509\n",
      "Step 111/391, Loss: 0.0257\n",
      "Step 112/391, Loss: 0.0395\n",
      "Step 113/391, Loss: 0.0550\n",
      "Step 114/391, Loss: 0.0454\n",
      "Step 115/391, Loss: 0.0412\n",
      "Step 116/391, Loss: 0.0643\n",
      "Step 117/391, Loss: 0.0227\n",
      "Step 118/391, Loss: 0.0547\n",
      "Step 119/391, Loss: 0.0619\n",
      "Step 120/391, Loss: 0.0197\n",
      "Step 121/391, Loss: 0.0190\n",
      "Step 122/391, Loss: 0.0084\n",
      "Step 123/391, Loss: 0.0372\n",
      "Step 124/391, Loss: 0.0796\n",
      "Step 125/391, Loss: 0.0209\n",
      "Step 126/391, Loss: 0.0592\n",
      "Step 127/391, Loss: 0.0433\n",
      "Step 128/391, Loss: 0.0391\n",
      "Step 129/391, Loss: 0.0140\n",
      "Step 130/391, Loss: 0.0032\n",
      "Step 131/391, Loss: 0.0178\n",
      "Step 132/391, Loss: 0.0103\n",
      "Step 133/391, Loss: 0.0995\n",
      "Step 134/391, Loss: 0.0542\n",
      "Step 135/391, Loss: 0.0188\n",
      "Step 136/391, Loss: 0.0641\n",
      "Step 137/391, Loss: 0.0419\n",
      "Step 138/391, Loss: 0.0131\n",
      "Step 139/391, Loss: 0.0431\n",
      "Step 140/391, Loss: 0.0883\n",
      "Step 141/391, Loss: 0.0613\n",
      "Step 142/391, Loss: 0.0574\n",
      "Step 143/391, Loss: 0.0100\n",
      "Step 144/391, Loss: 0.0682\n",
      "Step 145/391, Loss: 0.0697\n",
      "Step 146/391, Loss: 0.0272\n",
      "Step 147/391, Loss: 0.0038\n",
      "Step 148/391, Loss: 0.0931\n",
      "Step 149/391, Loss: 0.0162\n",
      "Step 150/391, Loss: 0.0430\n",
      "Step 151/391, Loss: 0.0242\n",
      "Step 152/391, Loss: 0.0139\n",
      "Step 153/391, Loss: 0.0390\n",
      "Step 154/391, Loss: 0.0418\n",
      "Step 155/391, Loss: 0.0226\n",
      "Step 156/391, Loss: 0.0430\n",
      "Step 157/391, Loss: 0.0140\n",
      "Step 158/391, Loss: 0.1158\n",
      "Step 159/391, Loss: 0.0604\n",
      "Step 160/391, Loss: 0.0087\n",
      "Step 161/391, Loss: 0.0424\n",
      "Step 162/391, Loss: 0.0116\n",
      "Step 163/391, Loss: 0.0287\n",
      "Step 164/391, Loss: 0.0517\n",
      "Step 165/391, Loss: 0.0342\n",
      "Step 166/391, Loss: 0.0130\n",
      "Step 167/391, Loss: 0.0604\n",
      "Step 168/391, Loss: 0.0982\n",
      "Step 169/391, Loss: 0.1047\n",
      "Step 170/391, Loss: 0.0716\n",
      "Step 171/391, Loss: 0.0350\n",
      "Step 172/391, Loss: 0.0270\n",
      "Step 173/391, Loss: 0.0308\n",
      "Step 174/391, Loss: 0.0355\n",
      "Step 175/391, Loss: 0.0857\n",
      "Step 176/391, Loss: 0.0974\n",
      "Step 177/391, Loss: 0.0271\n",
      "Step 178/391, Loss: 0.0550\n",
      "Step 179/391, Loss: 0.0347\n",
      "Step 180/391, Loss: 0.0582\n",
      "Step 181/391, Loss: 0.0616\n",
      "Step 182/391, Loss: 0.1089\n",
      "Step 183/391, Loss: 0.0741\n",
      "Step 184/391, Loss: 0.0062\n",
      "Step 185/391, Loss: 0.0169\n",
      "Step 186/391, Loss: 0.0813\n",
      "Step 187/391, Loss: 0.0355\n",
      "Step 188/391, Loss: 0.0661\n",
      "Step 189/391, Loss: 0.0655\n",
      "Step 190/391, Loss: 0.1089\n",
      "Step 191/391, Loss: 0.0320\n",
      "Step 192/391, Loss: 0.1428\n",
      "Step 193/391, Loss: 0.0152\n",
      "Step 194/391, Loss: 0.1915\n",
      "Step 195/391, Loss: 0.0669\n",
      "Step 196/391, Loss: 0.0384\n",
      "Step 197/391, Loss: 0.0058\n",
      "Step 198/391, Loss: 0.1155\n",
      "Step 199/391, Loss: 0.0393\n",
      "Step 200/391, Loss: 0.0865\n",
      "Step 201/391, Loss: 0.0376\n",
      "Step 202/391, Loss: 0.0150\n",
      "Step 203/391, Loss: 0.0663\n",
      "Step 204/391, Loss: 0.0165\n",
      "Step 205/391, Loss: 0.0607\n",
      "Step 206/391, Loss: 0.0452\n",
      "Step 207/391, Loss: 0.0488\n",
      "Step 208/391, Loss: 0.0164\n",
      "Step 209/391, Loss: 0.1258\n",
      "Step 210/391, Loss: 0.0743\n",
      "Step 211/391, Loss: 0.0126\n",
      "Step 212/391, Loss: 0.1321\n",
      "Step 213/391, Loss: 0.0459\n",
      "Step 214/391, Loss: 0.0424\n",
      "Step 215/391, Loss: 0.0545\n",
      "Step 216/391, Loss: 0.0154\n",
      "Step 217/391, Loss: 0.0572\n",
      "Step 218/391, Loss: 0.0186\n",
      "Step 219/391, Loss: 0.0878\n",
      "Step 220/391, Loss: 0.0337\n",
      "Step 221/391, Loss: 0.0926\n",
      "Step 222/391, Loss: 0.0396\n",
      "Step 223/391, Loss: 0.0394\n",
      "Step 224/391, Loss: 0.0559\n",
      "Step 225/391, Loss: 0.0261\n",
      "Step 226/391, Loss: 0.0295\n",
      "Step 227/391, Loss: 0.1447\n",
      "Step 228/391, Loss: 0.0151\n",
      "Step 229/391, Loss: 0.0537\n",
      "Step 230/391, Loss: 0.0764\n",
      "Step 231/391, Loss: 0.0252\n",
      "Step 232/391, Loss: 0.0817\n",
      "Step 233/391, Loss: 0.0255\n",
      "Step 234/391, Loss: 0.0262\n",
      "Step 235/391, Loss: 0.0648\n",
      "Step 236/391, Loss: 0.0652\n",
      "Step 237/391, Loss: 0.0382\n",
      "Step 238/391, Loss: 0.0373\n",
      "Step 239/391, Loss: 0.1224\n",
      "Step 240/391, Loss: 0.0913\n",
      "Step 241/391, Loss: 0.1999\n",
      "Step 242/391, Loss: 0.0147\n",
      "Step 243/391, Loss: 0.0828\n",
      "Step 244/391, Loss: 0.0096\n",
      "Step 245/391, Loss: 0.0116\n",
      "Step 246/391, Loss: 0.0690\n",
      "Step 247/391, Loss: 0.0666\n",
      "Step 248/391, Loss: 0.0081\n",
      "Step 249/391, Loss: 0.0249\n",
      "Step 250/391, Loss: 0.0732\n",
      "Step 251/391, Loss: 0.0174\n",
      "Step 252/391, Loss: 0.0155\n",
      "Step 253/391, Loss: 0.0832\n",
      "Step 254/391, Loss: 0.0594\n",
      "Step 255/391, Loss: 0.0479\n",
      "Step 256/391, Loss: 0.0091\n",
      "Step 257/391, Loss: 0.0207\n",
      "Step 258/391, Loss: 0.0801\n",
      "Step 259/391, Loss: 0.0558\n",
      "Step 260/391, Loss: 0.0593\n",
      "Step 261/391, Loss: 0.0157\n",
      "Step 262/391, Loss: 0.0591\n",
      "Step 263/391, Loss: 0.0898\n",
      "Step 264/391, Loss: 0.0318\n",
      "Step 265/391, Loss: 0.0182\n",
      "Step 266/391, Loss: 0.0351\n",
      "Step 267/391, Loss: 0.0932\n",
      "Step 268/391, Loss: 0.0675\n",
      "Step 269/391, Loss: 0.0290\n",
      "Step 270/391, Loss: 0.0853\n",
      "Step 271/391, Loss: 0.0098\n",
      "Step 272/391, Loss: 0.0710\n",
      "Step 273/391, Loss: 0.0188\n",
      "Step 274/391, Loss: 0.0649\n",
      "Step 275/391, Loss: 0.0087\n",
      "Step 276/391, Loss: 0.0536\n",
      "Step 277/391, Loss: 0.0088\n",
      "Step 278/391, Loss: 0.0814\n",
      "Step 279/391, Loss: 0.1214\n",
      "Step 280/391, Loss: 0.0421\n",
      "Step 281/391, Loss: 0.0671\n",
      "Step 282/391, Loss: 0.0650\n",
      "Step 283/391, Loss: 0.0299\n",
      "Step 284/391, Loss: 0.0044\n",
      "Step 285/391, Loss: 0.0371\n",
      "Step 286/391, Loss: 0.0194\n",
      "Step 287/391, Loss: 0.0371\n",
      "Step 288/391, Loss: 0.0247\n",
      "Step 289/391, Loss: 0.0151\n",
      "Step 290/391, Loss: 0.0545\n",
      "Step 291/391, Loss: 0.0821\n",
      "Step 292/391, Loss: 0.0255\n",
      "Step 293/391, Loss: 0.0491\n",
      "Step 294/391, Loss: 0.0435\n",
      "Step 295/391, Loss: 0.0485\n",
      "Step 296/391, Loss: 0.0667\n",
      "Step 297/391, Loss: 0.0798\n",
      "Step 298/391, Loss: 0.0125\n",
      "Step 299/391, Loss: 0.0381\n",
      "Step 300/391, Loss: 0.1047\n",
      "Step 301/391, Loss: 0.0491\n",
      "Step 302/391, Loss: 0.0299\n",
      "Step 303/391, Loss: 0.0606\n",
      "Step 304/391, Loss: 0.0463\n",
      "Step 305/391, Loss: 0.0281\n",
      "Step 306/391, Loss: 0.1658\n",
      "Step 307/391, Loss: 0.0220\n",
      "Step 308/391, Loss: 0.0785\n",
      "Step 309/391, Loss: 0.1485\n",
      "Step 310/391, Loss: 0.0332\n",
      "Step 311/391, Loss: 0.0477\n",
      "Step 312/391, Loss: 0.0267\n",
      "Step 313/391, Loss: 0.0976\n",
      "Step 314/391, Loss: 0.0509\n",
      "Step 315/391, Loss: 0.0440\n",
      "Step 316/391, Loss: 0.0189\n",
      "Step 317/391, Loss: 0.0669\n",
      "Step 318/391, Loss: 0.0883\n",
      "Step 319/391, Loss: 0.1121\n",
      "Step 320/391, Loss: 0.0680\n",
      "Step 321/391, Loss: 0.0130\n",
      "Step 322/391, Loss: 0.0385\n",
      "Step 323/391, Loss: 0.0432\n",
      "Step 324/391, Loss: 0.0553\n",
      "Step 325/391, Loss: 0.0440\n",
      "Step 326/391, Loss: 0.0345\n",
      "Step 327/391, Loss: 0.0479\n",
      "Step 328/391, Loss: 0.0459\n",
      "Step 329/391, Loss: 0.0563\n",
      "Step 330/391, Loss: 0.0193\n",
      "Step 331/391, Loss: 0.0303\n",
      "Step 332/391, Loss: 0.0705\n",
      "Step 333/391, Loss: 0.0315\n",
      "Step 334/391, Loss: 0.0795\n",
      "Step 335/391, Loss: 0.0814\n",
      "Step 336/391, Loss: 0.0902\n",
      "Step 337/391, Loss: 0.0583\n",
      "Step 338/391, Loss: 0.0111\n",
      "Step 339/391, Loss: 0.1007\n",
      "Step 340/391, Loss: 0.0538\n",
      "Step 341/391, Loss: 0.0605\n",
      "Step 342/391, Loss: 0.0341\n",
      "Step 343/391, Loss: 0.1114\n",
      "Step 344/391, Loss: 0.0907\n",
      "Step 345/391, Loss: 0.0506\n",
      "Step 346/391, Loss: 0.0143\n",
      "Step 347/391, Loss: 0.1005\n",
      "Step 348/391, Loss: 0.1201\n",
      "Step 349/391, Loss: 0.0595\n",
      "Step 350/391, Loss: 0.1548\n",
      "Step 351/391, Loss: 0.0593\n",
      "Step 352/391, Loss: 0.0957\n",
      "Step 353/391, Loss: 0.0538\n",
      "Step 354/391, Loss: 0.0169\n",
      "Step 355/391, Loss: 0.0474\n",
      "Step 356/391, Loss: 0.0310\n",
      "Step 357/391, Loss: 0.1257\n",
      "Step 358/391, Loss: 0.1023\n",
      "Step 359/391, Loss: 0.1280\n",
      "Step 360/391, Loss: 0.0943\n",
      "Step 361/391, Loss: 0.0750\n",
      "Step 362/391, Loss: 0.0572\n",
      "Step 363/391, Loss: 0.0249\n",
      "Step 364/391, Loss: 0.0763\n",
      "Step 365/391, Loss: 0.0679\n",
      "Step 366/391, Loss: 0.0719\n",
      "Step 367/391, Loss: 0.0892\n",
      "Step 368/391, Loss: 0.0646\n",
      "Step 369/391, Loss: 0.0357\n",
      "Step 370/391, Loss: 0.0992\n",
      "Step 371/391, Loss: 0.1178\n",
      "Step 372/391, Loss: 0.0661\n",
      "Step 373/391, Loss: 0.0549\n",
      "Step 374/391, Loss: 0.1055\n",
      "Step 375/391, Loss: 0.0571\n",
      "Step 376/391, Loss: 0.0801\n",
      "Step 377/391, Loss: 0.0307\n",
      "Step 378/391, Loss: 0.0815\n",
      "Step 379/391, Loss: 0.0181\n",
      "Step 380/391, Loss: 0.0562\n",
      "Step 381/391, Loss: 0.0766\n",
      "Step 382/391, Loss: 0.0110\n",
      "Step 383/391, Loss: 0.0452\n",
      "Step 384/391, Loss: 0.0875\n",
      "Step 385/391, Loss: 0.1087\n",
      "Step 386/391, Loss: 0.0797\n",
      "Step 387/391, Loss: 0.1472\n",
      "Step 388/391, Loss: 0.0432\n",
      "Step 389/391, Loss: 0.0140\n",
      "Step 390/391, Loss: 0.1078\n",
      "Step 391/391, Loss: 0.0334\n",
      "Epoch 14/25, Average Train Loss: 0.0523\n",
      "Epoch 14/25, Average Validation Loss: 0.0832\n",
      "Step 1/391, Loss: 0.0088\n",
      "Step 2/391, Loss: 0.1049\n",
      "Step 3/391, Loss: 0.0852\n",
      "Step 4/391, Loss: 0.0420\n",
      "Step 5/391, Loss: 0.0663\n",
      "Step 6/391, Loss: 0.1412\n",
      "Step 7/391, Loss: 0.0468\n",
      "Step 8/391, Loss: 0.0345\n",
      "Step 9/391, Loss: 0.0415\n",
      "Step 10/391, Loss: 0.0258\n",
      "Step 11/391, Loss: 0.0859\n",
      "Step 12/391, Loss: 0.1296\n",
      "Step 13/391, Loss: 0.0503\n",
      "Step 14/391, Loss: 0.0791\n",
      "Step 15/391, Loss: 0.0501\n",
      "Step 16/391, Loss: 0.0249\n",
      "Step 17/391, Loss: 0.0078\n",
      "Step 18/391, Loss: 0.0450\n",
      "Step 19/391, Loss: 0.0581\n",
      "Step 20/391, Loss: 0.0144\n",
      "Step 21/391, Loss: 0.0775\n",
      "Step 22/391, Loss: 0.0470\n",
      "Step 23/391, Loss: 0.0524\n",
      "Step 24/391, Loss: 0.0695\n",
      "Step 25/391, Loss: 0.0609\n",
      "Step 26/391, Loss: 0.0537\n",
      "Step 27/391, Loss: 0.0590\n",
      "Step 28/391, Loss: 0.0531\n",
      "Step 29/391, Loss: 0.0706\n",
      "Step 30/391, Loss: 0.0837\n",
      "Step 31/391, Loss: 0.0166\n",
      "Step 32/391, Loss: 0.0253\n",
      "Step 33/391, Loss: 0.0597\n",
      "Step 34/391, Loss: 0.0249\n",
      "Step 35/391, Loss: 0.0466\n",
      "Step 36/391, Loss: 0.0158\n",
      "Step 37/391, Loss: 0.0319\n",
      "Step 38/391, Loss: 0.0190\n",
      "Step 39/391, Loss: 0.1063\n",
      "Step 40/391, Loss: 0.0826\n",
      "Step 41/391, Loss: 0.1116\n",
      "Step 42/391, Loss: 0.0117\n",
      "Step 43/391, Loss: 0.0320\n",
      "Step 44/391, Loss: 0.0286\n",
      "Step 45/391, Loss: 0.0114\n",
      "Step 46/391, Loss: 0.0193\n",
      "Step 47/391, Loss: 0.0447\n",
      "Step 48/391, Loss: 0.0359\n",
      "Step 49/391, Loss: 0.0565\n",
      "Step 50/391, Loss: 0.0086\n",
      "Step 51/391, Loss: 0.0388\n",
      "Step 52/391, Loss: 0.0102\n",
      "Step 53/391, Loss: 0.0148\n",
      "Step 54/391, Loss: 0.0120\n",
      "Step 55/391, Loss: 0.0389\n",
      "Step 56/391, Loss: 0.0380\n",
      "Step 57/391, Loss: 0.0054\n",
      "Step 58/391, Loss: 0.0349\n",
      "Step 59/391, Loss: 0.0594\n",
      "Step 60/391, Loss: 0.1118\n",
      "Step 61/391, Loss: 0.0398\n",
      "Step 62/391, Loss: 0.0069\n",
      "Step 63/391, Loss: 0.0579\n",
      "Step 64/391, Loss: 0.0408\n",
      "Step 65/391, Loss: 0.0079\n",
      "Step 66/391, Loss: 0.0174\n",
      "Step 67/391, Loss: 0.0350\n",
      "Step 68/391, Loss: 0.0492\n",
      "Step 69/391, Loss: 0.0439\n",
      "Step 70/391, Loss: 0.0371\n",
      "Step 71/391, Loss: 0.0477\n",
      "Step 72/391, Loss: 0.0798\n",
      "Step 73/391, Loss: 0.0352\n",
      "Step 74/391, Loss: 0.0679\n",
      "Step 75/391, Loss: 0.0924\n",
      "Step 76/391, Loss: 0.0954\n",
      "Step 77/391, Loss: 0.0448\n",
      "Step 78/391, Loss: 0.0145\n",
      "Step 79/391, Loss: 0.0204\n",
      "Step 80/391, Loss: 0.0543\n",
      "Step 81/391, Loss: 0.0088\n",
      "Step 82/391, Loss: 0.0245\n",
      "Step 83/391, Loss: 0.0382\n",
      "Step 84/391, Loss: 0.0254\n",
      "Step 85/391, Loss: 0.0361\n",
      "Step 86/391, Loss: 0.0538\n",
      "Step 87/391, Loss: 0.0747\n",
      "Step 88/391, Loss: 0.0915\n",
      "Step 89/391, Loss: 0.0270\n",
      "Step 90/391, Loss: 0.0021\n",
      "Step 91/391, Loss: 0.0748\n",
      "Step 92/391, Loss: 0.0249\n",
      "Step 93/391, Loss: 0.0274\n",
      "Step 94/391, Loss: 0.0081\n",
      "Step 95/391, Loss: 0.0224\n",
      "Step 96/391, Loss: 0.0349\n",
      "Step 97/391, Loss: 0.0189\n",
      "Step 98/391, Loss: 0.0141\n",
      "Step 99/391, Loss: 0.0709\n",
      "Step 100/391, Loss: 0.0257\n",
      "Step 101/391, Loss: 0.0471\n",
      "Step 102/391, Loss: 0.0661\n",
      "Step 103/391, Loss: 0.0048\n",
      "Step 104/391, Loss: 0.0214\n",
      "Step 105/391, Loss: 0.0280\n",
      "Step 106/391, Loss: 0.0589\n",
      "Step 107/391, Loss: 0.0261\n",
      "Step 108/391, Loss: 0.0124\n",
      "Step 109/391, Loss: 0.0262\n",
      "Step 110/391, Loss: 0.0091\n",
      "Step 111/391, Loss: 0.0843\n",
      "Step 112/391, Loss: 0.0359\n",
      "Step 113/391, Loss: 0.0284\n",
      "Step 114/391, Loss: 0.0081\n",
      "Step 115/391, Loss: 0.0771\n",
      "Step 116/391, Loss: 0.0293\n",
      "Step 117/391, Loss: 0.0806\n",
      "Step 118/391, Loss: 0.0322\n",
      "Step 119/391, Loss: 0.0341\n",
      "Step 120/391, Loss: 0.0549\n",
      "Step 121/391, Loss: 0.0125\n",
      "Step 122/391, Loss: 0.0458\n",
      "Step 123/391, Loss: 0.0831\n",
      "Step 124/391, Loss: 0.0307\n",
      "Step 125/391, Loss: 0.0092\n",
      "Step 126/391, Loss: 0.1099\n",
      "Step 127/391, Loss: 0.0194\n",
      "Step 128/391, Loss: 0.0414\n",
      "Step 129/391, Loss: 0.0250\n",
      "Step 130/391, Loss: 0.0429\n",
      "Step 131/391, Loss: 0.0341\n",
      "Step 132/391, Loss: 0.1464\n",
      "Step 133/391, Loss: 0.0961\n",
      "Step 134/391, Loss: 0.0392\n",
      "Step 135/391, Loss: 0.0112\n",
      "Step 136/391, Loss: 0.0137\n",
      "Step 137/391, Loss: 0.0125\n",
      "Step 138/391, Loss: 0.0434\n",
      "Step 139/391, Loss: 0.0422\n",
      "Step 140/391, Loss: 0.0226\n",
      "Step 141/391, Loss: 0.1409\n",
      "Step 142/391, Loss: 0.0131\n",
      "Step 143/391, Loss: 0.0503\n",
      "Step 144/391, Loss: 0.0796\n",
      "Step 145/391, Loss: 0.0486\n",
      "Step 146/391, Loss: 0.0115\n",
      "Step 147/391, Loss: 0.0584\n",
      "Step 148/391, Loss: 0.0093\n",
      "Step 149/391, Loss: 0.0212\n",
      "Step 150/391, Loss: 0.0365\n",
      "Step 151/391, Loss: 0.0865\n",
      "Step 152/391, Loss: 0.0190\n",
      "Step 153/391, Loss: 0.0564\n",
      "Step 154/391, Loss: 0.0681\n",
      "Step 155/391, Loss: 0.0049\n",
      "Step 156/391, Loss: 0.0331\n",
      "Step 157/391, Loss: 0.0499\n",
      "Step 158/391, Loss: 0.0373\n",
      "Step 159/391, Loss: 0.1153\n",
      "Step 160/391, Loss: 0.0955\n",
      "Step 161/391, Loss: 0.0426\n",
      "Step 162/391, Loss: 0.0055\n",
      "Step 163/391, Loss: 0.0709\n",
      "Step 164/391, Loss: 0.0197\n",
      "Step 165/391, Loss: 0.0873\n",
      "Step 166/391, Loss: 0.1233\n",
      "Step 167/391, Loss: 0.0450\n",
      "Step 168/391, Loss: 0.0573\n",
      "Step 169/391, Loss: 0.0472\n",
      "Step 170/391, Loss: 0.0330\n",
      "Step 171/391, Loss: 0.0271\n",
      "Step 172/391, Loss: 0.0493\n",
      "Step 173/391, Loss: 0.0066\n",
      "Step 174/391, Loss: 0.0189\n",
      "Step 175/391, Loss: 0.1220\n",
      "Step 176/391, Loss: 0.0608\n",
      "Step 177/391, Loss: 0.0404\n",
      "Step 178/391, Loss: 0.1058\n",
      "Step 179/391, Loss: 0.0333\n",
      "Step 180/391, Loss: 0.0365\n",
      "Step 181/391, Loss: 0.0064\n",
      "Step 182/391, Loss: 0.0600\n",
      "Step 183/391, Loss: 0.0266\n",
      "Step 184/391, Loss: 0.0336\n",
      "Step 185/391, Loss: 0.0085\n",
      "Step 186/391, Loss: 0.0788\n",
      "Step 187/391, Loss: 0.0300\n",
      "Step 188/391, Loss: 0.0407\n",
      "Step 189/391, Loss: 0.0503\n",
      "Step 190/391, Loss: 0.0616\n",
      "Step 191/391, Loss: 0.0819\n",
      "Step 192/391, Loss: 0.0381\n",
      "Step 193/391, Loss: 0.1053\n",
      "Step 194/391, Loss: 0.0293\n",
      "Step 195/391, Loss: 0.0929\n",
      "Step 196/391, Loss: 0.0712\n",
      "Step 197/391, Loss: 0.0872\n",
      "Step 198/391, Loss: 0.0369\n",
      "Step 199/391, Loss: 0.0399\n",
      "Step 200/391, Loss: 0.1084\n",
      "Step 201/391, Loss: 0.1606\n",
      "Step 202/391, Loss: 0.0484\n",
      "Step 203/391, Loss: 0.0358\n",
      "Step 204/391, Loss: 0.0193\n",
      "Step 205/391, Loss: 0.0515\n",
      "Step 206/391, Loss: 0.0181\n",
      "Step 207/391, Loss: 0.0270\n",
      "Step 208/391, Loss: 0.0508\n",
      "Step 209/391, Loss: 0.0791\n",
      "Step 210/391, Loss: 0.0590\n",
      "Step 211/391, Loss: 0.0611\n",
      "Step 212/391, Loss: 0.1083\n",
      "Step 213/391, Loss: 0.0375\n",
      "Step 214/391, Loss: 0.0086\n",
      "Step 215/391, Loss: 0.0626\n",
      "Step 216/391, Loss: 0.1261\n",
      "Step 217/391, Loss: 0.0573\n",
      "Step 218/391, Loss: 0.0744\n",
      "Step 219/391, Loss: 0.0843\n",
      "Step 220/391, Loss: 0.0245\n",
      "Step 221/391, Loss: 0.0142\n",
      "Step 222/391, Loss: 0.0347\n",
      "Step 223/391, Loss: 0.0701\n",
      "Step 224/391, Loss: 0.0241\n",
      "Step 225/391, Loss: 0.0471\n",
      "Step 226/391, Loss: 0.0475\n",
      "Step 227/391, Loss: 0.0581\n",
      "Step 228/391, Loss: 0.0966\n",
      "Step 229/391, Loss: 0.1014\n",
      "Step 230/391, Loss: 0.1419\n",
      "Step 231/391, Loss: 0.0356\n",
      "Step 232/391, Loss: 0.0250\n",
      "Step 233/391, Loss: 0.0675\n",
      "Step 234/391, Loss: 0.1162\n",
      "Step 235/391, Loss: 0.0247\n",
      "Step 236/391, Loss: 0.0127\n",
      "Step 237/391, Loss: 0.0710\n",
      "Step 238/391, Loss: 0.0148\n",
      "Step 239/391, Loss: 0.0529\n",
      "Step 240/391, Loss: 0.0380\n",
      "Step 241/391, Loss: 0.0511\n",
      "Step 242/391, Loss: 0.0481\n",
      "Step 243/391, Loss: 0.0157\n",
      "Step 244/391, Loss: 0.0143\n",
      "Step 245/391, Loss: 0.0304\n",
      "Step 246/391, Loss: 0.0246\n",
      "Step 247/391, Loss: 0.1123\n",
      "Step 248/391, Loss: 0.0829\n",
      "Step 249/391, Loss: 0.0484\n",
      "Step 250/391, Loss: 0.1027\n",
      "Step 251/391, Loss: 0.0192\n",
      "Step 252/391, Loss: 0.0640\n",
      "Step 253/391, Loss: 0.0303\n",
      "Step 254/391, Loss: 0.0257\n",
      "Step 255/391, Loss: 0.0403\n",
      "Step 256/391, Loss: 0.0482\n",
      "Step 257/391, Loss: 0.0588\n",
      "Step 258/391, Loss: 0.0634\n",
      "Step 259/391, Loss: 0.0192\n",
      "Step 260/391, Loss: 0.0497\n",
      "Step 261/391, Loss: 0.0454\n",
      "Step 262/391, Loss: 0.1919\n",
      "Step 263/391, Loss: 0.0578\n",
      "Step 264/391, Loss: 0.0590\n",
      "Step 265/391, Loss: 0.0628\n",
      "Step 266/391, Loss: 0.0061\n",
      "Step 267/391, Loss: 0.0786\n",
      "Step 268/391, Loss: 0.0414\n",
      "Step 269/391, Loss: 0.0350\n",
      "Step 270/391, Loss: 0.0315\n",
      "Step 271/391, Loss: 0.0513\n",
      "Step 272/391, Loss: 0.0678\n",
      "Step 273/391, Loss: 0.0784\n",
      "Step 274/391, Loss: 0.0619\n",
      "Step 275/391, Loss: 0.0132\n",
      "Step 276/391, Loss: 0.1206\n",
      "Step 277/391, Loss: 0.0456\n",
      "Step 278/391, Loss: 0.0261\n",
      "Step 279/391, Loss: 0.1486\n",
      "Step 280/391, Loss: 0.0485\n",
      "Step 281/391, Loss: 0.1153\n",
      "Step 282/391, Loss: 0.0556\n",
      "Step 283/391, Loss: 0.0382\n",
      "Step 284/391, Loss: 0.0684\n",
      "Step 285/391, Loss: 0.0485\n",
      "Step 286/391, Loss: 0.0972\n",
      "Step 287/391, Loss: 0.0501\n",
      "Step 288/391, Loss: 0.0497\n",
      "Step 289/391, Loss: 0.0299\n",
      "Step 290/391, Loss: 0.0644\n",
      "Step 291/391, Loss: 0.0347\n",
      "Step 292/391, Loss: 0.0878\n",
      "Step 293/391, Loss: 0.0795\n",
      "Step 294/391, Loss: 0.1107\n",
      "Step 295/391, Loss: 0.0236\n",
      "Step 296/391, Loss: 0.0374\n",
      "Step 297/391, Loss: 0.0562\n",
      "Step 298/391, Loss: 0.0156\n",
      "Step 299/391, Loss: 0.0940\n",
      "Step 300/391, Loss: 0.0641\n",
      "Step 301/391, Loss: 0.0489\n",
      "Step 302/391, Loss: 0.0770\n",
      "Step 303/391, Loss: 0.1063\n",
      "Step 304/391, Loss: 0.0666\n",
      "Step 305/391, Loss: 0.0552\n",
      "Step 306/391, Loss: 0.1192\n",
      "Step 307/391, Loss: 0.0348\n",
      "Step 308/391, Loss: 0.0622\n",
      "Step 309/391, Loss: 0.0670\n",
      "Step 310/391, Loss: 0.0199\n",
      "Step 311/391, Loss: 0.1147\n",
      "Step 312/391, Loss: 0.0610\n",
      "Step 313/391, Loss: 0.1205\n",
      "Step 314/391, Loss: 0.0135\n",
      "Step 315/391, Loss: 0.0879\n",
      "Step 316/391, Loss: 0.0580\n",
      "Step 317/391, Loss: 0.0733\n",
      "Step 318/391, Loss: 0.1777\n",
      "Step 319/391, Loss: 0.0527\n",
      "Step 320/391, Loss: 0.0224\n",
      "Step 321/391, Loss: 0.0166\n",
      "Step 322/391, Loss: 0.0814\n",
      "Step 323/391, Loss: 0.0161\n",
      "Step 324/391, Loss: 0.1236\n",
      "Step 325/391, Loss: 0.0365\n",
      "Step 326/391, Loss: 0.0743\n",
      "Step 327/391, Loss: 0.0405\n",
      "Step 328/391, Loss: 0.0206\n",
      "Step 329/391, Loss: 0.0458\n",
      "Step 330/391, Loss: 0.1112\n",
      "Step 331/391, Loss: 0.0283\n",
      "Step 332/391, Loss: 0.0487\n",
      "Step 333/391, Loss: 0.0343\n",
      "Step 334/391, Loss: 0.1046\n",
      "Step 335/391, Loss: 0.0683\n",
      "Step 336/391, Loss: 0.0370\n",
      "Step 337/391, Loss: 0.0424\n",
      "Step 338/391, Loss: 0.0164\n",
      "Step 339/391, Loss: 0.0502\n",
      "Step 340/391, Loss: 0.0723\n",
      "Step 341/391, Loss: 0.0592\n",
      "Step 342/391, Loss: 0.0126\n",
      "Step 343/391, Loss: 0.0640\n",
      "Step 344/391, Loss: 0.0431\n",
      "Step 345/391, Loss: 0.0516\n",
      "Step 346/391, Loss: 0.1042\n",
      "Step 347/391, Loss: 0.0406\n",
      "Step 348/391, Loss: 0.0064\n",
      "Step 349/391, Loss: 0.0717\n",
      "Step 350/391, Loss: 0.0067\n",
      "Step 351/391, Loss: 0.0547\n",
      "Step 352/391, Loss: 0.1204\n",
      "Step 353/391, Loss: 0.0438\n",
      "Step 354/391, Loss: 0.0059\n",
      "Step 355/391, Loss: 0.0341\n",
      "Step 356/391, Loss: 0.0077\n",
      "Step 357/391, Loss: 0.0748\n",
      "Step 358/391, Loss: 0.0455\n",
      "Step 359/391, Loss: 0.0128\n",
      "Step 360/391, Loss: 0.1119\n",
      "Step 361/391, Loss: 0.0701\n",
      "Step 362/391, Loss: 0.0377\n",
      "Step 363/391, Loss: 0.0335\n",
      "Step 364/391, Loss: 0.0143\n",
      "Step 365/391, Loss: 0.0126\n",
      "Step 366/391, Loss: 0.0203\n",
      "Step 367/391, Loss: 0.0603\n",
      "Step 368/391, Loss: 0.0283\n",
      "Step 369/391, Loss: 0.0619\n",
      "Step 370/391, Loss: 0.0404\n",
      "Step 371/391, Loss: 0.0561\n",
      "Step 372/391, Loss: 0.0618\n",
      "Step 373/391, Loss: 0.0135\n",
      "Step 374/391, Loss: 0.0316\n",
      "Step 375/391, Loss: 0.0045\n",
      "Step 376/391, Loss: 0.0891\n",
      "Step 377/391, Loss: 0.0184\n",
      "Step 378/391, Loss: 0.0365\n",
      "Step 379/391, Loss: 0.0415\n",
      "Step 380/391, Loss: 0.0588\n",
      "Step 381/391, Loss: 0.0177\n",
      "Step 382/391, Loss: 0.0937\n",
      "Step 383/391, Loss: 0.0317\n",
      "Step 384/391, Loss: 0.0149\n",
      "Step 385/391, Loss: 0.0146\n",
      "Step 386/391, Loss: 0.0746\n",
      "Step 387/391, Loss: 0.0312\n",
      "Step 388/391, Loss: 0.0413\n",
      "Step 389/391, Loss: 0.0378\n",
      "Step 390/391, Loss: 0.0617\n",
      "Step 391/391, Loss: 0.0715\n",
      "Epoch 15/25, Average Train Loss: 0.0507\n",
      "Epoch 15/25, Average Validation Loss: 0.0862\n",
      "Step 1/391, Loss: 0.0261\n",
      "Step 2/391, Loss: 0.0405\n",
      "Step 3/391, Loss: 0.0165\n",
      "Step 4/391, Loss: 0.0397\n",
      "Step 5/391, Loss: 0.0642\n",
      "Step 6/391, Loss: 0.0213\n",
      "Step 7/391, Loss: 0.0683\n",
      "Step 8/391, Loss: 0.1097\n",
      "Step 9/391, Loss: 0.0112\n",
      "Step 10/391, Loss: 0.1029\n",
      "Step 11/391, Loss: 0.0026\n",
      "Step 12/391, Loss: 0.0081\n",
      "Step 13/391, Loss: 0.0603\n",
      "Step 14/391, Loss: 0.0589\n",
      "Step 15/391, Loss: 0.0188\n",
      "Step 16/391, Loss: 0.0358\n",
      "Step 17/391, Loss: 0.0209\n",
      "Step 18/391, Loss: 0.0166\n",
      "Step 19/391, Loss: 0.0422\n",
      "Step 20/391, Loss: 0.0611\n",
      "Step 21/391, Loss: 0.0501\n",
      "Step 22/391, Loss: 0.0109\n",
      "Step 23/391, Loss: 0.0829\n",
      "Step 24/391, Loss: 0.0061\n",
      "Step 25/391, Loss: 0.0501\n",
      "Step 26/391, Loss: 0.0472\n",
      "Step 27/391, Loss: 0.0808\n",
      "Step 28/391, Loss: 0.1352\n",
      "Step 29/391, Loss: 0.0845\n",
      "Step 30/391, Loss: 0.0555\n",
      "Step 31/391, Loss: 0.0447\n",
      "Step 32/391, Loss: 0.0441\n",
      "Step 33/391, Loss: 0.0969\n",
      "Step 34/391, Loss: 0.0139\n",
      "Step 35/391, Loss: 0.0873\n",
      "Step 36/391, Loss: 0.0179\n",
      "Step 37/391, Loss: 0.0506\n",
      "Step 38/391, Loss: 0.0741\n",
      "Step 39/391, Loss: 0.0490\n",
      "Step 40/391, Loss: 0.0038\n",
      "Step 41/391, Loss: 0.0631\n",
      "Step 42/391, Loss: 0.0590\n",
      "Step 43/391, Loss: 0.0364\n",
      "Step 44/391, Loss: 0.0522\n",
      "Step 45/391, Loss: 0.0436\n",
      "Step 46/391, Loss: 0.0489\n",
      "Step 47/391, Loss: 0.0642\n",
      "Step 48/391, Loss: 0.0272\n",
      "Step 49/391, Loss: 0.0352\n",
      "Step 50/391, Loss: 0.0382\n",
      "Step 51/391, Loss: 0.0288\n",
      "Step 52/391, Loss: 0.0401\n",
      "Step 53/391, Loss: 0.0242\n",
      "Step 54/391, Loss: 0.0042\n",
      "Step 55/391, Loss: 0.0742\n",
      "Step 56/391, Loss: 0.0084\n",
      "Step 57/391, Loss: 0.0302\n",
      "Step 58/391, Loss: 0.0429\n",
      "Step 59/391, Loss: 0.0353\n",
      "Step 60/391, Loss: 0.0117\n",
      "Step 61/391, Loss: 0.0828\n",
      "Step 62/391, Loss: 0.0094\n",
      "Step 63/391, Loss: 0.0442\n",
      "Step 64/391, Loss: 0.0062\n",
      "Step 65/391, Loss: 0.0824\n",
      "Step 66/391, Loss: 0.0306\n",
      "Step 67/391, Loss: 0.0468\n",
      "Step 68/391, Loss: 0.0742\n",
      "Step 69/391, Loss: 0.0368\n",
      "Step 70/391, Loss: 0.0109\n",
      "Step 71/391, Loss: 0.0686\n",
      "Step 72/391, Loss: 0.0214\n",
      "Step 73/391, Loss: 0.0140\n",
      "Step 74/391, Loss: 0.0120\n",
      "Step 75/391, Loss: 0.0273\n",
      "Step 76/391, Loss: 0.0253\n",
      "Step 77/391, Loss: 0.0203\n",
      "Step 78/391, Loss: 0.1055\n",
      "Step 79/391, Loss: 0.0195\n",
      "Step 80/391, Loss: 0.0105\n",
      "Step 81/391, Loss: 0.0247\n",
      "Step 82/391, Loss: 0.0916\n",
      "Step 83/391, Loss: 0.0434\n",
      "Step 84/391, Loss: 0.0814\n",
      "Step 85/391, Loss: 0.0041\n",
      "Step 86/391, Loss: 0.0236\n",
      "Step 87/391, Loss: 0.0390\n",
      "Step 88/391, Loss: 0.0198\n",
      "Step 89/391, Loss: 0.0080\n",
      "Step 90/391, Loss: 0.0196\n",
      "Step 91/391, Loss: 0.0319\n",
      "Step 92/391, Loss: 0.0166\n",
      "Step 93/391, Loss: 0.0454\n",
      "Step 94/391, Loss: 0.1111\n",
      "Step 95/391, Loss: 0.1227\n",
      "Step 96/391, Loss: 0.0122\n",
      "Step 97/391, Loss: 0.0446\n",
      "Step 98/391, Loss: 0.0612\n",
      "Step 99/391, Loss: 0.0089\n",
      "Step 100/391, Loss: 0.0242\n",
      "Step 101/391, Loss: 0.0688\n",
      "Step 102/391, Loss: 0.0071\n",
      "Step 103/391, Loss: 0.0943\n",
      "Step 104/391, Loss: 0.0910\n",
      "Step 105/391, Loss: 0.0935\n",
      "Step 106/391, Loss: 0.0639\n",
      "Step 107/391, Loss: 0.1197\n",
      "Step 108/391, Loss: 0.0308\n",
      "Step 109/391, Loss: 0.0191\n",
      "Step 110/391, Loss: 0.1270\n",
      "Step 111/391, Loss: 0.0209\n",
      "Step 112/391, Loss: 0.0442\n",
      "Step 113/391, Loss: 0.0172\n",
      "Step 114/391, Loss: 0.0523\n",
      "Step 115/391, Loss: 0.0119\n",
      "Step 116/391, Loss: 0.0341\n",
      "Step 117/391, Loss: 0.0155\n",
      "Step 118/391, Loss: 0.0683\n",
      "Step 119/391, Loss: 0.0429\n",
      "Step 120/391, Loss: 0.0830\n",
      "Step 121/391, Loss: 0.0652\n",
      "Step 122/391, Loss: 0.0859\n",
      "Step 123/391, Loss: 0.0618\n",
      "Step 124/391, Loss: 0.0919\n",
      "Step 125/391, Loss: 0.1155\n",
      "Step 126/391, Loss: 0.0217\n",
      "Step 127/391, Loss: 0.0194\n",
      "Step 128/391, Loss: 0.0552\n",
      "Step 129/391, Loss: 0.0339\n",
      "Step 130/391, Loss: 0.0720\n",
      "Step 131/391, Loss: 0.0175\n",
      "Step 132/391, Loss: 0.0081\n",
      "Step 133/391, Loss: 0.0576\n",
      "Step 134/391, Loss: 0.0681\n",
      "Step 135/391, Loss: 0.0364\n",
      "Step 136/391, Loss: 0.0204\n",
      "Step 137/391, Loss: 0.0335\n",
      "Step 138/391, Loss: 0.0740\n",
      "Step 139/391, Loss: 0.0306\n",
      "Step 140/391, Loss: 0.0130\n",
      "Step 141/391, Loss: 0.0257\n",
      "Step 142/391, Loss: 0.0407\n",
      "Step 143/391, Loss: 0.0633\n",
      "Step 144/391, Loss: 0.0915\n",
      "Step 145/391, Loss: 0.0464\n",
      "Step 146/391, Loss: 0.0759\n",
      "Step 147/391, Loss: 0.0602\n",
      "Step 148/391, Loss: 0.0233\n",
      "Step 149/391, Loss: 0.0134\n",
      "Step 150/391, Loss: 0.0633\n",
      "Step 151/391, Loss: 0.0213\n",
      "Step 152/391, Loss: 0.1072\n",
      "Step 153/391, Loss: 0.0173\n",
      "Step 154/391, Loss: 0.0302\n",
      "Step 155/391, Loss: 0.0457\n",
      "Step 156/391, Loss: 0.0736\n",
      "Step 157/391, Loss: 0.0758\n",
      "Step 158/391, Loss: 0.0289\n",
      "Step 159/391, Loss: 0.0984\n",
      "Step 160/391, Loss: 0.0401\n",
      "Step 161/391, Loss: 0.0517\n",
      "Step 162/391, Loss: 0.0211\n",
      "Step 163/391, Loss: 0.0175\n",
      "Step 164/391, Loss: 0.0214\n",
      "Step 165/391, Loss: 0.1181\n",
      "Step 166/391, Loss: 0.0808\n",
      "Step 167/391, Loss: 0.0123\n",
      "Step 168/391, Loss: 0.0517\n",
      "Step 169/391, Loss: 0.0293\n",
      "Step 170/391, Loss: 0.0046\n",
      "Step 171/391, Loss: 0.0341\n",
      "Step 172/391, Loss: 0.0627\n",
      "Step 173/391, Loss: 0.0438\n",
      "Step 174/391, Loss: 0.0215\n",
      "Step 175/391, Loss: 0.0145\n",
      "Step 176/391, Loss: 0.0146\n",
      "Step 177/391, Loss: 0.0594\n",
      "Step 178/391, Loss: 0.0171\n",
      "Step 179/391, Loss: 0.0487\n",
      "Step 180/391, Loss: 0.0559\n",
      "Step 181/391, Loss: 0.0074\n",
      "Step 182/391, Loss: 0.0607\n",
      "Step 183/391, Loss: 0.0347\n",
      "Step 184/391, Loss: 0.0453\n",
      "Step 185/391, Loss: 0.0535\n",
      "Step 186/391, Loss: 0.0423\n",
      "Step 187/391, Loss: 0.0335\n",
      "Step 188/391, Loss: 0.0300\n",
      "Step 189/391, Loss: 0.0075\n",
      "Step 190/391, Loss: 0.0885\n",
      "Step 191/391, Loss: 0.0087\n",
      "Step 192/391, Loss: 0.0547\n",
      "Step 193/391, Loss: 0.0573\n",
      "Step 194/391, Loss: 0.1359\n",
      "Step 195/391, Loss: 0.0707\n",
      "Step 196/391, Loss: 0.0399\n",
      "Step 197/391, Loss: 0.0566\n",
      "Step 198/391, Loss: 0.0150\n",
      "Step 199/391, Loss: 0.0265\n",
      "Step 200/391, Loss: 0.0128\n",
      "Step 201/391, Loss: 0.0395\n",
      "Step 202/391, Loss: 0.0634\n",
      "Step 203/391, Loss: 0.0060\n",
      "Step 204/391, Loss: 0.0638\n",
      "Step 205/391, Loss: 0.0639\n",
      "Step 206/391, Loss: 0.0811\n",
      "Step 207/391, Loss: 0.0193\n",
      "Step 208/391, Loss: 0.0270\n",
      "Step 209/391, Loss: 0.1432\n",
      "Step 210/391, Loss: 0.0202\n",
      "Step 211/391, Loss: 0.0523\n",
      "Step 212/391, Loss: 0.0205\n",
      "Step 213/391, Loss: 0.0501\n",
      "Step 214/391, Loss: 0.0120\n",
      "Step 215/391, Loss: 0.0646\n",
      "Step 216/391, Loss: 0.0319\n",
      "Step 217/391, Loss: 0.0924\n",
      "Step 218/391, Loss: 0.0712\n",
      "Step 219/391, Loss: 0.0998\n",
      "Step 220/391, Loss: 0.0857\n",
      "Step 221/391, Loss: 0.0383\n",
      "Step 222/391, Loss: 0.0519\n",
      "Step 223/391, Loss: 0.0960\n",
      "Step 224/391, Loss: 0.0926\n",
      "Step 225/391, Loss: 0.1472\n",
      "Step 226/391, Loss: 0.0940\n",
      "Step 227/391, Loss: 0.0852\n",
      "Step 228/391, Loss: 0.0081\n",
      "Step 229/391, Loss: 0.0421\n",
      "Step 230/391, Loss: 0.0215\n",
      "Step 231/391, Loss: 0.0522\n",
      "Step 232/391, Loss: 0.1179\n",
      "Step 233/391, Loss: 0.0564\n",
      "Step 234/391, Loss: 0.1210\n",
      "Step 235/391, Loss: 0.0943\n",
      "Step 236/391, Loss: 0.0531\n",
      "Step 237/391, Loss: 0.0493\n",
      "Step 238/391, Loss: 0.0505\n",
      "Step 239/391, Loss: 0.0174\n",
      "Step 240/391, Loss: 0.0549\n",
      "Step 241/391, Loss: 0.1397\n",
      "Step 242/391, Loss: 0.0494\n",
      "Step 243/391, Loss: 0.0570\n",
      "Step 244/391, Loss: 0.0573\n",
      "Step 245/391, Loss: 0.0469\n",
      "Step 246/391, Loss: 0.0157\n",
      "Step 247/391, Loss: 0.0752\n",
      "Step 248/391, Loss: 0.0363\n",
      "Step 249/391, Loss: 0.0326\n",
      "Step 250/391, Loss: 0.0254\n",
      "Step 251/391, Loss: 0.0741\n",
      "Step 252/391, Loss: 0.0462\n",
      "Step 253/391, Loss: 0.0671\n",
      "Step 254/391, Loss: 0.0278\n",
      "Step 255/391, Loss: 0.0663\n",
      "Step 256/391, Loss: 0.0752\n",
      "Step 257/391, Loss: 0.0230\n",
      "Step 258/391, Loss: 0.0279\n",
      "Step 259/391, Loss: 0.0819\n",
      "Step 260/391, Loss: 0.0624\n",
      "Step 261/391, Loss: 0.2718\n",
      "Step 262/391, Loss: 0.0245\n",
      "Step 263/391, Loss: 0.0579\n",
      "Step 264/391, Loss: 0.0186\n",
      "Step 265/391, Loss: 0.0721\n",
      "Step 266/391, Loss: 0.0474\n",
      "Step 267/391, Loss: 0.0651\n",
      "Step 268/391, Loss: 0.0390\n",
      "Step 269/391, Loss: 0.0150\n",
      "Step 270/391, Loss: 0.0118\n",
      "Step 271/391, Loss: 0.0572\n",
      "Step 272/391, Loss: 0.0465\n",
      "Step 273/391, Loss: 0.0629\n",
      "Step 274/391, Loss: 0.0384\n",
      "Step 275/391, Loss: 0.0202\n",
      "Step 276/391, Loss: 0.0158\n",
      "Step 277/391, Loss: 0.0156\n",
      "Step 278/391, Loss: 0.0127\n",
      "Step 279/391, Loss: 0.0413\n",
      "Step 280/391, Loss: 0.0093\n",
      "Step 281/391, Loss: 0.0238\n",
      "Step 282/391, Loss: 0.0306\n",
      "Step 283/391, Loss: 0.0186\n",
      "Step 284/391, Loss: 0.0318\n",
      "Step 285/391, Loss: 0.0276\n",
      "Step 286/391, Loss: 0.0168\n",
      "Step 287/391, Loss: 0.0816\n",
      "Step 288/391, Loss: 0.0232\n",
      "Step 289/391, Loss: 0.0131\n",
      "Step 290/391, Loss: 0.0584\n",
      "Step 291/391, Loss: 0.0034\n",
      "Step 292/391, Loss: 0.1187\n",
      "Step 293/391, Loss: 0.1430\n",
      "Step 294/391, Loss: 0.0295\n",
      "Step 295/391, Loss: 0.0301\n",
      "Step 296/391, Loss: 0.0314\n",
      "Step 297/391, Loss: 0.0312\n",
      "Step 298/391, Loss: 0.2046\n",
      "Step 299/391, Loss: 0.0399\n",
      "Step 300/391, Loss: 0.0108\n",
      "Step 301/391, Loss: 0.0888\n",
      "Step 302/391, Loss: 0.0159\n",
      "Step 303/391, Loss: 0.0523\n",
      "Step 304/391, Loss: 0.0364\n",
      "Step 305/391, Loss: 0.0629\n",
      "Step 306/391, Loss: 0.0954\n",
      "Step 307/391, Loss: 0.0462\n",
      "Step 308/391, Loss: 0.0360\n",
      "Step 309/391, Loss: 0.0505\n",
      "Step 310/391, Loss: 0.1143\n",
      "Step 311/391, Loss: 0.0102\n",
      "Step 312/391, Loss: 0.0518\n",
      "Step 313/391, Loss: 0.1015\n",
      "Step 314/391, Loss: 0.1172\n",
      "Step 315/391, Loss: 0.0310\n",
      "Step 316/391, Loss: 0.0426\n",
      "Step 317/391, Loss: 0.0971\n",
      "Step 318/391, Loss: 0.0775\n",
      "Step 319/391, Loss: 0.0319\n",
      "Step 320/391, Loss: 0.1033\n",
      "Step 321/391, Loss: 0.0489\n",
      "Step 322/391, Loss: 0.0272\n",
      "Step 323/391, Loss: 0.0682\n",
      "Step 324/391, Loss: 0.1368\n",
      "Step 325/391, Loss: 0.1096\n",
      "Step 326/391, Loss: 0.0435\n",
      "Step 327/391, Loss: 0.1067\n",
      "Step 328/391, Loss: 0.0615\n",
      "Step 329/391, Loss: 0.0703\n",
      "Step 330/391, Loss: 0.0280\n",
      "Step 331/391, Loss: 0.0267\n",
      "Step 332/391, Loss: 0.0710\n",
      "Step 333/391, Loss: 0.0315\n",
      "Step 334/391, Loss: 0.0731\n",
      "Step 335/391, Loss: 0.0645\n",
      "Step 336/391, Loss: 0.0357\n",
      "Step 337/391, Loss: 0.0526\n",
      "Step 338/391, Loss: 0.0292\n",
      "Step 339/391, Loss: 0.0240\n",
      "Step 340/391, Loss: 0.0523\n",
      "Step 341/391, Loss: 0.0342\n",
      "Step 342/391, Loss: 0.1139\n",
      "Step 343/391, Loss: 0.0555\n",
      "Step 344/391, Loss: 0.0161\n",
      "Step 345/391, Loss: 0.0423\n",
      "Step 346/391, Loss: 0.0841\n",
      "Step 347/391, Loss: 0.1052\n",
      "Step 348/391, Loss: 0.0224\n",
      "Step 349/391, Loss: 0.0212\n",
      "Step 350/391, Loss: 0.0588\n",
      "Step 351/391, Loss: 0.0203\n",
      "Step 352/391, Loss: 0.0377\n",
      "Step 353/391, Loss: 0.0543\n",
      "Step 354/391, Loss: 0.0220\n",
      "Step 355/391, Loss: 0.0081\n",
      "Step 356/391, Loss: 0.0445\n",
      "Step 357/391, Loss: 0.0291\n",
      "Step 358/391, Loss: 0.0655\n",
      "Step 359/391, Loss: 0.0314\n",
      "Step 360/391, Loss: 0.0289\n",
      "Step 361/391, Loss: 0.0506\n",
      "Step 362/391, Loss: 0.0419\n",
      "Step 363/391, Loss: 0.0581\n",
      "Step 364/391, Loss: 0.0669\n",
      "Step 365/391, Loss: 0.0036\n",
      "Step 366/391, Loss: 0.0117\n",
      "Step 367/391, Loss: 0.0289\n",
      "Step 368/391, Loss: 0.0617\n",
      "Step 369/391, Loss: 0.0525\n",
      "Step 370/391, Loss: 0.0272\n",
      "Step 371/391, Loss: 0.0221\n",
      "Step 372/391, Loss: 0.0020\n",
      "Step 373/391, Loss: 0.0249\n",
      "Step 374/391, Loss: 0.0229\n",
      "Step 375/391, Loss: 0.0201\n",
      "Step 376/391, Loss: 0.0292\n",
      "Step 377/391, Loss: 0.0671\n",
      "Step 378/391, Loss: 0.0130\n",
      "Step 379/391, Loss: 0.1007\n",
      "Step 380/391, Loss: 0.0363\n",
      "Step 381/391, Loss: 0.0209\n",
      "Step 382/391, Loss: 0.0318\n",
      "Step 383/391, Loss: 0.0405\n",
      "Step 384/391, Loss: 0.0691\n",
      "Step 385/391, Loss: 0.0253\n",
      "Step 386/391, Loss: 0.0075\n",
      "Step 387/391, Loss: 0.0046\n",
      "Step 388/391, Loss: 0.0256\n",
      "Step 389/391, Loss: 0.0587\n",
      "Step 390/391, Loss: 0.0507\n",
      "Step 391/391, Loss: 0.1107\n",
      "Epoch 16/25, Average Train Loss: 0.0486\n",
      "Epoch 16/25, Average Validation Loss: 0.0792\n",
      "Step 1/391, Loss: 0.0745\n",
      "Step 2/391, Loss: 0.0530\n",
      "Step 3/391, Loss: 0.0690\n",
      "Step 4/391, Loss: 0.0761\n",
      "Step 5/391, Loss: 0.0080\n",
      "Step 6/391, Loss: 0.0575\n",
      "Step 7/391, Loss: 0.0247\n",
      "Step 8/391, Loss: 0.0388\n",
      "Step 9/391, Loss: 0.0309\n",
      "Step 10/391, Loss: 0.0438\n",
      "Step 11/391, Loss: 0.0677\n",
      "Step 12/391, Loss: 0.0469\n",
      "Step 13/391, Loss: 0.0430\n",
      "Step 14/391, Loss: 0.0392\n",
      "Step 15/391, Loss: 0.0161\n",
      "Step 16/391, Loss: 0.0427\n",
      "Step 17/391, Loss: 0.0565\n",
      "Step 18/391, Loss: 0.0229\n",
      "Step 19/391, Loss: 0.0945\n",
      "Step 20/391, Loss: 0.1089\n",
      "Step 21/391, Loss: 0.0185\n",
      "Step 22/391, Loss: 0.0146\n",
      "Step 23/391, Loss: 0.0794\n",
      "Step 24/391, Loss: 0.0121\n",
      "Step 25/391, Loss: 0.0872\n",
      "Step 26/391, Loss: 0.0621\n",
      "Step 27/391, Loss: 0.1132\n",
      "Step 28/391, Loss: 0.0613\n",
      "Step 29/391, Loss: 0.0591\n",
      "Step 30/391, Loss: 0.0086\n",
      "Step 31/391, Loss: 0.0127\n",
      "Step 32/391, Loss: 0.0358\n",
      "Step 33/391, Loss: 0.0291\n",
      "Step 34/391, Loss: 0.0156\n",
      "Step 35/391, Loss: 0.0301\n",
      "Step 36/391, Loss: 0.0274\n",
      "Step 37/391, Loss: 0.0167\n",
      "Step 38/391, Loss: 0.0450\n",
      "Step 39/391, Loss: 0.0471\n",
      "Step 40/391, Loss: 0.0560\n",
      "Step 41/391, Loss: 0.0408\n",
      "Step 42/391, Loss: 0.0572\n",
      "Step 43/391, Loss: 0.0541\n",
      "Step 44/391, Loss: 0.0040\n",
      "Step 45/391, Loss: 0.0494\n",
      "Step 46/391, Loss: 0.0531\n",
      "Step 47/391, Loss: 0.0434\n",
      "Step 48/391, Loss: 0.0064\n",
      "Step 49/391, Loss: 0.1079\n",
      "Step 50/391, Loss: 0.0488\n",
      "Step 51/391, Loss: 0.0422\n",
      "Step 52/391, Loss: 0.0151\n",
      "Step 53/391, Loss: 0.0106\n",
      "Step 54/391, Loss: 0.1006\n",
      "Step 55/391, Loss: 0.0235\n",
      "Step 56/391, Loss: 0.0935\n",
      "Step 57/391, Loss: 0.0834\n",
      "Step 58/391, Loss: 0.0447\n",
      "Step 59/391, Loss: 0.0389\n",
      "Step 60/391, Loss: 0.0190\n",
      "Step 61/391, Loss: 0.0768\n",
      "Step 62/391, Loss: 0.0107\n",
      "Step 63/391, Loss: 0.0358\n",
      "Step 64/391, Loss: 0.0883\n",
      "Step 65/391, Loss: 0.0597\n",
      "Step 66/391, Loss: 0.0242\n",
      "Step 67/391, Loss: 0.0326\n",
      "Step 68/391, Loss: 0.0617\n",
      "Step 69/391, Loss: 0.0803\n",
      "Step 70/391, Loss: 0.0246\n",
      "Step 71/391, Loss: 0.0584\n",
      "Step 72/391, Loss: 0.0317\n",
      "Step 73/391, Loss: 0.0387\n",
      "Step 74/391, Loss: 0.0658\n",
      "Step 75/391, Loss: 0.0991\n",
      "Step 76/391, Loss: 0.0735\n",
      "Step 77/391, Loss: 0.0357\n",
      "Step 78/391, Loss: 0.0487\n",
      "Step 79/391, Loss: 0.0142\n",
      "Step 80/391, Loss: 0.0085\n",
      "Step 81/391, Loss: 0.0371\n",
      "Step 82/391, Loss: 0.0409\n",
      "Step 83/391, Loss: 0.0615\n",
      "Step 84/391, Loss: 0.0180\n",
      "Step 85/391, Loss: 0.0087\n",
      "Step 86/391, Loss: 0.0470\n",
      "Step 87/391, Loss: 0.0575\n",
      "Step 88/391, Loss: 0.0127\n",
      "Step 89/391, Loss: 0.0080\n",
      "Step 90/391, Loss: 0.0179\n",
      "Step 91/391, Loss: 0.0344\n",
      "Step 92/391, Loss: 0.0177\n",
      "Step 93/391, Loss: 0.0626\n",
      "Step 94/391, Loss: 0.0303\n",
      "Step 95/391, Loss: 0.0092\n",
      "Step 96/391, Loss: 0.0084\n",
      "Step 97/391, Loss: 0.0050\n",
      "Step 98/391, Loss: 0.0436\n",
      "Step 99/391, Loss: 0.0365\n",
      "Step 100/391, Loss: 0.0388\n",
      "Step 101/391, Loss: 0.0372\n",
      "Step 102/391, Loss: 0.0249\n",
      "Step 103/391, Loss: 0.0562\n",
      "Step 104/391, Loss: 0.0456\n",
      "Step 105/391, Loss: 0.0320\n",
      "Step 106/391, Loss: 0.0864\n",
      "Step 107/391, Loss: 0.0145\n",
      "Step 108/391, Loss: 0.0307\n",
      "Step 109/391, Loss: 0.0693\n",
      "Step 110/391, Loss: 0.0091\n",
      "Step 111/391, Loss: 0.0474\n",
      "Step 112/391, Loss: 0.0392\n",
      "Step 113/391, Loss: 0.0363\n",
      "Step 114/391, Loss: 0.0361\n",
      "Step 115/391, Loss: 0.0178\n",
      "Step 116/391, Loss: 0.0313\n",
      "Step 117/391, Loss: 0.0491\n",
      "Step 118/391, Loss: 0.0139\n",
      "Step 119/391, Loss: 0.0436\n",
      "Step 120/391, Loss: 0.0102\n",
      "Step 121/391, Loss: 0.0157\n",
      "Step 122/391, Loss: 0.0264\n",
      "Step 123/391, Loss: 0.0411\n",
      "Step 124/391, Loss: 0.0424\n",
      "Step 125/391, Loss: 0.0162\n",
      "Step 126/391, Loss: 0.0480\n",
      "Step 127/391, Loss: 0.0586\n",
      "Step 128/391, Loss: 0.1488\n",
      "Step 129/391, Loss: 0.0424\n",
      "Step 130/391, Loss: 0.0647\n",
      "Step 131/391, Loss: 0.0407\n",
      "Step 132/391, Loss: 0.0451\n",
      "Step 133/391, Loss: 0.0301\n",
      "Step 134/391, Loss: 0.0510\n",
      "Step 135/391, Loss: 0.0046\n",
      "Step 136/391, Loss: 0.0618\n",
      "Step 137/391, Loss: 0.0362\n",
      "Step 138/391, Loss: 0.0268\n",
      "Step 139/391, Loss: 0.0337\n",
      "Step 140/391, Loss: 0.0107\n",
      "Step 141/391, Loss: 0.0184\n",
      "Step 142/391, Loss: 0.0024\n",
      "Step 143/391, Loss: 0.0449\n",
      "Step 144/391, Loss: 0.0427\n",
      "Step 145/391, Loss: 0.0302\n",
      "Step 146/391, Loss: 0.0111\n",
      "Step 147/391, Loss: 0.1245\n",
      "Step 148/391, Loss: 0.0517\n",
      "Step 149/391, Loss: 0.0779\n",
      "Step 150/391, Loss: 0.0268\n",
      "Step 151/391, Loss: 0.0852\n",
      "Step 152/391, Loss: 0.0693\n",
      "Step 153/391, Loss: 0.0449\n",
      "Step 154/391, Loss: 0.0346\n",
      "Step 155/391, Loss: 0.0831\n",
      "Step 156/391, Loss: 0.0369\n",
      "Step 157/391, Loss: 0.0365\n",
      "Step 158/391, Loss: 0.0334\n",
      "Step 159/391, Loss: 0.1461\n",
      "Step 160/391, Loss: 0.0040\n",
      "Step 161/391, Loss: 0.0137\n",
      "Step 162/391, Loss: 0.0235\n",
      "Step 163/391, Loss: 0.0037\n",
      "Step 164/391, Loss: 0.1074\n",
      "Step 165/391, Loss: 0.0176\n",
      "Step 166/391, Loss: 0.0446\n",
      "Step 167/391, Loss: 0.0259\n",
      "Step 168/391, Loss: 0.0432\n",
      "Step 169/391, Loss: 0.0250\n",
      "Step 170/391, Loss: 0.0656\n",
      "Step 171/391, Loss: 0.0645\n",
      "Step 172/391, Loss: 0.1015\n",
      "Step 173/391, Loss: 0.0554\n",
      "Step 174/391, Loss: 0.0479\n",
      "Step 175/391, Loss: 0.0590\n",
      "Step 176/391, Loss: 0.0333\n",
      "Step 177/391, Loss: 0.0168\n",
      "Step 178/391, Loss: 0.0519\n",
      "Step 179/391, Loss: 0.0534\n",
      "Step 180/391, Loss: 0.0050\n",
      "Step 181/391, Loss: 0.0159\n",
      "Step 182/391, Loss: 0.0334\n",
      "Step 183/391, Loss: 0.0290\n",
      "Step 184/391, Loss: 0.0359\n",
      "Step 185/391, Loss: 0.0093\n",
      "Step 186/391, Loss: 0.0477\n",
      "Step 187/391, Loss: 0.0116\n",
      "Step 188/391, Loss: 0.0204\n",
      "Step 189/391, Loss: 0.0177\n",
      "Step 190/391, Loss: 0.1401\n",
      "Step 191/391, Loss: 0.0112\n",
      "Step 192/391, Loss: 0.0176\n",
      "Step 193/391, Loss: 0.0219\n",
      "Step 194/391, Loss: 0.0179\n",
      "Step 195/391, Loss: 0.0057\n",
      "Step 196/391, Loss: 0.1164\n",
      "Step 197/391, Loss: 0.0448\n",
      "Step 198/391, Loss: 0.0796\n",
      "Step 199/391, Loss: 0.0368\n",
      "Step 200/391, Loss: 0.0153\n",
      "Step 201/391, Loss: 0.1093\n",
      "Step 202/391, Loss: 0.0205\n",
      "Step 203/391, Loss: 0.0567\n",
      "Step 204/391, Loss: 0.0260\n",
      "Step 205/391, Loss: 0.0378\n",
      "Step 206/391, Loss: 0.0272\n",
      "Step 207/391, Loss: 0.0247\n",
      "Step 208/391, Loss: 0.0732\n",
      "Step 209/391, Loss: 0.0994\n",
      "Step 210/391, Loss: 0.0340\n",
      "Step 211/391, Loss: 0.0227\n",
      "Step 212/391, Loss: 0.0306\n",
      "Step 213/391, Loss: 0.1253\n",
      "Step 214/391, Loss: 0.0607\n",
      "Step 215/391, Loss: 0.0019\n",
      "Step 216/391, Loss: 0.0949\n",
      "Step 217/391, Loss: 0.0362\n",
      "Step 218/391, Loss: 0.0498\n",
      "Step 219/391, Loss: 0.0072\n",
      "Step 220/391, Loss: 0.0403\n",
      "Step 221/391, Loss: 0.0146\n",
      "Step 222/391, Loss: 0.0306\n",
      "Step 223/391, Loss: 0.0502\n",
      "Step 224/391, Loss: 0.0495\n",
      "Step 225/391, Loss: 0.0536\n",
      "Step 226/391, Loss: 0.0540\n",
      "Step 227/391, Loss: 0.0199\n",
      "Step 228/391, Loss: 0.0506\n",
      "Step 229/391, Loss: 0.0244\n",
      "Step 230/391, Loss: 0.0334\n",
      "Step 231/391, Loss: 0.0287\n",
      "Step 232/391, Loss: 0.0403\n",
      "Step 233/391, Loss: 0.0478\n",
      "Step 234/391, Loss: 0.0224\n",
      "Step 235/391, Loss: 0.0183\n",
      "Step 236/391, Loss: 0.0437\n",
      "Step 237/391, Loss: 0.0224\n",
      "Step 238/391, Loss: 0.0071\n",
      "Step 239/391, Loss: 0.0233\n",
      "Step 240/391, Loss: 0.0298\n",
      "Step 241/391, Loss: 0.0351\n",
      "Step 242/391, Loss: 0.0095\n",
      "Step 243/391, Loss: 0.0981\n",
      "Step 244/391, Loss: 0.0103\n",
      "Step 245/391, Loss: 0.0559\n",
      "Step 246/391, Loss: 0.0169\n",
      "Step 247/391, Loss: 0.0643\n",
      "Step 248/391, Loss: 0.0055\n",
      "Step 249/391, Loss: 0.0133\n",
      "Step 250/391, Loss: 0.1155\n",
      "Step 251/391, Loss: 0.0136\n",
      "Step 252/391, Loss: 0.0200\n",
      "Step 253/391, Loss: 0.0414\n",
      "Step 254/391, Loss: 0.0727\n",
      "Step 255/391, Loss: 0.0910\n",
      "Step 256/391, Loss: 0.0430\n",
      "Step 257/391, Loss: 0.0269\n",
      "Step 258/391, Loss: 0.0409\n",
      "Step 259/391, Loss: 0.0014\n",
      "Step 260/391, Loss: 0.1319\n",
      "Step 261/391, Loss: 0.0437\n",
      "Step 262/391, Loss: 0.0131\n",
      "Step 263/391, Loss: 0.0286\n",
      "Step 264/391, Loss: 0.0465\n",
      "Step 265/391, Loss: 0.0177\n",
      "Step 266/391, Loss: 0.0563\n",
      "Step 267/391, Loss: 0.0270\n",
      "Step 268/391, Loss: 0.1286\n",
      "Step 269/391, Loss: 0.0763\n",
      "Step 270/391, Loss: 0.0452\n",
      "Step 271/391, Loss: 0.0422\n",
      "Step 272/391, Loss: 0.0399\n",
      "Step 273/391, Loss: 0.1258\n",
      "Step 274/391, Loss: 0.0442\n",
      "Step 275/391, Loss: 0.0357\n",
      "Step 276/391, Loss: 0.0432\n",
      "Step 277/391, Loss: 0.0378\n",
      "Step 278/391, Loss: 0.0672\n",
      "Step 279/391, Loss: 0.0490\n",
      "Step 280/391, Loss: 0.0213\n",
      "Step 281/391, Loss: 0.0577\n",
      "Step 282/391, Loss: 0.0318\n",
      "Step 283/391, Loss: 0.0408\n",
      "Step 284/391, Loss: 0.0320\n",
      "Step 285/391, Loss: 0.0096\n",
      "Step 286/391, Loss: 0.0299\n",
      "Step 287/391, Loss: 0.0076\n",
      "Step 288/391, Loss: 0.0397\n",
      "Step 289/391, Loss: 0.0273\n",
      "Step 290/391, Loss: 0.0734\n",
      "Step 291/391, Loss: 0.0245\n",
      "Step 292/391, Loss: 0.0116\n",
      "Step 293/391, Loss: 0.0146\n",
      "Step 294/391, Loss: 0.0836\n",
      "Step 295/391, Loss: 0.0458\n",
      "Step 296/391, Loss: 0.0506\n",
      "Step 297/391, Loss: 0.0218\n",
      "Step 298/391, Loss: 0.0332\n",
      "Step 299/391, Loss: 0.0236\n",
      "Step 300/391, Loss: 0.1232\n",
      "Step 301/391, Loss: 0.0108\n",
      "Step 302/391, Loss: 0.0452\n",
      "Step 303/391, Loss: 0.0893\n",
      "Step 304/391, Loss: 0.0289\n",
      "Step 305/391, Loss: 0.0176\n",
      "Step 306/391, Loss: 0.0341\n",
      "Step 307/391, Loss: 0.1129\n",
      "Step 308/391, Loss: 0.0075\n",
      "Step 309/391, Loss: 0.0515\n",
      "Step 310/391, Loss: 0.0900\n",
      "Step 311/391, Loss: 0.0378\n",
      "Step 312/391, Loss: 0.0873\n",
      "Step 313/391, Loss: 0.0308\n",
      "Step 314/391, Loss: 0.0260\n",
      "Step 315/391, Loss: 0.0472\n",
      "Step 316/391, Loss: 0.0435\n",
      "Step 317/391, Loss: 0.0161\n",
      "Step 318/391, Loss: 0.0159\n",
      "Step 319/391, Loss: 0.0238\n",
      "Step 320/391, Loss: 0.0399\n",
      "Step 321/391, Loss: 0.0076\n",
      "Step 322/391, Loss: 0.0222\n",
      "Step 323/391, Loss: 0.0320\n",
      "Step 324/391, Loss: 0.1880\n",
      "Step 325/391, Loss: 0.0373\n",
      "Step 326/391, Loss: 0.0666\n",
      "Step 327/391, Loss: 0.1113\n",
      "Step 328/391, Loss: 0.0098\n",
      "Step 329/391, Loss: 0.0277\n",
      "Step 330/391, Loss: 0.0678\n",
      "Step 331/391, Loss: 0.0205\n",
      "Step 332/391, Loss: 0.0334\n",
      "Step 333/391, Loss: 0.0306\n",
      "Step 334/391, Loss: 0.0739\n",
      "Step 335/391, Loss: 0.0309\n",
      "Step 336/391, Loss: 0.0158\n",
      "Step 337/391, Loss: 0.0919\n",
      "Step 338/391, Loss: 0.0832\n",
      "Step 339/391, Loss: 0.0148\n",
      "Step 340/391, Loss: 0.0145\n",
      "Step 341/391, Loss: 0.0826\n",
      "Step 342/391, Loss: 0.0571\n",
      "Step 343/391, Loss: 0.0721\n",
      "Step 344/391, Loss: 0.0377\n",
      "Step 345/391, Loss: 0.0342\n",
      "Step 346/391, Loss: 0.0405\n",
      "Step 347/391, Loss: 0.0328\n",
      "Step 348/391, Loss: 0.0105\n",
      "Step 349/391, Loss: 0.0241\n",
      "Step 350/391, Loss: 0.0761\n",
      "Step 351/391, Loss: 0.0924\n",
      "Step 352/391, Loss: 0.0867\n",
      "Step 353/391, Loss: 0.0124\n",
      "Step 354/391, Loss: 0.1636\n",
      "Step 355/391, Loss: 0.0505\n",
      "Step 356/391, Loss: 0.0300\n",
      "Step 357/391, Loss: 0.0143\n",
      "Step 358/391, Loss: 0.0285\n",
      "Step 359/391, Loss: 0.0553\n",
      "Step 360/391, Loss: 0.0186\n",
      "Step 361/391, Loss: 0.0193\n",
      "Step 362/391, Loss: 0.0712\n",
      "Step 363/391, Loss: 0.0959\n",
      "Step 364/391, Loss: 0.0332\n",
      "Step 365/391, Loss: 0.0582\n",
      "Step 366/391, Loss: 0.0143\n",
      "Step 367/391, Loss: 0.0686\n",
      "Step 368/391, Loss: 0.0987\n",
      "Step 369/391, Loss: 0.0316\n",
      "Step 370/391, Loss: 0.0473\n",
      "Step 371/391, Loss: 0.0733\n",
      "Step 372/391, Loss: 0.0633\n",
      "Step 373/391, Loss: 0.0495\n",
      "Step 374/391, Loss: 0.0422\n",
      "Step 375/391, Loss: 0.0593\n",
      "Step 376/391, Loss: 0.0184\n",
      "Step 377/391, Loss: 0.0563\n",
      "Step 378/391, Loss: 0.0577\n",
      "Step 379/391, Loss: 0.0555\n",
      "Step 380/391, Loss: 0.0767\n",
      "Step 381/391, Loss: 0.0108\n",
      "Step 382/391, Loss: 0.0271\n",
      "Step 383/391, Loss: 0.0488\n",
      "Step 384/391, Loss: 0.0313\n",
      "Step 385/391, Loss: 0.0614\n",
      "Step 386/391, Loss: 0.0554\n",
      "Step 387/391, Loss: 0.0875\n",
      "Step 388/391, Loss: 0.0161\n",
      "Step 389/391, Loss: 0.0447\n",
      "Step 390/391, Loss: 0.0031\n",
      "Step 391/391, Loss: 0.0267\n",
      "Epoch 17/25, Average Train Loss: 0.0440\n",
      "Epoch 17/25, Average Validation Loss: 0.0824\n",
      "Step 1/391, Loss: 0.0190\n",
      "Step 2/391, Loss: 0.0429\n",
      "Step 3/391, Loss: 0.0597\n",
      "Step 4/391, Loss: 0.0121\n",
      "Step 5/391, Loss: 0.0289\n",
      "Step 6/391, Loss: 0.0558\n",
      "Step 7/391, Loss: 0.0017\n",
      "Step 8/391, Loss: 0.0361\n",
      "Step 9/391, Loss: 0.0036\n",
      "Step 10/391, Loss: 0.0162\n",
      "Step 11/391, Loss: 0.0340\n",
      "Step 12/391, Loss: 0.0273\n",
      "Step 13/391, Loss: 0.0237\n",
      "Step 14/391, Loss: 0.0482\n",
      "Step 15/391, Loss: 0.0164\n",
      "Step 16/391, Loss: 0.0838\n",
      "Step 17/391, Loss: 0.0679\n",
      "Step 18/391, Loss: 0.0825\n",
      "Step 19/391, Loss: 0.0533\n",
      "Step 20/391, Loss: 0.1979\n",
      "Step 21/391, Loss: 0.0616\n",
      "Step 22/391, Loss: 0.0099\n",
      "Step 23/391, Loss: 0.0040\n",
      "Step 24/391, Loss: 0.0335\n",
      "Step 25/391, Loss: 0.0339\n",
      "Step 26/391, Loss: 0.0274\n",
      "Step 27/391, Loss: 0.0101\n",
      "Step 28/391, Loss: 0.0270\n",
      "Step 29/391, Loss: 0.0827\n",
      "Step 30/391, Loss: 0.0766\n",
      "Step 31/391, Loss: 0.0814\n",
      "Step 32/391, Loss: 0.0294\n",
      "Step 33/391, Loss: 0.0260\n",
      "Step 34/391, Loss: 0.0241\n",
      "Step 35/391, Loss: 0.0285\n",
      "Step 36/391, Loss: 0.0775\n",
      "Step 37/391, Loss: 0.0240\n",
      "Step 38/391, Loss: 0.0055\n",
      "Step 39/391, Loss: 0.0046\n",
      "Step 40/391, Loss: 0.0463\n",
      "Step 41/391, Loss: 0.0361\n",
      "Step 42/391, Loss: 0.1543\n",
      "Step 43/391, Loss: 0.0039\n",
      "Step 44/391, Loss: 0.0090\n",
      "Step 45/391, Loss: 0.0383\n",
      "Step 46/391, Loss: 0.0976\n",
      "Step 47/391, Loss: 0.0919\n",
      "Step 48/391, Loss: 0.0191\n",
      "Step 49/391, Loss: 0.1313\n",
      "Step 50/391, Loss: 0.0322\n",
      "Step 51/391, Loss: 0.0350\n",
      "Step 52/391, Loss: 0.0137\n",
      "Step 53/391, Loss: 0.0163\n",
      "Step 54/391, Loss: 0.0209\n",
      "Step 55/391, Loss: 0.0320\n",
      "Step 56/391, Loss: 0.0672\n",
      "Step 57/391, Loss: 0.0295\n",
      "Step 58/391, Loss: 0.0530\n",
      "Step 59/391, Loss: 0.0336\n",
      "Step 60/391, Loss: 0.0342\n",
      "Step 61/391, Loss: 0.0847\n",
      "Step 62/391, Loss: 0.0118\n",
      "Step 63/391, Loss: 0.0619\n",
      "Step 64/391, Loss: 0.0883\n",
      "Step 65/391, Loss: 0.0870\n",
      "Step 66/391, Loss: 0.0291\n",
      "Step 67/391, Loss: 0.0221\n",
      "Step 68/391, Loss: 0.0403\n",
      "Step 69/391, Loss: 0.0167\n",
      "Step 70/391, Loss: 0.0494\n",
      "Step 71/391, Loss: 0.0208\n",
      "Step 72/391, Loss: 0.0495\n",
      "Step 73/391, Loss: 0.0578\n",
      "Step 74/391, Loss: 0.0626\n",
      "Step 75/391, Loss: 0.0526\n",
      "Step 76/391, Loss: 0.0153\n",
      "Step 77/391, Loss: 0.0057\n",
      "Step 78/391, Loss: 0.0613\n",
      "Step 79/391, Loss: 0.0212\n",
      "Step 80/391, Loss: 0.0069\n",
      "Step 81/391, Loss: 0.0133\n",
      "Step 82/391, Loss: 0.0069\n",
      "Step 83/391, Loss: 0.0373\n",
      "Step 84/391, Loss: 0.0329\n",
      "Step 85/391, Loss: 0.0249\n",
      "Step 86/391, Loss: 0.0777\n",
      "Step 87/391, Loss: 0.0160\n",
      "Step 88/391, Loss: 0.0307\n",
      "Step 89/391, Loss: 0.0225\n",
      "Step 90/391, Loss: 0.0671\n",
      "Step 91/391, Loss: 0.0576\n",
      "Step 92/391, Loss: 0.0637\n",
      "Step 93/391, Loss: 0.0584\n",
      "Step 94/391, Loss: 0.0743\n",
      "Step 95/391, Loss: 0.0430\n",
      "Step 96/391, Loss: 0.0203\n",
      "Step 97/391, Loss: 0.0114\n",
      "Step 98/391, Loss: 0.0518\n",
      "Step 99/391, Loss: 0.0431\n",
      "Step 100/391, Loss: 0.1034\n",
      "Step 101/391, Loss: 0.0794\n",
      "Step 102/391, Loss: 0.0279\n",
      "Step 103/391, Loss: 0.0291\n",
      "Step 104/391, Loss: 0.0159\n",
      "Step 105/391, Loss: 0.0739\n",
      "Step 106/391, Loss: 0.0050\n",
      "Step 107/391, Loss: 0.0452\n",
      "Step 108/391, Loss: 0.0460\n",
      "Step 109/391, Loss: 0.0570\n",
      "Step 110/391, Loss: 0.0332\n",
      "Step 111/391, Loss: 0.0320\n",
      "Step 112/391, Loss: 0.0357\n",
      "Step 113/391, Loss: 0.0296\n",
      "Step 114/391, Loss: 0.0223\n",
      "Step 115/391, Loss: 0.0770\n",
      "Step 116/391, Loss: 0.0623\n",
      "Step 117/391, Loss: 0.0201\n",
      "Step 118/391, Loss: 0.0172\n",
      "Step 119/391, Loss: 0.0142\n",
      "Step 120/391, Loss: 0.0688\n",
      "Step 121/391, Loss: 0.0606\n",
      "Step 122/391, Loss: 0.0409\n",
      "Step 123/391, Loss: 0.0430\n",
      "Step 124/391, Loss: 0.0667\n",
      "Step 125/391, Loss: 0.1191\n",
      "Step 126/391, Loss: 0.0038\n",
      "Step 127/391, Loss: 0.1044\n",
      "Step 128/391, Loss: 0.0049\n",
      "Step 129/391, Loss: 0.0221\n",
      "Step 130/391, Loss: 0.0264\n",
      "Step 131/391, Loss: 0.0304\n",
      "Step 132/391, Loss: 0.0446\n",
      "Step 133/391, Loss: 0.0125\n",
      "Step 134/391, Loss: 0.0321\n",
      "Step 135/391, Loss: 0.0170\n",
      "Step 136/391, Loss: 0.0722\n",
      "Step 137/391, Loss: 0.0926\n",
      "Step 138/391, Loss: 0.0111\n",
      "Step 139/391, Loss: 0.0179\n",
      "Step 140/391, Loss: 0.0271\n",
      "Step 141/391, Loss: 0.0478\n",
      "Step 142/391, Loss: 0.1008\n",
      "Step 143/391, Loss: 0.0100\n",
      "Step 144/391, Loss: 0.0527\n",
      "Step 145/391, Loss: 0.0431\n",
      "Step 146/391, Loss: 0.0136\n",
      "Step 147/391, Loss: 0.0315\n",
      "Step 148/391, Loss: 0.0655\n",
      "Step 149/391, Loss: 0.0728\n",
      "Step 150/391, Loss: 0.0374\n",
      "Step 151/391, Loss: 0.0826\n",
      "Step 152/391, Loss: 0.0522\n",
      "Step 153/391, Loss: 0.0363\n",
      "Step 154/391, Loss: 0.0194\n",
      "Step 155/391, Loss: 0.0501\n",
      "Step 156/391, Loss: 0.0208\n",
      "Step 157/391, Loss: 0.0151\n",
      "Step 158/391, Loss: 0.0572\n",
      "Step 159/391, Loss: 0.0079\n",
      "Step 160/391, Loss: 0.0501\n",
      "Step 161/391, Loss: 0.0198\n",
      "Step 162/391, Loss: 0.0410\n",
      "Step 163/391, Loss: 0.0032\n",
      "Step 164/391, Loss: 0.0296\n",
      "Step 165/391, Loss: 0.0350\n",
      "Step 166/391, Loss: 0.0579\n",
      "Step 167/391, Loss: 0.0399\n",
      "Step 168/391, Loss: 0.0159\n",
      "Step 169/391, Loss: 0.0293\n",
      "Step 170/391, Loss: 0.0239\n",
      "Step 171/391, Loss: 0.0701\n",
      "Step 172/391, Loss: 0.0219\n",
      "Step 173/391, Loss: 0.0100\n",
      "Step 174/391, Loss: 0.0089\n",
      "Step 175/391, Loss: 0.0297\n",
      "Step 176/391, Loss: 0.0366\n",
      "Step 177/391, Loss: 0.0629\n",
      "Step 178/391, Loss: 0.0549\n",
      "Step 179/391, Loss: 0.0246\n",
      "Step 180/391, Loss: 0.0188\n",
      "Step 181/391, Loss: 0.0210\n",
      "Step 182/391, Loss: 0.0117\n",
      "Step 183/391, Loss: 0.0970\n",
      "Step 184/391, Loss: 0.0093\n",
      "Step 185/391, Loss: 0.0136\n",
      "Step 186/391, Loss: 0.0657\n",
      "Step 187/391, Loss: 0.0206\n",
      "Step 188/391, Loss: 0.0207\n",
      "Step 189/391, Loss: 0.1036\n",
      "Step 190/391, Loss: 0.0204\n",
      "Step 191/391, Loss: 0.0156\n",
      "Step 192/391, Loss: 0.0551\n",
      "Step 193/391, Loss: 0.0244\n",
      "Step 194/391, Loss: 0.1098\n",
      "Step 195/391, Loss: 0.0300\n",
      "Step 196/391, Loss: 0.0052\n",
      "Step 197/391, Loss: 0.0637\n",
      "Step 198/391, Loss: 0.0245\n",
      "Step 199/391, Loss: 0.0556\n",
      "Step 200/391, Loss: 0.0658\n",
      "Step 201/391, Loss: 0.0392\n",
      "Step 202/391, Loss: 0.0045\n",
      "Step 203/391, Loss: 0.0562\n",
      "Step 204/391, Loss: 0.0135\n",
      "Step 205/391, Loss: 0.0237\n",
      "Step 206/391, Loss: 0.0356\n",
      "Step 207/391, Loss: 0.0228\n",
      "Step 208/391, Loss: 0.0596\n",
      "Step 209/391, Loss: 0.0339\n",
      "Step 210/391, Loss: 0.0393\n",
      "Step 211/391, Loss: 0.0050\n",
      "Step 212/391, Loss: 0.0177\n",
      "Step 213/391, Loss: 0.0742\n",
      "Step 214/391, Loss: 0.0095\n",
      "Step 215/391, Loss: 0.0179\n",
      "Step 216/391, Loss: 0.0320\n",
      "Step 217/391, Loss: 0.0913\n",
      "Step 218/391, Loss: 0.0091\n",
      "Step 219/391, Loss: 0.0152\n",
      "Step 220/391, Loss: 0.0264\n",
      "Step 221/391, Loss: 0.0341\n",
      "Step 222/391, Loss: 0.0466\n",
      "Step 223/391, Loss: 0.0311\n",
      "Step 224/391, Loss: 0.0303\n",
      "Step 225/391, Loss: 0.0287\n",
      "Step 226/391, Loss: 0.0517\n",
      "Step 227/391, Loss: 0.1177\n",
      "Step 228/391, Loss: 0.0173\n",
      "Step 229/391, Loss: 0.0115\n",
      "Step 230/391, Loss: 0.0473\n",
      "Step 231/391, Loss: 0.0599\n",
      "Step 232/391, Loss: 0.0789\n",
      "Step 233/391, Loss: 0.0754\n",
      "Step 234/391, Loss: 0.0239\n",
      "Step 235/391, Loss: 0.0447\n",
      "Step 236/391, Loss: 0.0369\n",
      "Step 237/391, Loss: 0.0235\n",
      "Step 238/391, Loss: 0.0969\n",
      "Step 239/391, Loss: 0.0389\n",
      "Step 240/391, Loss: 0.0171\n",
      "Step 241/391, Loss: 0.0939\n",
      "Step 242/391, Loss: 0.0105\n",
      "Step 243/391, Loss: 0.0277\n",
      "Step 244/391, Loss: 0.0254\n",
      "Step 245/391, Loss: 0.0305\n",
      "Step 246/391, Loss: 0.0342\n",
      "Step 247/391, Loss: 0.0639\n",
      "Step 248/391, Loss: 0.0146\n",
      "Step 249/391, Loss: 0.0285\n",
      "Step 250/391, Loss: 0.0129\n",
      "Step 251/391, Loss: 0.0843\n",
      "Step 252/391, Loss: 0.1260\n",
      "Step 253/391, Loss: 0.0580\n",
      "Step 254/391, Loss: 0.0771\n",
      "Step 255/391, Loss: 0.0319\n",
      "Step 256/391, Loss: 0.0092\n",
      "Step 257/391, Loss: 0.0077\n",
      "Step 258/391, Loss: 0.0379\n",
      "Step 259/391, Loss: 0.0918\n",
      "Step 260/391, Loss: 0.0980\n",
      "Step 261/391, Loss: 0.0196\n",
      "Step 262/391, Loss: 0.0070\n",
      "Step 263/391, Loss: 0.0870\n",
      "Step 264/391, Loss: 0.0335\n",
      "Step 265/391, Loss: 0.0372\n",
      "Step 266/391, Loss: 0.0659\n",
      "Step 267/391, Loss: 0.0851\n",
      "Step 268/391, Loss: 0.1127\n",
      "Step 269/391, Loss: 0.1042\n",
      "Step 270/391, Loss: 0.0244\n",
      "Step 271/391, Loss: 0.0369\n",
      "Step 272/391, Loss: 0.0710\n",
      "Step 273/391, Loss: 0.0993\n",
      "Step 274/391, Loss: 0.0593\n",
      "Step 275/391, Loss: 0.0131\n",
      "Step 276/391, Loss: 0.1126\n",
      "Step 277/391, Loss: 0.0093\n",
      "Step 278/391, Loss: 0.0350\n",
      "Step 279/391, Loss: 0.0243\n",
      "Step 280/391, Loss: 0.0455\n",
      "Step 281/391, Loss: 0.0287\n",
      "Step 282/391, Loss: 0.0989\n",
      "Step 283/391, Loss: 0.0138\n",
      "Step 284/391, Loss: 0.0975\n",
      "Step 285/391, Loss: 0.0966\n",
      "Step 286/391, Loss: 0.0699\n",
      "Step 287/391, Loss: 0.0725\n",
      "Step 288/391, Loss: 0.0591\n",
      "Step 289/391, Loss: 0.0292\n",
      "Step 290/391, Loss: 0.0317\n",
      "Step 291/391, Loss: 0.0180\n",
      "Step 292/391, Loss: 0.0668\n",
      "Step 293/391, Loss: 0.0417\n",
      "Step 294/391, Loss: 0.0393\n",
      "Step 295/391, Loss: 0.0302\n",
      "Step 296/391, Loss: 0.1015\n",
      "Step 297/391, Loss: 0.0120\n",
      "Step 298/391, Loss: 0.0323\n",
      "Step 299/391, Loss: 0.0520\n",
      "Step 300/391, Loss: 0.0594\n",
      "Step 301/391, Loss: 0.0985\n",
      "Step 302/391, Loss: 0.0489\n",
      "Step 303/391, Loss: 0.0213\n",
      "Step 304/391, Loss: 0.0218\n",
      "Step 305/391, Loss: 0.0999\n",
      "Step 306/391, Loss: 0.0235\n",
      "Step 307/391, Loss: 0.0738\n",
      "Step 308/391, Loss: 0.0121\n",
      "Step 309/391, Loss: 0.0695\n",
      "Step 310/391, Loss: 0.0239\n",
      "Step 311/391, Loss: 0.0454\n",
      "Step 312/391, Loss: 0.0183\n",
      "Step 313/391, Loss: 0.0909\n",
      "Step 314/391, Loss: 0.0756\n",
      "Step 315/391, Loss: 0.0216\n",
      "Step 316/391, Loss: 0.0187\n",
      "Step 317/391, Loss: 0.0394\n",
      "Step 318/391, Loss: 0.1600\n",
      "Step 319/391, Loss: 0.0725\n",
      "Step 320/391, Loss: 0.0419\n",
      "Step 321/391, Loss: 0.0576\n",
      "Step 322/391, Loss: 0.0709\n",
      "Step 323/391, Loss: 0.0422\n",
      "Step 324/391, Loss: 0.0271\n",
      "Step 325/391, Loss: 0.0232\n",
      "Step 326/391, Loss: 0.0651\n",
      "Step 327/391, Loss: 0.0552\n",
      "Step 328/391, Loss: 0.0603\n",
      "Step 329/391, Loss: 0.0328\n",
      "Step 330/391, Loss: 0.0410\n",
      "Step 331/391, Loss: 0.0664\n",
      "Step 332/391, Loss: 0.0086\n",
      "Step 333/391, Loss: 0.0530\n",
      "Step 334/391, Loss: 0.0589\n",
      "Step 335/391, Loss: 0.0215\n",
      "Step 336/391, Loss: 0.0248\n",
      "Step 337/391, Loss: 0.0768\n",
      "Step 338/391, Loss: 0.0907\n",
      "Step 339/391, Loss: 0.0280\n",
      "Step 340/391, Loss: 0.0868\n",
      "Step 341/391, Loss: 0.0118\n",
      "Step 342/391, Loss: 0.0323\n",
      "Step 343/391, Loss: 0.0413\n",
      "Step 344/391, Loss: 0.0419\n",
      "Step 345/391, Loss: 0.0420\n",
      "Step 346/391, Loss: 0.0877\n",
      "Step 347/391, Loss: 0.0401\n",
      "Step 348/391, Loss: 0.0067\n",
      "Step 349/391, Loss: 0.0283\n",
      "Step 350/391, Loss: 0.0114\n",
      "Step 351/391, Loss: 0.0583\n",
      "Step 352/391, Loss: 0.0553\n",
      "Step 353/391, Loss: 0.0963\n",
      "Step 354/391, Loss: 0.0488\n",
      "Step 355/391, Loss: 0.0755\n",
      "Step 356/391, Loss: 0.0104\n",
      "Step 357/391, Loss: 0.0193\n",
      "Step 358/391, Loss: 0.0471\n",
      "Step 359/391, Loss: 0.0963\n",
      "Step 360/391, Loss: 0.0857\n",
      "Step 361/391, Loss: 0.0147\n",
      "Step 362/391, Loss: 0.0437\n",
      "Step 363/391, Loss: 0.0198\n",
      "Step 364/391, Loss: 0.0345\n",
      "Step 365/391, Loss: 0.0962\n",
      "Step 366/391, Loss: 0.1196\n",
      "Step 367/391, Loss: 0.0848\n",
      "Step 368/391, Loss: 0.0474\n",
      "Step 369/391, Loss: 0.0070\n",
      "Step 370/391, Loss: 0.0198\n",
      "Step 371/391, Loss: 0.0086\n",
      "Step 372/391, Loss: 0.0321\n",
      "Step 373/391, Loss: 0.1179\n",
      "Step 374/391, Loss: 0.0187\n",
      "Step 375/391, Loss: 0.0752\n",
      "Step 376/391, Loss: 0.0323\n",
      "Step 377/391, Loss: 0.0697\n",
      "Step 378/391, Loss: 0.0285\n",
      "Step 379/391, Loss: 0.0482\n",
      "Step 380/391, Loss: 0.0268\n",
      "Step 381/391, Loss: 0.0873\n",
      "Step 382/391, Loss: 0.0302\n",
      "Step 383/391, Loss: 0.0407\n",
      "Step 384/391, Loss: 0.0292\n",
      "Step 385/391, Loss: 0.0796\n",
      "Step 386/391, Loss: 0.0759\n",
      "Step 387/391, Loss: 0.0105\n",
      "Step 388/391, Loss: 0.0407\n",
      "Step 389/391, Loss: 0.0348\n",
      "Step 390/391, Loss: 0.0335\n",
      "Step 391/391, Loss: 0.0264\n",
      "Epoch 18/25, Average Train Loss: 0.0443\n",
      "Epoch 18/25, Average Validation Loss: 0.0743\n",
      "Model saved at epoch 18 with validation loss: 0.0743\n",
      "Step 1/391, Loss: 0.0284\n",
      "Step 2/391, Loss: 0.0766\n",
      "Step 3/391, Loss: 0.0416\n",
      "Step 4/391, Loss: 0.0146\n",
      "Step 5/391, Loss: 0.1372\n",
      "Step 6/391, Loss: 0.0123\n",
      "Step 7/391, Loss: 0.0384\n",
      "Step 8/391, Loss: 0.0140\n",
      "Step 9/391, Loss: 0.0859\n",
      "Step 10/391, Loss: 0.0030\n",
      "Step 11/391, Loss: 0.0232\n",
      "Step 12/391, Loss: 0.0671\n",
      "Step 13/391, Loss: 0.0163\n",
      "Step 14/391, Loss: 0.0273\n",
      "Step 15/391, Loss: 0.0164\n",
      "Step 16/391, Loss: 0.0201\n",
      "Step 17/391, Loss: 0.0623\n",
      "Step 18/391, Loss: 0.0444\n",
      "Step 19/391, Loss: 0.0558\n",
      "Step 20/391, Loss: 0.0311\n",
      "Step 21/391, Loss: 0.0139\n",
      "Step 22/391, Loss: 0.0380\n",
      "Step 23/391, Loss: 0.0238\n",
      "Step 24/391, Loss: 0.0344\n",
      "Step 25/391, Loss: 0.0290\n",
      "Step 26/391, Loss: 0.0257\n",
      "Step 27/391, Loss: 0.0304\n",
      "Step 28/391, Loss: 0.0215\n",
      "Step 29/391, Loss: 0.0373\n",
      "Step 30/391, Loss: 0.0170\n",
      "Step 31/391, Loss: 0.0885\n",
      "Step 32/391, Loss: 0.1093\n",
      "Step 33/391, Loss: 0.0238\n",
      "Step 34/391, Loss: 0.0250\n",
      "Step 35/391, Loss: 0.0808\n",
      "Step 36/391, Loss: 0.0178\n",
      "Step 37/391, Loss: 0.0461\n",
      "Step 38/391, Loss: 0.1170\n",
      "Step 39/391, Loss: 0.0069\n",
      "Step 40/391, Loss: 0.0059\n",
      "Step 41/391, Loss: 0.0386\n",
      "Step 42/391, Loss: 0.0073\n",
      "Step 43/391, Loss: 0.0452\n",
      "Step 44/391, Loss: 0.0102\n",
      "Step 45/391, Loss: 0.1246\n",
      "Step 46/391, Loss: 0.0214\n",
      "Step 47/391, Loss: 0.0584\n",
      "Step 48/391, Loss: 0.0270\n",
      "Step 49/391, Loss: 0.0273\n",
      "Step 50/391, Loss: 0.2166\n",
      "Step 51/391, Loss: 0.0319\n",
      "Step 52/391, Loss: 0.0435\n",
      "Step 53/391, Loss: 0.0926\n",
      "Step 54/391, Loss: 0.0958\n",
      "Step 55/391, Loss: 0.0439\n",
      "Step 56/391, Loss: 0.0275\n",
      "Step 57/391, Loss: 0.0423\n",
      "Step 58/391, Loss: 0.0034\n",
      "Step 59/391, Loss: 0.0383\n",
      "Step 60/391, Loss: 0.0225\n",
      "Step 61/391, Loss: 0.0564\n",
      "Step 62/391, Loss: 0.0846\n",
      "Step 63/391, Loss: 0.0431\n",
      "Step 64/391, Loss: 0.0259\n",
      "Step 65/391, Loss: 0.0472\n",
      "Step 66/391, Loss: 0.0590\n",
      "Step 67/391, Loss: 0.0236\n",
      "Step 68/391, Loss: 0.0172\n",
      "Step 69/391, Loss: 0.0189\n",
      "Step 70/391, Loss: 0.0116\n",
      "Step 71/391, Loss: 0.0398\n",
      "Step 72/391, Loss: 0.0465\n",
      "Step 73/391, Loss: 0.0134\n",
      "Step 74/391, Loss: 0.0395\n",
      "Step 75/391, Loss: 0.0036\n",
      "Step 76/391, Loss: 0.0270\n",
      "Step 77/391, Loss: 0.0374\n",
      "Step 78/391, Loss: 0.0236\n",
      "Step 79/391, Loss: 0.0341\n",
      "Step 80/391, Loss: 0.1211\n",
      "Step 81/391, Loss: 0.0049\n",
      "Step 82/391, Loss: 0.0279\n",
      "Step 83/391, Loss: 0.0417\n",
      "Step 84/391, Loss: 0.0127\n",
      "Step 85/391, Loss: 0.0379\n",
      "Step 86/391, Loss: 0.0360\n",
      "Step 87/391, Loss: 0.0147\n",
      "Step 88/391, Loss: 0.0886\n",
      "Step 89/391, Loss: 0.0108\n",
      "Step 90/391, Loss: 0.0256\n",
      "Step 91/391, Loss: 0.0454\n",
      "Step 92/391, Loss: 0.0601\n",
      "Step 93/391, Loss: 0.0075\n",
      "Step 94/391, Loss: 0.0306\n",
      "Step 95/391, Loss: 0.0806\n",
      "Step 96/391, Loss: 0.0529\n",
      "Step 97/391, Loss: 0.0511\n",
      "Step 98/391, Loss: 0.0526\n",
      "Step 99/391, Loss: 0.0327\n",
      "Step 100/391, Loss: 0.0580\n",
      "Step 101/391, Loss: 0.0517\n",
      "Step 102/391, Loss: 0.0272\n",
      "Step 103/391, Loss: 0.1282\n",
      "Step 104/391, Loss: 0.0697\n",
      "Step 105/391, Loss: 0.0311\n",
      "Step 106/391, Loss: 0.0741\n",
      "Step 107/391, Loss: 0.0530\n",
      "Step 108/391, Loss: 0.0308\n",
      "Step 109/391, Loss: 0.0078\n",
      "Step 110/391, Loss: 0.0232\n",
      "Step 111/391, Loss: 0.0547\n",
      "Step 112/391, Loss: 0.0554\n",
      "Step 113/391, Loss: 0.0336\n",
      "Step 114/391, Loss: 0.0278\n",
      "Step 115/391, Loss: 0.0634\n",
      "Step 116/391, Loss: 0.0473\n",
      "Step 117/391, Loss: 0.0507\n",
      "Step 118/391, Loss: 0.0388\n",
      "Step 119/391, Loss: 0.0319\n",
      "Step 120/391, Loss: 0.0512\n",
      "Step 121/391, Loss: 0.0176\n",
      "Step 122/391, Loss: 0.0351\n",
      "Step 123/391, Loss: 0.0039\n",
      "Step 124/391, Loss: 0.0886\n",
      "Step 125/391, Loss: 0.0290\n",
      "Step 126/391, Loss: 0.0359\n",
      "Step 127/391, Loss: 0.0191\n",
      "Step 128/391, Loss: 0.0293\n",
      "Step 129/391, Loss: 0.0102\n",
      "Step 130/391, Loss: 0.0419\n",
      "Step 131/391, Loss: 0.0743\n",
      "Step 132/391, Loss: 0.0441\n",
      "Step 133/391, Loss: 0.0487\n",
      "Step 134/391, Loss: 0.0108\n",
      "Step 135/391, Loss: 0.0070\n",
      "Step 136/391, Loss: 0.0135\n",
      "Step 137/391, Loss: 0.0033\n",
      "Step 138/391, Loss: 0.0070\n",
      "Step 139/391, Loss: 0.0309\n",
      "Step 140/391, Loss: 0.0838\n",
      "Step 141/391, Loss: 0.0245\n",
      "Step 142/391, Loss: 0.0179\n",
      "Step 143/391, Loss: 0.0824\n",
      "Step 144/391, Loss: 0.0264\n",
      "Step 145/391, Loss: 0.0137\n",
      "Step 146/391, Loss: 0.0194\n",
      "Step 147/391, Loss: 0.0643\n",
      "Step 148/391, Loss: 0.0360\n",
      "Step 149/391, Loss: 0.0210\n",
      "Step 150/391, Loss: 0.0034\n",
      "Step 151/391, Loss: 0.0050\n",
      "Step 152/391, Loss: 0.0052\n",
      "Step 153/391, Loss: 0.0189\n",
      "Step 154/391, Loss: 0.0286\n",
      "Step 155/391, Loss: 0.0196\n",
      "Step 156/391, Loss: 0.0319\n",
      "Step 157/391, Loss: 0.0662\n",
      "Step 158/391, Loss: 0.0050\n",
      "Step 159/391, Loss: 0.0376\n",
      "Step 160/391, Loss: 0.0460\n",
      "Step 161/391, Loss: 0.0683\n",
      "Step 162/391, Loss: 0.0058\n",
      "Step 163/391, Loss: 0.0445\n",
      "Step 164/391, Loss: 0.1037\n",
      "Step 165/391, Loss: 0.0067\n",
      "Step 166/391, Loss: 0.0105\n",
      "Step 167/391, Loss: 0.0045\n",
      "Step 168/391, Loss: 0.0094\n",
      "Step 169/391, Loss: 0.0158\n",
      "Step 170/391, Loss: 0.0038\n",
      "Step 171/391, Loss: 0.0074\n",
      "Step 172/391, Loss: 0.0322\n",
      "Step 173/391, Loss: 0.0344\n",
      "Step 174/391, Loss: 0.0209\n",
      "Step 175/391, Loss: 0.0058\n",
      "Step 176/391, Loss: 0.0181\n",
      "Step 177/391, Loss: 0.0544\n",
      "Step 178/391, Loss: 0.0119\n",
      "Step 179/391, Loss: 0.0378\n",
      "Step 180/391, Loss: 0.0106\n",
      "Step 181/391, Loss: 0.0612\n",
      "Step 182/391, Loss: 0.0522\n",
      "Step 183/391, Loss: 0.0035\n",
      "Step 184/391, Loss: 0.0284\n",
      "Step 185/391, Loss: 0.0093\n",
      "Step 186/391, Loss: 0.0586\n",
      "Step 187/391, Loss: 0.0434\n",
      "Step 188/391, Loss: 0.0061\n",
      "Step 189/391, Loss: 0.0816\n",
      "Step 190/391, Loss: 0.0551\n",
      "Step 191/391, Loss: 0.0362\n",
      "Step 192/391, Loss: 0.0099\n",
      "Step 193/391, Loss: 0.0047\n",
      "Step 194/391, Loss: 0.0033\n",
      "Step 195/391, Loss: 0.0347\n",
      "Step 196/391, Loss: 0.0202\n",
      "Step 197/391, Loss: 0.0115\n",
      "Step 198/391, Loss: 0.0818\n",
      "Step 199/391, Loss: 0.0213\n",
      "Step 200/391, Loss: 0.0232\n",
      "Step 201/391, Loss: 0.0057\n",
      "Step 202/391, Loss: 0.0615\n",
      "Step 203/391, Loss: 0.0755\n",
      "Step 204/391, Loss: 0.0145\n",
      "Step 205/391, Loss: 0.0300\n",
      "Step 206/391, Loss: 0.0159\n",
      "Step 207/391, Loss: 0.0057\n",
      "Step 208/391, Loss: 0.0271\n",
      "Step 209/391, Loss: 0.0389\n",
      "Step 210/391, Loss: 0.0811\n",
      "Step 211/391, Loss: 0.0097\n",
      "Step 212/391, Loss: 0.0255\n",
      "Step 213/391, Loss: 0.0094\n",
      "Step 214/391, Loss: 0.0160\n",
      "Step 215/391, Loss: 0.0702\n",
      "Step 216/391, Loss: 0.0334\n",
      "Step 217/391, Loss: 0.0326\n",
      "Step 218/391, Loss: 0.0434\n",
      "Step 219/391, Loss: 0.0170\n",
      "Step 220/391, Loss: 0.0107\n",
      "Step 221/391, Loss: 0.0124\n",
      "Step 222/391, Loss: 0.0412\n",
      "Step 223/391, Loss: 0.0451\n",
      "Step 224/391, Loss: 0.0156\n",
      "Step 225/391, Loss: 0.0028\n",
      "Step 226/391, Loss: 0.0117\n",
      "Step 227/391, Loss: 0.0743\n",
      "Step 228/391, Loss: 0.0751\n",
      "Step 229/391, Loss: 0.0197\n",
      "Step 230/391, Loss: 0.0109\n",
      "Step 231/391, Loss: 0.0509\n",
      "Step 232/391, Loss: 0.1039\n",
      "Step 233/391, Loss: 0.0705\n",
      "Step 234/391, Loss: 0.0109\n",
      "Step 235/391, Loss: 0.0420\n",
      "Step 236/391, Loss: 0.0318\n",
      "Step 237/391, Loss: 0.0672\n",
      "Step 238/391, Loss: 0.0056\n",
      "Step 239/391, Loss: 0.0424\n",
      "Step 240/391, Loss: 0.0765\n",
      "Step 241/391, Loss: 0.0340\n",
      "Step 242/391, Loss: 0.0185\n",
      "Step 243/391, Loss: 0.0550\n",
      "Step 244/391, Loss: 0.0618\n",
      "Step 245/391, Loss: 0.0496\n",
      "Step 246/391, Loss: 0.0179\n",
      "Step 247/391, Loss: 0.0166\n",
      "Step 248/391, Loss: 0.0504\n",
      "Step 249/391, Loss: 0.0751\n",
      "Step 250/391, Loss: 0.0912\n",
      "Step 251/391, Loss: 0.0044\n",
      "Step 252/391, Loss: 0.0670\n",
      "Step 253/391, Loss: 0.0401\n",
      "Step 254/391, Loss: 0.0596\n",
      "Step 255/391, Loss: 0.0102\n",
      "Step 256/391, Loss: 0.0830\n",
      "Step 257/391, Loss: 0.0081\n",
      "Step 258/391, Loss: 0.0494\n",
      "Step 259/391, Loss: 0.0663\n",
      "Step 260/391, Loss: 0.0256\n",
      "Step 261/391, Loss: 0.0383\n",
      "Step 262/391, Loss: 0.0202\n",
      "Step 263/391, Loss: 0.0125\n",
      "Step 264/391, Loss: 0.0640\n",
      "Step 265/391, Loss: 0.0349\n",
      "Step 266/391, Loss: 0.0607\n",
      "Step 267/391, Loss: 0.0221\n",
      "Step 268/391, Loss: 0.0123\n",
      "Step 269/391, Loss: 0.0034\n",
      "Step 270/391, Loss: 0.0334\n",
      "Step 271/391, Loss: 0.0288\n",
      "Step 272/391, Loss: 0.0420\n",
      "Step 273/391, Loss: 0.0228\n",
      "Step 274/391, Loss: 0.1107\n",
      "Step 275/391, Loss: 0.0669\n",
      "Step 276/391, Loss: 0.0391\n",
      "Step 277/391, Loss: 0.0638\n",
      "Step 278/391, Loss: 0.0777\n",
      "Step 279/391, Loss: 0.0301\n",
      "Step 280/391, Loss: 0.0505\n",
      "Step 281/391, Loss: 0.0837\n",
      "Step 282/391, Loss: 0.0125\n",
      "Step 283/391, Loss: 0.0675\n",
      "Step 284/391, Loss: 0.0459\n",
      "Step 285/391, Loss: 0.0835\n",
      "Step 286/391, Loss: 0.0507\n",
      "Step 287/391, Loss: 0.0306\n",
      "Step 288/391, Loss: 0.0558\n",
      "Step 289/391, Loss: 0.0453\n",
      "Step 290/391, Loss: 0.0171\n",
      "Step 291/391, Loss: 0.1376\n",
      "Step 292/391, Loss: 0.0277\n",
      "Step 293/391, Loss: 0.0445\n",
      "Step 294/391, Loss: 0.0350\n",
      "Step 295/391, Loss: 0.0323\n",
      "Step 296/391, Loss: 0.0258\n",
      "Step 297/391, Loss: 0.0088\n",
      "Step 298/391, Loss: 0.0499\n",
      "Step 299/391, Loss: 0.0538\n",
      "Step 300/391, Loss: 0.0093\n",
      "Step 301/391, Loss: 0.0268\n",
      "Step 302/391, Loss: 0.1436\n",
      "Step 303/391, Loss: 0.0416\n",
      "Step 304/391, Loss: 0.0052\n",
      "Step 305/391, Loss: 0.0270\n",
      "Step 306/391, Loss: 0.0705\n",
      "Step 307/391, Loss: 0.0617\n",
      "Step 308/391, Loss: 0.0126\n",
      "Step 309/391, Loss: 0.0307\n",
      "Step 310/391, Loss: 0.1049\n",
      "Step 311/391, Loss: 0.0862\n",
      "Step 312/391, Loss: 0.0096\n",
      "Step 313/391, Loss: 0.0060\n",
      "Step 314/391, Loss: 0.0341\n",
      "Step 315/391, Loss: 0.0089\n",
      "Step 316/391, Loss: 0.0253\n",
      "Step 317/391, Loss: 0.0063\n",
      "Step 318/391, Loss: 0.0628\n",
      "Step 319/391, Loss: 0.1620\n",
      "Step 320/391, Loss: 0.0958\n",
      "Step 321/391, Loss: 0.0187\n",
      "Step 322/391, Loss: 0.0267\n",
      "Step 323/391, Loss: 0.0087\n",
      "Step 324/391, Loss: 0.0093\n",
      "Step 325/391, Loss: 0.0058\n",
      "Step 326/391, Loss: 0.0499\n",
      "Step 327/391, Loss: 0.1218\n",
      "Step 328/391, Loss: 0.0721\n",
      "Step 329/391, Loss: 0.1005\n",
      "Step 330/391, Loss: 0.0467\n",
      "Step 331/391, Loss: 0.0722\n",
      "Step 332/391, Loss: 0.0200\n",
      "Step 333/391, Loss: 0.0322\n",
      "Step 334/391, Loss: 0.0313\n",
      "Step 335/391, Loss: 0.0425\n",
      "Step 336/391, Loss: 0.0359\n",
      "Step 337/391, Loss: 0.0800\n",
      "Step 338/391, Loss: 0.0419\n",
      "Step 339/391, Loss: 0.0097\n",
      "Step 340/391, Loss: 0.0898\n",
      "Step 341/391, Loss: 0.0447\n",
      "Step 342/391, Loss: 0.0625\n",
      "Step 343/391, Loss: 0.0636\n",
      "Step 344/391, Loss: 0.0563\n",
      "Step 345/391, Loss: 0.0309\n",
      "Step 346/391, Loss: 0.0077\n",
      "Step 347/391, Loss: 0.0483\n",
      "Step 348/391, Loss: 0.0091\n",
      "Step 349/391, Loss: 0.0283\n",
      "Step 350/391, Loss: 0.0728\n",
      "Step 351/391, Loss: 0.0296\n",
      "Step 352/391, Loss: 0.0188\n",
      "Step 353/391, Loss: 0.0634\n",
      "Step 354/391, Loss: 0.0082\n",
      "Step 355/391, Loss: 0.0360\n",
      "Step 356/391, Loss: 0.0621\n",
      "Step 357/391, Loss: 0.0216\n",
      "Step 358/391, Loss: 0.0311\n",
      "Step 359/391, Loss: 0.0259\n",
      "Step 360/391, Loss: 0.0267\n",
      "Step 361/391, Loss: 0.0508\n",
      "Step 362/391, Loss: 0.1063\n",
      "Step 363/391, Loss: 0.0181\n",
      "Step 364/391, Loss: 0.0539\n",
      "Step 365/391, Loss: 0.0184\n",
      "Step 366/391, Loss: 0.0531\n",
      "Step 367/391, Loss: 0.0384\n",
      "Step 368/391, Loss: 0.0263\n",
      "Step 369/391, Loss: 0.0883\n",
      "Step 370/391, Loss: 0.0636\n",
      "Step 371/391, Loss: 0.0026\n",
      "Step 372/391, Loss: 0.0332\n",
      "Step 373/391, Loss: 0.0642\n",
      "Step 374/391, Loss: 0.0137\n",
      "Step 375/391, Loss: 0.0396\n",
      "Step 376/391, Loss: 0.0288\n",
      "Step 377/391, Loss: 0.0697\n",
      "Step 378/391, Loss: 0.0194\n",
      "Step 379/391, Loss: 0.0280\n",
      "Step 380/391, Loss: 0.0772\n",
      "Step 381/391, Loss: 0.1491\n",
      "Step 382/391, Loss: 0.0938\n",
      "Step 383/391, Loss: 0.0083\n",
      "Step 384/391, Loss: 0.0642\n",
      "Step 385/391, Loss: 0.0061\n",
      "Step 386/391, Loss: 0.0169\n",
      "Step 387/391, Loss: 0.0269\n",
      "Step 388/391, Loss: 0.0336\n",
      "Step 389/391, Loss: 0.0344\n",
      "Step 390/391, Loss: 0.0327\n",
      "Step 391/391, Loss: 0.0156\n",
      "Epoch 19/25, Average Train Loss: 0.0399\n",
      "Epoch 19/25, Average Validation Loss: 0.0857\n",
      "Step 1/391, Loss: 0.0465\n",
      "Step 2/391, Loss: 0.0898\n",
      "Step 3/391, Loss: 0.0475\n",
      "Step 4/391, Loss: 0.0244\n",
      "Step 5/391, Loss: 0.0858\n",
      "Step 6/391, Loss: 0.0243\n",
      "Step 7/391, Loss: 0.0329\n",
      "Step 8/391, Loss: 0.0057\n",
      "Step 9/391, Loss: 0.0138\n",
      "Step 10/391, Loss: 0.0576\n",
      "Step 11/391, Loss: 0.0662\n",
      "Step 12/391, Loss: 0.0471\n",
      "Step 13/391, Loss: 0.0806\n",
      "Step 14/391, Loss: 0.0393\n",
      "Step 15/391, Loss: 0.0283\n",
      "Step 16/391, Loss: 0.0109\n",
      "Step 17/391, Loss: 0.0295\n",
      "Step 18/391, Loss: 0.0259\n",
      "Step 19/391, Loss: 0.0082\n",
      "Step 20/391, Loss: 0.0731\n",
      "Step 21/391, Loss: 0.0077\n",
      "Step 22/391, Loss: 0.0440\n",
      "Step 23/391, Loss: 0.0460\n",
      "Step 24/391, Loss: 0.0208\n",
      "Step 25/391, Loss: 0.0544\n",
      "Step 26/391, Loss: 0.0236\n",
      "Step 27/391, Loss: 0.0257\n",
      "Step 28/391, Loss: 0.0163\n",
      "Step 29/391, Loss: 0.0405\n",
      "Step 30/391, Loss: 0.0891\n",
      "Step 31/391, Loss: 0.0452\n",
      "Step 32/391, Loss: 0.0124\n",
      "Step 33/391, Loss: 0.0274\n",
      "Step 34/391, Loss: 0.0585\n",
      "Step 35/391, Loss: 0.0084\n",
      "Step 36/391, Loss: 0.0763\n",
      "Step 37/391, Loss: 0.0219\n",
      "Step 38/391, Loss: 0.0594\n",
      "Step 39/391, Loss: 0.0314\n",
      "Step 40/391, Loss: 0.0057\n",
      "Step 41/391, Loss: 0.0315\n",
      "Step 42/391, Loss: 0.0132\n",
      "Step 43/391, Loss: 0.0459\n",
      "Step 44/391, Loss: 0.0495\n",
      "Step 45/391, Loss: 0.0511\n",
      "Step 46/391, Loss: 0.0087\n",
      "Step 47/391, Loss: 0.0752\n",
      "Step 48/391, Loss: 0.0132\n",
      "Step 49/391, Loss: 0.0282\n",
      "Step 50/391, Loss: 0.0523\n",
      "Step 51/391, Loss: 0.0026\n",
      "Step 52/391, Loss: 0.0024\n",
      "Step 53/391, Loss: 0.0376\n",
      "Step 54/391, Loss: 0.0099\n",
      "Step 55/391, Loss: 0.0191\n",
      "Step 56/391, Loss: 0.0299\n",
      "Step 57/391, Loss: 0.0412\n",
      "Step 58/391, Loss: 0.0315\n",
      "Step 59/391, Loss: 0.0071\n",
      "Step 60/391, Loss: 0.0165\n",
      "Step 61/391, Loss: 0.0396\n",
      "Step 62/391, Loss: 0.0234\n",
      "Step 63/391, Loss: 0.0344\n",
      "Step 64/391, Loss: 0.0464\n",
      "Step 65/391, Loss: 0.0349\n",
      "Step 66/391, Loss: 0.0362\n",
      "Step 67/391, Loss: 0.0170\n",
      "Step 68/391, Loss: 0.0146\n",
      "Step 69/391, Loss: 0.0135\n",
      "Step 70/391, Loss: 0.0487\n",
      "Step 71/391, Loss: 0.0587\n",
      "Step 72/391, Loss: 0.0153\n",
      "Step 73/391, Loss: 0.0151\n",
      "Step 74/391, Loss: 0.0932\n",
      "Step 75/391, Loss: 0.0302\n",
      "Step 76/391, Loss: 0.1183\n",
      "Step 77/391, Loss: 0.0208\n",
      "Step 78/391, Loss: 0.0435\n",
      "Step 79/391, Loss: 0.0444\n",
      "Step 80/391, Loss: 0.0324\n",
      "Step 81/391, Loss: 0.0743\n",
      "Step 82/391, Loss: 0.1654\n",
      "Step 83/391, Loss: 0.0374\n",
      "Step 84/391, Loss: 0.0500\n",
      "Step 85/391, Loss: 0.0225\n",
      "Step 86/391, Loss: 0.0613\n",
      "Step 87/391, Loss: 0.0483\n",
      "Step 88/391, Loss: 0.0161\n",
      "Step 89/391, Loss: 0.0610\n",
      "Step 90/391, Loss: 0.0523\n",
      "Step 91/391, Loss: 0.0041\n",
      "Step 92/391, Loss: 0.0258\n",
      "Step 93/391, Loss: 0.0277\n",
      "Step 94/391, Loss: 0.0660\n",
      "Step 95/391, Loss: 0.0460\n",
      "Step 96/391, Loss: 0.0336\n",
      "Step 97/391, Loss: 0.0578\n",
      "Step 98/391, Loss: 0.0378\n",
      "Step 99/391, Loss: 0.0516\n",
      "Step 100/391, Loss: 0.0150\n",
      "Step 101/391, Loss: 0.0068\n",
      "Step 102/391, Loss: 0.0798\n",
      "Step 103/391, Loss: 0.0491\n",
      "Step 104/391, Loss: 0.0506\n",
      "Step 105/391, Loss: 0.0218\n",
      "Step 106/391, Loss: 0.0538\n",
      "Step 107/391, Loss: 0.0224\n",
      "Step 108/391, Loss: 0.0433\n",
      "Step 109/391, Loss: 0.0038\n",
      "Step 110/391, Loss: 0.0177\n",
      "Step 111/391, Loss: 0.0052\n",
      "Step 112/391, Loss: 0.0458\n",
      "Step 113/391, Loss: 0.0196\n",
      "Step 114/391, Loss: 0.0332\n",
      "Step 115/391, Loss: 0.0057\n",
      "Step 116/391, Loss: 0.0834\n",
      "Step 117/391, Loss: 0.0475\n",
      "Step 118/391, Loss: 0.0308\n",
      "Step 119/391, Loss: 0.0400\n",
      "Step 120/391, Loss: 0.0192\n",
      "Step 121/391, Loss: 0.0344\n",
      "Step 122/391, Loss: 0.0445\n",
      "Step 123/391, Loss: 0.0266\n",
      "Step 124/391, Loss: 0.0076\n",
      "Step 125/391, Loss: 0.0412\n",
      "Step 126/391, Loss: 0.0366\n",
      "Step 127/391, Loss: 0.0551\n",
      "Step 128/391, Loss: 0.0628\n",
      "Step 129/391, Loss: 0.1153\n",
      "Step 130/391, Loss: 0.0249\n",
      "Step 131/391, Loss: 0.0039\n",
      "Step 132/391, Loss: 0.0325\n",
      "Step 133/391, Loss: 0.0678\n",
      "Step 134/391, Loss: 0.0335\n",
      "Step 135/391, Loss: 0.0305\n",
      "Step 136/391, Loss: 0.0185\n",
      "Step 137/391, Loss: 0.0259\n",
      "Step 138/391, Loss: 0.0494\n",
      "Step 139/391, Loss: 0.0236\n",
      "Step 140/391, Loss: 0.0071\n",
      "Step 141/391, Loss: 0.0292\n",
      "Step 142/391, Loss: 0.0568\n",
      "Step 143/391, Loss: 0.0310\n",
      "Step 144/391, Loss: 0.0447\n",
      "Step 145/391, Loss: 0.0248\n",
      "Step 146/391, Loss: 0.0401\n",
      "Step 147/391, Loss: 0.0583\n",
      "Step 148/391, Loss: 0.0230\n",
      "Step 149/391, Loss: 0.0112\n",
      "Step 150/391, Loss: 0.0108\n",
      "Step 151/391, Loss: 0.1526\n",
      "Step 152/391, Loss: 0.0590\n",
      "Step 153/391, Loss: 0.0599\n",
      "Step 154/391, Loss: 0.0351\n",
      "Step 155/391, Loss: 0.0608\n",
      "Step 156/391, Loss: 0.0299\n",
      "Step 157/391, Loss: 0.0488\n",
      "Step 158/391, Loss: 0.0049\n",
      "Step 159/391, Loss: 0.0527\n",
      "Step 160/391, Loss: 0.0407\n",
      "Step 161/391, Loss: 0.0270\n",
      "Step 162/391, Loss: 0.0362\n",
      "Step 163/391, Loss: 0.0415\n",
      "Step 164/391, Loss: 0.0972\n",
      "Step 165/391, Loss: 0.0521\n",
      "Step 166/391, Loss: 0.0033\n",
      "Step 167/391, Loss: 0.0249\n",
      "Step 168/391, Loss: 0.0440\n",
      "Step 169/391, Loss: 0.0107\n",
      "Step 170/391, Loss: 0.0165\n",
      "Step 171/391, Loss: 0.0110\n",
      "Step 172/391, Loss: 0.0209\n",
      "Step 173/391, Loss: 0.1378\n",
      "Step 174/391, Loss: 0.0678\n",
      "Step 175/391, Loss: 0.0099\n",
      "Step 176/391, Loss: 0.1029\n",
      "Step 177/391, Loss: 0.0169\n",
      "Step 178/391, Loss: 0.0444\n",
      "Step 179/391, Loss: 0.1232\n",
      "Step 180/391, Loss: 0.0325\n",
      "Step 181/391, Loss: 0.0382\n",
      "Step 182/391, Loss: 0.0235\n",
      "Step 183/391, Loss: 0.0438\n",
      "Step 184/391, Loss: 0.0355\n",
      "Step 185/391, Loss: 0.0346\n",
      "Step 186/391, Loss: 0.0221\n",
      "Step 187/391, Loss: 0.0295\n",
      "Step 188/391, Loss: 0.0061\n",
      "Step 189/391, Loss: 0.0258\n",
      "Step 190/391, Loss: 0.0340\n",
      "Step 191/391, Loss: 0.0170\n",
      "Step 192/391, Loss: 0.0194\n",
      "Step 193/391, Loss: 0.0650\n",
      "Step 194/391, Loss: 0.0198\n",
      "Step 195/391, Loss: 0.0103\n",
      "Step 196/391, Loss: 0.0288\n",
      "Step 197/391, Loss: 0.0252\n",
      "Step 198/391, Loss: 0.0208\n",
      "Step 199/391, Loss: 0.0245\n",
      "Step 200/391, Loss: 0.0389\n",
      "Step 201/391, Loss: 0.0222\n",
      "Step 202/391, Loss: 0.0179\n",
      "Step 203/391, Loss: 0.0641\n",
      "Step 204/391, Loss: 0.0137\n",
      "Step 205/391, Loss: 0.0552\n",
      "Step 206/391, Loss: 0.0339\n",
      "Step 207/391, Loss: 0.0031\n",
      "Step 208/391, Loss: 0.0079\n",
      "Step 209/391, Loss: 0.0470\n",
      "Step 210/391, Loss: 0.0205\n",
      "Step 211/391, Loss: 0.0333\n",
      "Step 212/391, Loss: 0.0398\n",
      "Step 213/391, Loss: 0.0840\n",
      "Step 214/391, Loss: 0.0204\n",
      "Step 215/391, Loss: 0.0624\n",
      "Step 216/391, Loss: 0.0309\n",
      "Step 217/391, Loss: 0.1008\n",
      "Step 218/391, Loss: 0.1066\n",
      "Step 219/391, Loss: 0.0086\n",
      "Step 220/391, Loss: 0.0082\n",
      "Step 221/391, Loss: 0.0799\n",
      "Step 222/391, Loss: 0.0053\n",
      "Step 223/391, Loss: 0.0264\n",
      "Step 224/391, Loss: 0.0930\n",
      "Step 225/391, Loss: 0.0683\n",
      "Step 226/391, Loss: 0.0460\n",
      "Step 227/391, Loss: 0.0101\n",
      "Step 228/391, Loss: 0.0681\n",
      "Step 229/391, Loss: 0.0239\n",
      "Step 230/391, Loss: 0.0139\n",
      "Step 231/391, Loss: 0.0411\n",
      "Step 232/391, Loss: 0.1150\n",
      "Step 233/391, Loss: 0.0127\n",
      "Step 234/391, Loss: 0.0145\n",
      "Step 235/391, Loss: 0.0209\n",
      "Step 236/391, Loss: 0.0255\n",
      "Step 237/391, Loss: 0.1238\n",
      "Step 238/391, Loss: 0.0265\n",
      "Step 239/391, Loss: 0.0660\n",
      "Step 240/391, Loss: 0.0150\n",
      "Step 241/391, Loss: 0.0282\n",
      "Step 242/391, Loss: 0.0398\n",
      "Step 243/391, Loss: 0.0159\n",
      "Step 244/391, Loss: 0.0406\n",
      "Step 245/391, Loss: 0.0183\n",
      "Step 246/391, Loss: 0.0560\n",
      "Step 247/391, Loss: 0.0220\n",
      "Step 248/391, Loss: 0.0324\n",
      "Step 249/391, Loss: 0.0119\n",
      "Step 250/391, Loss: 0.0069\n",
      "Step 251/391, Loss: 0.0895\n",
      "Step 252/391, Loss: 0.0096\n",
      "Step 253/391, Loss: 0.0247\n",
      "Step 254/391, Loss: 0.0209\n",
      "Step 255/391, Loss: 0.0168\n",
      "Step 256/391, Loss: 0.0088\n",
      "Step 257/391, Loss: 0.0282\n",
      "Step 258/391, Loss: 0.0380\n",
      "Step 259/391, Loss: 0.0637\n",
      "Step 260/391, Loss: 0.0130\n",
      "Step 261/391, Loss: 0.0030\n",
      "Step 262/391, Loss: 0.0185\n",
      "Step 263/391, Loss: 0.0327\n",
      "Step 264/391, Loss: 0.0463\n",
      "Step 265/391, Loss: 0.1030\n",
      "Step 266/391, Loss: 0.0209\n",
      "Step 267/391, Loss: 0.0860\n",
      "Step 268/391, Loss: 0.0399\n",
      "Step 269/391, Loss: 0.0225\n",
      "Step 270/391, Loss: 0.0245\n",
      "Step 271/391, Loss: 0.0658\n",
      "Step 272/391, Loss: 0.0274\n",
      "Step 273/391, Loss: 0.0392\n",
      "Step 274/391, Loss: 0.0045\n",
      "Step 275/391, Loss: 0.0278\n",
      "Step 276/391, Loss: 0.0366\n",
      "Step 277/391, Loss: 0.1066\n",
      "Step 278/391, Loss: 0.1058\n",
      "Step 279/391, Loss: 0.0149\n",
      "Step 280/391, Loss: 0.0105\n",
      "Step 281/391, Loss: 0.0655\n",
      "Step 282/391, Loss: 0.0364\n",
      "Step 283/391, Loss: 0.0316\n",
      "Step 284/391, Loss: 0.0448\n",
      "Step 285/391, Loss: 0.0071\n",
      "Step 286/391, Loss: 0.0127\n",
      "Step 287/391, Loss: 0.0727\n",
      "Step 288/391, Loss: 0.1001\n",
      "Step 289/391, Loss: 0.1018\n",
      "Step 290/391, Loss: 0.0859\n",
      "Step 291/391, Loss: 0.0252\n",
      "Step 292/391, Loss: 0.0355\n",
      "Step 293/391, Loss: 0.0243\n",
      "Step 294/391, Loss: 0.0589\n",
      "Step 295/391, Loss: 0.0197\n",
      "Step 296/391, Loss: 0.0049\n",
      "Step 297/391, Loss: 0.0279\n",
      "Step 298/391, Loss: 0.0158\n",
      "Step 299/391, Loss: 0.0041\n",
      "Step 300/391, Loss: 0.0791\n",
      "Step 301/391, Loss: 0.0889\n",
      "Step 302/391, Loss: 0.0270\n",
      "Step 303/391, Loss: 0.1520\n",
      "Step 304/391, Loss: 0.0519\n",
      "Step 305/391, Loss: 0.0902\n",
      "Step 306/391, Loss: 0.0055\n",
      "Step 307/391, Loss: 0.0079\n",
      "Step 308/391, Loss: 0.0967\n",
      "Step 309/391, Loss: 0.0778\n",
      "Step 310/391, Loss: 0.0309\n",
      "Step 311/391, Loss: 0.0063\n",
      "Step 312/391, Loss: 0.0253\n",
      "Step 313/391, Loss: 0.0227\n",
      "Step 314/391, Loss: 0.1359\n",
      "Step 315/391, Loss: 0.0171\n",
      "Step 316/391, Loss: 0.0388\n",
      "Step 317/391, Loss: 0.0842\n",
      "Step 318/391, Loss: 0.0910\n",
      "Step 319/391, Loss: 0.0277\n",
      "Step 320/391, Loss: 0.0600\n",
      "Step 321/391, Loss: 0.0221\n",
      "Step 322/391, Loss: 0.0413\n",
      "Step 323/391, Loss: 0.0297\n",
      "Step 324/391, Loss: 0.1010\n",
      "Step 325/391, Loss: 0.0140\n",
      "Step 326/391, Loss: 0.0266\n",
      "Step 327/391, Loss: 0.0472\n",
      "Step 328/391, Loss: 0.0510\n",
      "Step 329/391, Loss: 0.0726\n",
      "Step 330/391, Loss: 0.0413\n",
      "Step 331/391, Loss: 0.0269\n",
      "Step 332/391, Loss: 0.1488\n",
      "Step 333/391, Loss: 0.0750\n",
      "Step 334/391, Loss: 0.0491\n",
      "Step 335/391, Loss: 0.0088\n",
      "Step 336/391, Loss: 0.0505\n",
      "Step 337/391, Loss: 0.0571\n",
      "Step 338/391, Loss: 0.1072\n",
      "Step 339/391, Loss: 0.1720\n",
      "Step 340/391, Loss: 0.0355\n",
      "Step 341/391, Loss: 0.0660\n",
      "Step 342/391, Loss: 0.0224\n",
      "Step 343/391, Loss: 0.0150\n",
      "Step 344/391, Loss: 0.0355\n",
      "Step 345/391, Loss: 0.0456\n",
      "Step 346/391, Loss: 0.0247\n",
      "Step 347/391, Loss: 0.0171\n",
      "Step 348/391, Loss: 0.0542\n",
      "Step 349/391, Loss: 0.0574\n",
      "Step 350/391, Loss: 0.0515\n",
      "Step 351/391, Loss: 0.0947\n",
      "Step 352/391, Loss: 0.0304\n",
      "Step 353/391, Loss: 0.1197\n",
      "Step 354/391, Loss: 0.1055\n",
      "Step 355/391, Loss: 0.0434\n",
      "Step 356/391, Loss: 0.0053\n",
      "Step 357/391, Loss: 0.0542\n",
      "Step 358/391, Loss: 0.0611\n",
      "Step 359/391, Loss: 0.0273\n",
      "Step 360/391, Loss: 0.0339\n",
      "Step 361/391, Loss: 0.0226\n",
      "Step 362/391, Loss: 0.0375\n",
      "Step 363/391, Loss: 0.0161\n",
      "Step 364/391, Loss: 0.0318\n",
      "Step 365/391, Loss: 0.0982\n",
      "Step 366/391, Loss: 0.0869\n",
      "Step 367/391, Loss: 0.0045\n",
      "Step 368/391, Loss: 0.0316\n",
      "Step 369/391, Loss: 0.0469\n",
      "Step 370/391, Loss: 0.0227\n",
      "Step 371/391, Loss: 0.0289\n",
      "Step 372/391, Loss: 0.0961\n",
      "Step 373/391, Loss: 0.0353\n",
      "Step 374/391, Loss: 0.0400\n",
      "Step 375/391, Loss: 0.0891\n",
      "Step 376/391, Loss: 0.0661\n",
      "Step 377/391, Loss: 0.0314\n",
      "Step 378/391, Loss: 0.0803\n",
      "Step 379/391, Loss: 0.0147\n",
      "Step 380/391, Loss: 0.0126\n",
      "Step 381/391, Loss: 0.0083\n",
      "Step 382/391, Loss: 0.0248\n",
      "Step 383/391, Loss: 0.0625\n",
      "Step 384/391, Loss: 0.0569\n",
      "Step 385/391, Loss: 0.0344\n",
      "Step 386/391, Loss: 0.0369\n",
      "Step 387/391, Loss: 0.0455\n",
      "Step 388/391, Loss: 0.2062\n",
      "Step 389/391, Loss: 0.0332\n",
      "Step 390/391, Loss: 0.0259\n",
      "Step 391/391, Loss: 0.0539\n",
      "Epoch 20/25, Average Train Loss: 0.0418\n",
      "Epoch 20/25, Average Validation Loss: 0.0863\n",
      "Step 1/391, Loss: 0.0214\n",
      "Step 2/391, Loss: 0.0303\n",
      "Step 3/391, Loss: 0.0576\n",
      "Step 4/391, Loss: 0.0743\n",
      "Step 5/391, Loss: 0.0190\n",
      "Step 6/391, Loss: 0.0378\n",
      "Step 7/391, Loss: 0.0088\n",
      "Step 8/391, Loss: 0.0124\n",
      "Step 9/391, Loss: 0.0172\n",
      "Step 10/391, Loss: 0.0341\n",
      "Step 11/391, Loss: 0.0256\n",
      "Step 12/391, Loss: 0.0377\n",
      "Step 13/391, Loss: 0.0439\n",
      "Step 14/391, Loss: 0.0178\n",
      "Step 15/391, Loss: 0.0852\n",
      "Step 16/391, Loss: 0.0094\n",
      "Step 17/391, Loss: 0.0103\n",
      "Step 18/391, Loss: 0.0483\n",
      "Step 19/391, Loss: 0.0149\n",
      "Step 20/391, Loss: 0.0328\n",
      "Step 21/391, Loss: 0.0782\n",
      "Step 22/391, Loss: 0.0504\n",
      "Step 23/391, Loss: 0.0332\n",
      "Step 24/391, Loss: 0.0177\n",
      "Step 25/391, Loss: 0.0166\n",
      "Step 26/391, Loss: 0.0291\n",
      "Step 27/391, Loss: 0.0128\n",
      "Step 28/391, Loss: 0.0058\n",
      "Step 29/391, Loss: 0.0039\n",
      "Step 30/391, Loss: 0.0241\n",
      "Step 31/391, Loss: 0.0046\n",
      "Step 32/391, Loss: 0.0128\n",
      "Step 33/391, Loss: 0.0213\n",
      "Step 34/391, Loss: 0.0550\n",
      "Step 35/391, Loss: 0.0148\n",
      "Step 36/391, Loss: 0.0485\n",
      "Step 37/391, Loss: 0.0733\n",
      "Step 38/391, Loss: 0.0694\n",
      "Step 39/391, Loss: 0.0223\n",
      "Step 40/391, Loss: 0.0489\n",
      "Step 41/391, Loss: 0.0191\n",
      "Step 42/391, Loss: 0.0602\n",
      "Step 43/391, Loss: 0.0090\n",
      "Step 44/391, Loss: 0.0132\n",
      "Step 45/391, Loss: 0.0966\n",
      "Step 46/391, Loss: 0.0687\n",
      "Step 47/391, Loss: 0.0074\n",
      "Step 48/391, Loss: 0.0777\n",
      "Step 49/391, Loss: 0.0427\n",
      "Step 50/391, Loss: 0.0157\n",
      "Step 51/391, Loss: 0.0620\n",
      "Step 52/391, Loss: 0.0174\n",
      "Step 53/391, Loss: 0.0229\n",
      "Step 54/391, Loss: 0.0530\n",
      "Step 55/391, Loss: 0.0250\n",
      "Step 56/391, Loss: 0.0108\n",
      "Step 57/391, Loss: 0.0156\n",
      "Step 58/391, Loss: 0.0060\n",
      "Step 59/391, Loss: 0.0257\n",
      "Step 60/391, Loss: 0.0187\n",
      "Step 61/391, Loss: 0.0093\n",
      "Step 62/391, Loss: 0.0352\n",
      "Step 63/391, Loss: 0.0120\n",
      "Step 64/391, Loss: 0.0271\n",
      "Step 65/391, Loss: 0.0549\n",
      "Step 66/391, Loss: 0.0098\n",
      "Step 67/391, Loss: 0.0561\n",
      "Step 68/391, Loss: 0.0439\n",
      "Step 69/391, Loss: 0.0310\n",
      "Step 70/391, Loss: 0.0810\n",
      "Step 71/391, Loss: 0.0282\n",
      "Step 72/391, Loss: 0.0459\n",
      "Step 73/391, Loss: 0.0249\n",
      "Step 74/391, Loss: 0.0084\n",
      "Step 75/391, Loss: 0.0539\n",
      "Step 76/391, Loss: 0.0572\n",
      "Step 77/391, Loss: 0.1359\n",
      "Step 78/391, Loss: 0.0063\n",
      "Step 79/391, Loss: 0.0130\n",
      "Step 80/391, Loss: 0.0164\n",
      "Step 81/391, Loss: 0.0456\n",
      "Step 82/391, Loss: 0.0562\n",
      "Step 83/391, Loss: 0.0066\n",
      "Step 84/391, Loss: 0.0453\n",
      "Step 85/391, Loss: 0.0113\n",
      "Step 86/391, Loss: 0.0499\n",
      "Step 87/391, Loss: 0.0283\n",
      "Step 88/391, Loss: 0.0196\n",
      "Step 89/391, Loss: 0.0237\n",
      "Step 90/391, Loss: 0.0112\n",
      "Step 91/391, Loss: 0.0336\n",
      "Step 92/391, Loss: 0.0304\n",
      "Step 93/391, Loss: 0.0277\n",
      "Step 94/391, Loss: 0.0063\n",
      "Step 95/391, Loss: 0.0786\n",
      "Step 96/391, Loss: 0.0506\n",
      "Step 97/391, Loss: 0.0250\n",
      "Step 98/391, Loss: 0.0097\n",
      "Step 99/391, Loss: 0.0810\n",
      "Step 100/391, Loss: 0.0059\n",
      "Step 101/391, Loss: 0.0480\n",
      "Step 102/391, Loss: 0.0183\n",
      "Step 103/391, Loss: 0.0339\n",
      "Step 104/391, Loss: 0.0086\n",
      "Step 105/391, Loss: 0.0491\n",
      "Step 106/391, Loss: 0.0739\n",
      "Step 107/391, Loss: 0.0130\n",
      "Step 108/391, Loss: 0.0274\n",
      "Step 109/391, Loss: 0.0111\n",
      "Step 110/391, Loss: 0.0128\n",
      "Step 111/391, Loss: 0.0407\n",
      "Step 112/391, Loss: 0.0827\n",
      "Step 113/391, Loss: 0.0218\n",
      "Step 114/391, Loss: 0.0035\n",
      "Step 115/391, Loss: 0.0494\n",
      "Step 116/391, Loss: 0.0192\n",
      "Step 117/391, Loss: 0.0018\n",
      "Step 118/391, Loss: 0.0137\n",
      "Step 119/391, Loss: 0.0107\n",
      "Step 120/391, Loss: 0.0327\n",
      "Step 121/391, Loss: 0.0106\n",
      "Step 122/391, Loss: 0.0133\n",
      "Step 123/391, Loss: 0.0126\n",
      "Step 124/391, Loss: 0.0460\n",
      "Step 125/391, Loss: 0.0299\n",
      "Step 126/391, Loss: 0.0468\n",
      "Step 127/391, Loss: 0.0092\n",
      "Step 128/391, Loss: 0.0664\n",
      "Step 129/391, Loss: 0.0218\n",
      "Step 130/391, Loss: 0.0231\n",
      "Step 131/391, Loss: 0.0105\n",
      "Step 132/391, Loss: 0.0642\n",
      "Step 133/391, Loss: 0.0044\n",
      "Step 134/391, Loss: 0.0052\n",
      "Step 135/391, Loss: 0.0102\n",
      "Step 136/391, Loss: 0.0084\n",
      "Step 137/391, Loss: 0.0190\n",
      "Step 138/391, Loss: 0.0137\n",
      "Step 139/391, Loss: 0.0642\n",
      "Step 140/391, Loss: 0.0166\n",
      "Step 141/391, Loss: 0.0337\n",
      "Step 142/391, Loss: 0.0369\n",
      "Step 143/391, Loss: 0.0389\n",
      "Step 144/391, Loss: 0.0368\n",
      "Step 145/391, Loss: 0.0307\n",
      "Step 146/391, Loss: 0.0345\n",
      "Step 147/391, Loss: 0.0058\n",
      "Step 148/391, Loss: 0.0262\n",
      "Step 149/391, Loss: 0.0089\n",
      "Step 150/391, Loss: 0.0520\n",
      "Step 151/391, Loss: 0.0086\n",
      "Step 152/391, Loss: 0.0335\n",
      "Step 153/391, Loss: 0.0314\n",
      "Step 154/391, Loss: 0.0695\n",
      "Step 155/391, Loss: 0.0577\n",
      "Step 156/391, Loss: 0.0249\n",
      "Step 157/391, Loss: 0.0401\n",
      "Step 158/391, Loss: 0.0331\n",
      "Step 159/391, Loss: 0.0163\n",
      "Step 160/391, Loss: 0.0316\n",
      "Step 161/391, Loss: 0.1243\n",
      "Step 162/391, Loss: 0.0295\n",
      "Step 163/391, Loss: 0.0015\n",
      "Step 164/391, Loss: 0.0200\n",
      "Step 165/391, Loss: 0.0363\n",
      "Step 166/391, Loss: 0.0041\n",
      "Step 167/391, Loss: 0.1041\n",
      "Step 168/391, Loss: 0.0428\n",
      "Step 169/391, Loss: 0.0095\n",
      "Step 170/391, Loss: 0.0556\n",
      "Step 171/391, Loss: 0.0643\n",
      "Step 172/391, Loss: 0.0109\n",
      "Step 173/391, Loss: 0.0142\n",
      "Step 174/391, Loss: 0.0463\n",
      "Step 175/391, Loss: 0.0817\n",
      "Step 176/391, Loss: 0.0200\n",
      "Step 177/391, Loss: 0.0085\n",
      "Step 178/391, Loss: 0.0285\n",
      "Step 179/391, Loss: 0.0041\n",
      "Step 180/391, Loss: 0.0346\n",
      "Step 181/391, Loss: 0.0206\n",
      "Step 182/391, Loss: 0.0583\n",
      "Step 183/391, Loss: 0.0057\n",
      "Step 184/391, Loss: 0.0202\n",
      "Step 185/391, Loss: 0.0645\n",
      "Step 186/391, Loss: 0.0170\n",
      "Step 187/391, Loss: 0.0228\n",
      "Step 188/391, Loss: 0.0157\n",
      "Step 189/391, Loss: 0.0038\n",
      "Step 190/391, Loss: 0.0030\n",
      "Step 191/391, Loss: 0.0129\n",
      "Step 192/391, Loss: 0.0451\n",
      "Step 193/391, Loss: 0.0239\n",
      "Step 194/391, Loss: 0.0165\n",
      "Step 195/391, Loss: 0.0136\n",
      "Step 196/391, Loss: 0.0225\n",
      "Step 197/391, Loss: 0.0838\n",
      "Step 198/391, Loss: 0.0340\n",
      "Step 199/391, Loss: 0.0188\n",
      "Step 200/391, Loss: 0.0511\n",
      "Step 201/391, Loss: 0.0150\n",
      "Step 202/391, Loss: 0.0069\n",
      "Step 203/391, Loss: 0.0490\n",
      "Step 204/391, Loss: 0.0534\n",
      "Step 205/391, Loss: 0.0521\n",
      "Step 206/391, Loss: 0.0587\n",
      "Step 207/391, Loss: 0.0257\n",
      "Step 208/391, Loss: 0.0137\n",
      "Step 209/391, Loss: 0.0461\n",
      "Step 210/391, Loss: 0.0292\n",
      "Step 211/391, Loss: 0.1029\n",
      "Step 212/391, Loss: 0.0515\n",
      "Step 213/391, Loss: 0.0227\n",
      "Step 214/391, Loss: 0.0680\n",
      "Step 215/391, Loss: 0.0661\n",
      "Step 216/391, Loss: 0.0339\n",
      "Step 217/391, Loss: 0.0150\n",
      "Step 218/391, Loss: 0.0023\n",
      "Step 219/391, Loss: 0.1035\n",
      "Step 220/391, Loss: 0.0066\n",
      "Step 221/391, Loss: 0.0067\n",
      "Step 222/391, Loss: 0.0321\n",
      "Step 223/391, Loss: 0.0700\n",
      "Step 224/391, Loss: 0.0098\n",
      "Step 225/391, Loss: 0.1005\n",
      "Step 226/391, Loss: 0.0626\n",
      "Step 227/391, Loss: 0.0412\n",
      "Step 228/391, Loss: 0.0265\n",
      "Step 229/391, Loss: 0.0126\n",
      "Step 230/391, Loss: 0.0552\n",
      "Step 231/391, Loss: 0.0356\n",
      "Step 232/391, Loss: 0.0239\n",
      "Step 233/391, Loss: 0.0081\n",
      "Step 234/391, Loss: 0.0677\n",
      "Step 235/391, Loss: 0.0324\n",
      "Step 236/391, Loss: 0.0262\n",
      "Step 237/391, Loss: 0.0482\n",
      "Step 238/391, Loss: 0.0053\n",
      "Step 239/391, Loss: 0.0320\n",
      "Step 240/391, Loss: 0.0524\n",
      "Step 241/391, Loss: 0.0907\n",
      "Step 242/391, Loss: 0.0154\n",
      "Step 243/391, Loss: 0.0184\n",
      "Step 244/391, Loss: 0.0055\n",
      "Step 245/391, Loss: 0.0184\n",
      "Step 246/391, Loss: 0.0729\n",
      "Step 247/391, Loss: 0.0628\n",
      "Step 248/391, Loss: 0.0508\n",
      "Step 249/391, Loss: 0.0321\n",
      "Step 250/391, Loss: 0.0198\n",
      "Step 251/391, Loss: 0.0053\n",
      "Step 252/391, Loss: 0.0245\n",
      "Step 253/391, Loss: 0.0460\n",
      "Step 254/391, Loss: 0.0589\n",
      "Step 255/391, Loss: 0.0201\n",
      "Step 256/391, Loss: 0.0212\n",
      "Step 257/391, Loss: 0.0495\n",
      "Step 258/391, Loss: 0.0064\n",
      "Step 259/391, Loss: 0.0254\n",
      "Step 260/391, Loss: 0.0259\n",
      "Step 261/391, Loss: 0.0526\n",
      "Step 262/391, Loss: 0.1052\n",
      "Step 263/391, Loss: 0.0202\n",
      "Step 264/391, Loss: 0.0187\n",
      "Step 265/391, Loss: 0.0538\n",
      "Step 266/391, Loss: 0.0114\n",
      "Step 267/391, Loss: 0.0223\n",
      "Step 268/391, Loss: 0.0148\n",
      "Step 269/391, Loss: 0.0097\n",
      "Step 270/391, Loss: 0.0594\n",
      "Step 271/391, Loss: 0.0812\n",
      "Step 272/391, Loss: 0.0165\n",
      "Step 273/391, Loss: 0.0527\n",
      "Step 274/391, Loss: 0.0153\n",
      "Step 275/391, Loss: 0.0140\n",
      "Step 276/391, Loss: 0.0531\n",
      "Step 277/391, Loss: 0.0110\n",
      "Step 278/391, Loss: 0.0044\n",
      "Step 279/391, Loss: 0.0075\n",
      "Step 280/391, Loss: 0.0082\n",
      "Step 281/391, Loss: 0.0097\n",
      "Step 282/391, Loss: 0.1007\n",
      "Step 283/391, Loss: 0.0456\n",
      "Step 284/391, Loss: 0.0666\n",
      "Step 285/391, Loss: 0.1078\n",
      "Step 286/391, Loss: 0.0092\n",
      "Step 287/391, Loss: 0.0534\n",
      "Step 288/391, Loss: 0.0270\n",
      "Step 289/391, Loss: 0.0034\n",
      "Step 290/391, Loss: 0.0136\n",
      "Step 291/391, Loss: 0.0070\n",
      "Step 292/391, Loss: 0.0055\n",
      "Step 293/391, Loss: 0.0417\n",
      "Step 294/391, Loss: 0.0430\n",
      "Step 295/391, Loss: 0.0619\n",
      "Step 296/391, Loss: 0.0193\n",
      "Step 297/391, Loss: 0.0123\n",
      "Step 298/391, Loss: 0.0231\n",
      "Step 299/391, Loss: 0.0370\n",
      "Step 300/391, Loss: 0.0143\n",
      "Step 301/391, Loss: 0.0422\n",
      "Step 302/391, Loss: 0.0987\n",
      "Step 303/391, Loss: 0.0132\n",
      "Step 304/391, Loss: 0.0248\n",
      "Step 305/391, Loss: 0.0135\n",
      "Step 306/391, Loss: 0.0049\n",
      "Step 307/391, Loss: 0.0179\n",
      "Step 308/391, Loss: 0.0821\n",
      "Step 309/391, Loss: 0.1228\n",
      "Step 310/391, Loss: 0.0134\n",
      "Step 311/391, Loss: 0.0184\n",
      "Step 312/391, Loss: 0.0823\n",
      "Step 313/391, Loss: 0.0220\n",
      "Step 314/391, Loss: 0.1288\n",
      "Step 315/391, Loss: 0.0234\n",
      "Step 316/391, Loss: 0.0889\n",
      "Step 317/391, Loss: 0.0402\n",
      "Step 318/391, Loss: 0.0032\n",
      "Step 319/391, Loss: 0.0727\n",
      "Step 320/391, Loss: 0.0257\n",
      "Step 321/391, Loss: 0.0767\n",
      "Step 322/391, Loss: 0.0044\n",
      "Step 323/391, Loss: 0.0139\n",
      "Step 324/391, Loss: 0.0277\n",
      "Step 325/391, Loss: 0.0141\n",
      "Step 326/391, Loss: 0.0356\n",
      "Step 327/391, Loss: 0.0273\n",
      "Step 328/391, Loss: 0.0199\n",
      "Step 329/391, Loss: 0.0846\n",
      "Step 330/391, Loss: 0.0306\n",
      "Step 331/391, Loss: 0.0064\n",
      "Step 332/391, Loss: 0.0769\n",
      "Step 333/391, Loss: 0.0182\n",
      "Step 334/391, Loss: 0.0417\n",
      "Step 335/391, Loss: 0.0177\n",
      "Step 336/391, Loss: 0.0265\n",
      "Step 337/391, Loss: 0.0333\n",
      "Step 338/391, Loss: 0.0377\n",
      "Step 339/391, Loss: 0.0509\n",
      "Step 340/391, Loss: 0.0398\n",
      "Step 341/391, Loss: 0.0114\n",
      "Step 342/391, Loss: 0.0742\n",
      "Step 343/391, Loss: 0.0174\n",
      "Step 344/391, Loss: 0.0387\n",
      "Step 345/391, Loss: 0.0632\n",
      "Step 346/391, Loss: 0.0127\n",
      "Step 347/391, Loss: 0.0108\n",
      "Step 348/391, Loss: 0.0158\n",
      "Step 349/391, Loss: 0.0447\n",
      "Step 350/391, Loss: 0.0222\n",
      "Step 351/391, Loss: 0.1385\n",
      "Step 352/391, Loss: 0.0587\n",
      "Step 353/391, Loss: 0.0566\n",
      "Step 354/391, Loss: 0.0712\n",
      "Step 355/391, Loss: 0.0132\n",
      "Step 356/391, Loss: 0.0366\n",
      "Step 357/391, Loss: 0.0825\n",
      "Step 358/391, Loss: 0.0303\n",
      "Step 359/391, Loss: 0.0481\n",
      "Step 360/391, Loss: 0.0493\n",
      "Step 361/391, Loss: 0.0561\n",
      "Step 362/391, Loss: 0.0555\n",
      "Step 363/391, Loss: 0.1097\n",
      "Step 364/391, Loss: 0.0637\n",
      "Step 365/391, Loss: 0.0348\n",
      "Step 366/391, Loss: 0.0353\n",
      "Step 367/391, Loss: 0.0077\n",
      "Step 368/391, Loss: 0.0197\n",
      "Step 369/391, Loss: 0.1059\n",
      "Step 370/391, Loss: 0.0578\n",
      "Step 371/391, Loss: 0.1455\n",
      "Step 372/391, Loss: 0.0257\n",
      "Step 373/391, Loss: 0.0206\n",
      "Step 374/391, Loss: 0.0241\n",
      "Step 375/391, Loss: 0.0869\n",
      "Step 376/391, Loss: 0.0542\n",
      "Step 377/391, Loss: 0.0411\n",
      "Step 378/391, Loss: 0.0923\n",
      "Step 379/391, Loss: 0.0182\n",
      "Step 380/391, Loss: 0.0978\n",
      "Step 381/391, Loss: 0.0404\n",
      "Step 382/391, Loss: 0.0064\n",
      "Step 383/391, Loss: 0.0337\n",
      "Step 384/391, Loss: 0.0370\n",
      "Step 385/391, Loss: 0.0046\n",
      "Step 386/391, Loss: 0.0858\n",
      "Step 387/391, Loss: 0.0065\n",
      "Step 388/391, Loss: 0.0370\n",
      "Step 389/391, Loss: 0.1102\n",
      "Step 390/391, Loss: 0.0328\n",
      "Step 391/391, Loss: 0.1332\n",
      "Epoch 21/25, Average Train Loss: 0.0361\n",
      "Epoch 21/25, Average Validation Loss: 0.0991\n",
      "Step 1/391, Loss: 0.0654\n",
      "Step 2/391, Loss: 0.0390\n",
      "Step 3/391, Loss: 0.0873\n",
      "Step 4/391, Loss: 0.0364\n",
      "Step 5/391, Loss: 0.0287\n",
      "Step 6/391, Loss: 0.0218\n",
      "Step 7/391, Loss: 0.0174\n",
      "Step 8/391, Loss: 0.0282\n",
      "Step 9/391, Loss: 0.0174\n",
      "Step 10/391, Loss: 0.0492\n",
      "Step 11/391, Loss: 0.0626\n",
      "Step 12/391, Loss: 0.0239\n",
      "Step 13/391, Loss: 0.0074\n",
      "Step 14/391, Loss: 0.0084\n",
      "Step 15/391, Loss: 0.0576\n",
      "Step 16/391, Loss: 0.0559\n",
      "Step 17/391, Loss: 0.0693\n",
      "Step 18/391, Loss: 0.0637\n",
      "Step 19/391, Loss: 0.0740\n",
      "Step 20/391, Loss: 0.0605\n",
      "Step 21/391, Loss: 0.0248\n",
      "Step 22/391, Loss: 0.0080\n",
      "Step 23/391, Loss: 0.0551\n",
      "Step 24/391, Loss: 0.0171\n",
      "Step 25/391, Loss: 0.0104\n",
      "Step 26/391, Loss: 0.0482\n",
      "Step 27/391, Loss: 0.0360\n",
      "Step 28/391, Loss: 0.0060\n",
      "Step 29/391, Loss: 0.0122\n",
      "Step 30/391, Loss: 0.0648\n",
      "Step 31/391, Loss: 0.0472\n",
      "Step 32/391, Loss: 0.0249\n",
      "Step 33/391, Loss: 0.0068\n",
      "Step 34/391, Loss: 0.0081\n",
      "Step 35/391, Loss: 0.0516\n",
      "Step 36/391, Loss: 0.0662\n",
      "Step 37/391, Loss: 0.0157\n",
      "Step 38/391, Loss: 0.0017\n",
      "Step 39/391, Loss: 0.0044\n",
      "Step 40/391, Loss: 0.0051\n",
      "Step 41/391, Loss: 0.0175\n",
      "Step 42/391, Loss: 0.0065\n",
      "Step 43/391, Loss: 0.0038\n",
      "Step 44/391, Loss: 0.0728\n",
      "Step 45/391, Loss: 0.0068\n",
      "Step 46/391, Loss: 0.0255\n",
      "Step 47/391, Loss: 0.0137\n",
      "Step 48/391, Loss: 0.0087\n",
      "Step 49/391, Loss: 0.0088\n",
      "Step 50/391, Loss: 0.0117\n",
      "Step 51/391, Loss: 0.0389\n",
      "Step 52/391, Loss: 0.0611\n",
      "Step 53/391, Loss: 0.0227\n",
      "Step 54/391, Loss: 0.0035\n",
      "Step 55/391, Loss: 0.0065\n",
      "Step 56/391, Loss: 0.0425\n",
      "Step 57/391, Loss: 0.0867\n",
      "Step 58/391, Loss: 0.0116\n",
      "Step 59/391, Loss: 0.0149\n",
      "Step 60/391, Loss: 0.0264\n",
      "Step 61/391, Loss: 0.0365\n",
      "Step 62/391, Loss: 0.0134\n",
      "Step 63/391, Loss: 0.0247\n",
      "Step 64/391, Loss: 0.0417\n",
      "Step 65/391, Loss: 0.0147\n",
      "Step 66/391, Loss: 0.0484\n",
      "Step 67/391, Loss: 0.0021\n",
      "Step 68/391, Loss: 0.0089\n",
      "Step 69/391, Loss: 0.0465\n",
      "Step 70/391, Loss: 0.0013\n",
      "Step 71/391, Loss: 0.0133\n",
      "Step 72/391, Loss: 0.0407\n",
      "Step 73/391, Loss: 0.0110\n",
      "Step 74/391, Loss: 0.0295\n",
      "Step 75/391, Loss: 0.0655\n",
      "Step 76/391, Loss: 0.0791\n",
      "Step 77/391, Loss: 0.0012\n",
      "Step 78/391, Loss: 0.0134\n",
      "Step 79/391, Loss: 0.0362\n",
      "Step 80/391, Loss: 0.0296\n",
      "Step 81/391, Loss: 0.0571\n",
      "Step 82/391, Loss: 0.0265\n",
      "Step 83/391, Loss: 0.0626\n",
      "Step 84/391, Loss: 0.0421\n",
      "Step 85/391, Loss: 0.0698\n",
      "Step 86/391, Loss: 0.0191\n",
      "Step 87/391, Loss: 0.0237\n",
      "Step 88/391, Loss: 0.0045\n",
      "Step 89/391, Loss: 0.0535\n",
      "Step 90/391, Loss: 0.0353\n",
      "Step 91/391, Loss: 0.0396\n",
      "Step 92/391, Loss: 0.0031\n",
      "Step 93/391, Loss: 0.0491\n",
      "Step 94/391, Loss: 0.0146\n",
      "Step 95/391, Loss: 0.0353\n",
      "Step 96/391, Loss: 0.0044\n",
      "Step 97/391, Loss: 0.0084\n",
      "Step 98/391, Loss: 0.0670\n",
      "Step 99/391, Loss: 0.0385\n",
      "Step 100/391, Loss: 0.0072\n",
      "Step 101/391, Loss: 0.0439\n",
      "Step 102/391, Loss: 0.0738\n",
      "Step 103/391, Loss: 0.0212\n",
      "Step 104/391, Loss: 0.0193\n",
      "Step 105/391, Loss: 0.0224\n",
      "Step 106/391, Loss: 0.0626\n",
      "Step 107/391, Loss: 0.0122\n",
      "Step 108/391, Loss: 0.0181\n",
      "Step 109/391, Loss: 0.0338\n",
      "Step 110/391, Loss: 0.0379\n",
      "Step 111/391, Loss: 0.0102\n",
      "Step 112/391, Loss: 0.0190\n",
      "Step 113/391, Loss: 0.0288\n",
      "Step 114/391, Loss: 0.0129\n",
      "Step 115/391, Loss: 0.0284\n",
      "Step 116/391, Loss: 0.0475\n",
      "Step 117/391, Loss: 0.0063\n",
      "Step 118/391, Loss: 0.0266\n",
      "Step 119/391, Loss: 0.0577\n",
      "Step 120/391, Loss: 0.0553\n",
      "Step 121/391, Loss: 0.0225\n",
      "Step 122/391, Loss: 0.0320\n",
      "Step 123/391, Loss: 0.0879\n",
      "Step 124/391, Loss: 0.0145\n",
      "Step 125/391, Loss: 0.0791\n",
      "Step 126/391, Loss: 0.0594\n",
      "Step 127/391, Loss: 0.0283\n",
      "Step 128/391, Loss: 0.0365\n",
      "Step 129/391, Loss: 0.0100\n",
      "Step 130/391, Loss: 0.0269\n",
      "Step 131/391, Loss: 0.0056\n",
      "Step 132/391, Loss: 0.0252\n",
      "Step 133/391, Loss: 0.1768\n",
      "Step 134/391, Loss: 0.0143\n",
      "Step 135/391, Loss: 0.0704\n",
      "Step 136/391, Loss: 0.0291\n",
      "Step 137/391, Loss: 0.0299\n",
      "Step 138/391, Loss: 0.0117\n",
      "Step 139/391, Loss: 0.0672\n",
      "Step 140/391, Loss: 0.0083\n",
      "Step 141/391, Loss: 0.0352\n",
      "Step 142/391, Loss: 0.0575\n",
      "Step 143/391, Loss: 0.0853\n",
      "Step 144/391, Loss: 0.0304\n",
      "Step 145/391, Loss: 0.0117\n",
      "Step 146/391, Loss: 0.0062\n",
      "Step 147/391, Loss: 0.0767\n",
      "Step 148/391, Loss: 0.0628\n",
      "Step 149/391, Loss: 0.0021\n",
      "Step 150/391, Loss: 0.0651\n",
      "Step 151/391, Loss: 0.0019\n",
      "Step 152/391, Loss: 0.0284\n",
      "Step 153/391, Loss: 0.0266\n",
      "Step 154/391, Loss: 0.0270\n",
      "Step 155/391, Loss: 0.0865\n",
      "Step 156/391, Loss: 0.0958\n",
      "Step 157/391, Loss: 0.0289\n",
      "Step 158/391, Loss: 0.0046\n",
      "Step 159/391, Loss: 0.1168\n",
      "Step 160/391, Loss: 0.0380\n",
      "Step 161/391, Loss: 0.0404\n",
      "Step 162/391, Loss: 0.0166\n",
      "Step 163/391, Loss: 0.0208\n",
      "Step 164/391, Loss: 0.0096\n",
      "Step 165/391, Loss: 0.0046\n",
      "Step 166/391, Loss: 0.0446\n",
      "Step 167/391, Loss: 0.0129\n",
      "Step 168/391, Loss: 0.0404\n",
      "Step 169/391, Loss: 0.0433\n",
      "Step 170/391, Loss: 0.0093\n",
      "Step 171/391, Loss: 0.1416\n",
      "Step 172/391, Loss: 0.1546\n",
      "Step 173/391, Loss: 0.0283\n",
      "Step 174/391, Loss: 0.0141\n",
      "Step 175/391, Loss: 0.0263\n",
      "Step 176/391, Loss: 0.0070\n",
      "Step 177/391, Loss: 0.0348\n",
      "Step 178/391, Loss: 0.0377\n",
      "Step 179/391, Loss: 0.0144\n",
      "Step 180/391, Loss: 0.0733\n",
      "Step 181/391, Loss: 0.0728\n",
      "Step 182/391, Loss: 0.0065\n",
      "Step 183/391, Loss: 0.0198\n",
      "Step 184/391, Loss: 0.1131\n",
      "Step 185/391, Loss: 0.0399\n",
      "Step 186/391, Loss: 0.0112\n",
      "Step 187/391, Loss: 0.0037\n",
      "Step 188/391, Loss: 0.0749\n",
      "Step 189/391, Loss: 0.0441\n",
      "Step 190/391, Loss: 0.0374\n",
      "Step 191/391, Loss: 0.0066\n",
      "Step 192/391, Loss: 0.0509\n",
      "Step 193/391, Loss: 0.0988\n",
      "Step 194/391, Loss: 0.0475\n",
      "Step 195/391, Loss: 0.0128\n",
      "Step 196/391, Loss: 0.0408\n",
      "Step 197/391, Loss: 0.0180\n",
      "Step 198/391, Loss: 0.0223\n",
      "Step 199/391, Loss: 0.0167\n",
      "Step 200/391, Loss: 0.0196\n",
      "Step 201/391, Loss: 0.0382\n",
      "Step 202/391, Loss: 0.0142\n",
      "Step 203/391, Loss: 0.0494\n",
      "Step 204/391, Loss: 0.0290\n",
      "Step 205/391, Loss: 0.0614\n",
      "Step 206/391, Loss: 0.0649\n",
      "Step 207/391, Loss: 0.0142\n",
      "Step 208/391, Loss: 0.0703\n",
      "Step 209/391, Loss: 0.0445\n",
      "Step 210/391, Loss: 0.0333\n",
      "Step 211/391, Loss: 0.0292\n",
      "Step 212/391, Loss: 0.0121\n",
      "Step 213/391, Loss: 0.0478\n",
      "Step 214/391, Loss: 0.0083\n",
      "Step 215/391, Loss: 0.0035\n",
      "Step 216/391, Loss: 0.0258\n",
      "Step 217/391, Loss: 0.0052\n",
      "Step 218/391, Loss: 0.0435\n",
      "Step 219/391, Loss: 0.0369\n",
      "Step 220/391, Loss: 0.0766\n",
      "Step 221/391, Loss: 0.1016\n",
      "Step 222/391, Loss: 0.0116\n",
      "Step 223/391, Loss: 0.0760\n",
      "Step 224/391, Loss: 0.0776\n",
      "Step 225/391, Loss: 0.0485\n",
      "Step 226/391, Loss: 0.0175\n",
      "Step 227/391, Loss: 0.0204\n",
      "Step 228/391, Loss: 0.0148\n",
      "Step 229/391, Loss: 0.0250\n",
      "Step 230/391, Loss: 0.0038\n",
      "Step 231/391, Loss: 0.0710\n",
      "Step 232/391, Loss: 0.0335\n",
      "Step 233/391, Loss: 0.0039\n",
      "Step 234/391, Loss: 0.0014\n",
      "Step 235/391, Loss: 0.0109\n",
      "Step 236/391, Loss: 0.0856\n",
      "Step 237/391, Loss: 0.0440\n",
      "Step 238/391, Loss: 0.0355\n",
      "Step 239/391, Loss: 0.0094\n",
      "Step 240/391, Loss: 0.0435\n",
      "Step 241/391, Loss: 0.0042\n",
      "Step 242/391, Loss: 0.0538\n",
      "Step 243/391, Loss: 0.0753\n",
      "Step 244/391, Loss: 0.0363\n",
      "Step 245/391, Loss: 0.0247\n",
      "Step 246/391, Loss: 0.0225\n",
      "Step 247/391, Loss: 0.0228\n",
      "Step 248/391, Loss: 0.0790\n",
      "Step 249/391, Loss: 0.0180\n",
      "Step 250/391, Loss: 0.0067\n",
      "Step 251/391, Loss: 0.0098\n",
      "Step 252/391, Loss: 0.0771\n",
      "Step 253/391, Loss: 0.0790\n",
      "Step 254/391, Loss: 0.0094\n",
      "Step 255/391, Loss: 0.0621\n",
      "Step 256/391, Loss: 0.0199\n",
      "Step 257/391, Loss: 0.0054\n",
      "Step 258/391, Loss: 0.0714\n",
      "Step 259/391, Loss: 0.0813\n",
      "Step 260/391, Loss: 0.0217\n",
      "Step 261/391, Loss: 0.0417\n",
      "Step 262/391, Loss: 0.0476\n",
      "Step 263/391, Loss: 0.0143\n",
      "Step 264/391, Loss: 0.0498\n",
      "Step 265/391, Loss: 0.0102\n",
      "Step 266/391, Loss: 0.0776\n",
      "Step 267/391, Loss: 0.0179\n",
      "Step 268/391, Loss: 0.0899\n",
      "Step 269/391, Loss: 0.0609\n",
      "Step 270/391, Loss: 0.0374\n",
      "Step 271/391, Loss: 0.0220\n",
      "Step 272/391, Loss: 0.0135\n",
      "Step 273/391, Loss: 0.0526\n",
      "Step 274/391, Loss: 0.0326\n",
      "Step 275/391, Loss: 0.0329\n",
      "Step 276/391, Loss: 0.0461\n",
      "Step 277/391, Loss: 0.0254\n",
      "Step 278/391, Loss: 0.0190\n",
      "Step 279/391, Loss: 0.0030\n",
      "Step 280/391, Loss: 0.0027\n",
      "Step 281/391, Loss: 0.0463\n",
      "Step 282/391, Loss: 0.0203\n",
      "Step 283/391, Loss: 0.0783\n",
      "Step 284/391, Loss: 0.0121\n",
      "Step 285/391, Loss: 0.0479\n",
      "Step 286/391, Loss: 0.0336\n",
      "Step 287/391, Loss: 0.0254\n",
      "Step 288/391, Loss: 0.0612\n",
      "Step 289/391, Loss: 0.0875\n",
      "Step 290/391, Loss: 0.0254\n",
      "Step 291/391, Loss: 0.0086\n",
      "Step 292/391, Loss: 0.0735\n",
      "Step 293/391, Loss: 0.0390\n",
      "Step 294/391, Loss: 0.0244\n",
      "Step 295/391, Loss: 0.1072\n",
      "Step 296/391, Loss: 0.0431\n",
      "Step 297/391, Loss: 0.0571\n",
      "Step 298/391, Loss: 0.0410\n",
      "Step 299/391, Loss: 0.0324\n",
      "Step 300/391, Loss: 0.0244\n",
      "Step 301/391, Loss: 0.0203\n",
      "Step 302/391, Loss: 0.0062\n",
      "Step 303/391, Loss: 0.0389\n",
      "Step 304/391, Loss: 0.0707\n",
      "Step 305/391, Loss: 0.0545\n",
      "Step 306/391, Loss: 0.0050\n",
      "Step 307/391, Loss: 0.0591\n",
      "Step 308/391, Loss: 0.0557\n",
      "Step 309/391, Loss: 0.0188\n",
      "Step 310/391, Loss: 0.0174\n",
      "Step 311/391, Loss: 0.0187\n",
      "Step 312/391, Loss: 0.0266\n",
      "Step 313/391, Loss: 0.0167\n",
      "Step 314/391, Loss: 0.0784\n",
      "Step 315/391, Loss: 0.0031\n",
      "Step 316/391, Loss: 0.0306\n",
      "Step 317/391, Loss: 0.0137\n",
      "Step 318/391, Loss: 0.0548\n",
      "Step 319/391, Loss: 0.0207\n",
      "Step 320/391, Loss: 0.0174\n",
      "Step 321/391, Loss: 0.0428\n",
      "Step 322/391, Loss: 0.0167\n",
      "Step 323/391, Loss: 0.0472\n",
      "Step 324/391, Loss: 0.0039\n",
      "Step 325/391, Loss: 0.0416\n",
      "Step 326/391, Loss: 0.0160\n",
      "Step 327/391, Loss: 0.0666\n",
      "Step 328/391, Loss: 0.0221\n",
      "Step 329/391, Loss: 0.0148\n",
      "Step 330/391, Loss: 0.0378\n",
      "Step 331/391, Loss: 0.0585\n",
      "Step 332/391, Loss: 0.0121\n",
      "Step 333/391, Loss: 0.0130\n",
      "Step 334/391, Loss: 0.1200\n",
      "Step 335/391, Loss: 0.0300\n",
      "Step 336/391, Loss: 0.0175\n",
      "Step 337/391, Loss: 0.0476\n",
      "Step 338/391, Loss: 0.0378\n",
      "Step 339/391, Loss: 0.0339\n",
      "Step 340/391, Loss: 0.0186\n",
      "Step 341/391, Loss: 0.1177\n",
      "Step 342/391, Loss: 0.0069\n",
      "Step 343/391, Loss: 0.0280\n",
      "Step 344/391, Loss: 0.0193\n",
      "Step 345/391, Loss: 0.1107\n",
      "Step 346/391, Loss: 0.0054\n",
      "Step 347/391, Loss: 0.0266\n",
      "Step 348/391, Loss: 0.0288\n",
      "Step 349/391, Loss: 0.0113\n",
      "Step 350/391, Loss: 0.0151\n",
      "Step 351/391, Loss: 0.0251\n",
      "Step 352/391, Loss: 0.0107\n",
      "Step 353/391, Loss: 0.0523\n",
      "Step 354/391, Loss: 0.0305\n",
      "Step 355/391, Loss: 0.0629\n",
      "Step 356/391, Loss: 0.1009\n",
      "Step 357/391, Loss: 0.0358\n",
      "Step 358/391, Loss: 0.0161\n",
      "Step 359/391, Loss: 0.1437\n",
      "Step 360/391, Loss: 0.0045\n",
      "Step 361/391, Loss: 0.0392\n",
      "Step 362/391, Loss: 0.0602\n",
      "Step 363/391, Loss: 0.0903\n",
      "Step 364/391, Loss: 0.0483\n",
      "Step 365/391, Loss: 0.0273\n",
      "Step 366/391, Loss: 0.0445\n",
      "Step 367/391, Loss: 0.0251\n",
      "Step 368/391, Loss: 0.0388\n",
      "Step 369/391, Loss: 0.0362\n",
      "Step 370/391, Loss: 0.0518\n",
      "Step 371/391, Loss: 0.0677\n",
      "Step 372/391, Loss: 0.0300\n",
      "Step 373/391, Loss: 0.0240\n",
      "Step 374/391, Loss: 0.0778\n",
      "Step 375/391, Loss: 0.0090\n",
      "Step 376/391, Loss: 0.0099\n",
      "Step 377/391, Loss: 0.0258\n",
      "Step 378/391, Loss: 0.0229\n",
      "Step 379/391, Loss: 0.0058\n",
      "Step 380/391, Loss: 0.0436\n",
      "Step 381/391, Loss: 0.1174\n",
      "Step 382/391, Loss: 0.0156\n",
      "Step 383/391, Loss: 0.0240\n",
      "Step 384/391, Loss: 0.0424\n",
      "Step 385/391, Loss: 0.0385\n",
      "Step 386/391, Loss: 0.0219\n",
      "Step 387/391, Loss: 0.0130\n",
      "Step 388/391, Loss: 0.0172\n",
      "Step 389/391, Loss: 0.0465\n",
      "Step 390/391, Loss: 0.0288\n",
      "Step 391/391, Loss: 0.0338\n",
      "Epoch 22/25, Average Train Loss: 0.0362\n",
      "Epoch 22/25, Average Validation Loss: 0.0805\n",
      "Step 1/391, Loss: 0.0159\n",
      "Step 2/391, Loss: 0.0216\n",
      "Step 3/391, Loss: 0.0021\n",
      "Step 4/391, Loss: 0.0528\n",
      "Step 5/391, Loss: 0.0087\n",
      "Step 6/391, Loss: 0.0432\n",
      "Step 7/391, Loss: 0.0031\n",
      "Step 8/391, Loss: 0.0311\n",
      "Step 9/391, Loss: 0.0427\n",
      "Step 10/391, Loss: 0.0143\n",
      "Step 11/391, Loss: 0.0357\n",
      "Step 12/391, Loss: 0.0212\n",
      "Step 13/391, Loss: 0.0376\n",
      "Step 14/391, Loss: 0.0185\n",
      "Step 15/391, Loss: 0.0053\n",
      "Step 16/391, Loss: 0.0365\n",
      "Step 17/391, Loss: 0.0328\n",
      "Step 18/391, Loss: 0.0198\n",
      "Step 19/391, Loss: 0.0120\n",
      "Step 20/391, Loss: 0.0202\n",
      "Step 21/391, Loss: 0.0325\n",
      "Step 22/391, Loss: 0.0494\n",
      "Step 23/391, Loss: 0.0212\n",
      "Step 24/391, Loss: 0.0443\n",
      "Step 25/391, Loss: 0.0100\n",
      "Step 26/391, Loss: 0.0185\n",
      "Step 27/391, Loss: 0.0243\n",
      "Step 28/391, Loss: 0.0497\n",
      "Step 29/391, Loss: 0.0402\n",
      "Step 30/391, Loss: 0.0337\n",
      "Step 31/391, Loss: 0.0694\n",
      "Step 32/391, Loss: 0.0023\n",
      "Step 33/391, Loss: 0.0451\n",
      "Step 34/391, Loss: 0.0242\n",
      "Step 35/391, Loss: 0.0874\n",
      "Step 36/391, Loss: 0.0553\n",
      "Step 37/391, Loss: 0.0096\n",
      "Step 38/391, Loss: 0.1217\n",
      "Step 39/391, Loss: 0.0034\n",
      "Step 40/391, Loss: 0.0794\n",
      "Step 41/391, Loss: 0.0161\n",
      "Step 42/391, Loss: 0.0547\n",
      "Step 43/391, Loss: 0.0222\n",
      "Step 44/391, Loss: 0.0034\n",
      "Step 45/391, Loss: 0.0319\n",
      "Step 46/391, Loss: 0.0121\n",
      "Step 47/391, Loss: 0.0415\n",
      "Step 48/391, Loss: 0.0412\n",
      "Step 49/391, Loss: 0.0617\n",
      "Step 50/391, Loss: 0.0196\n",
      "Step 51/391, Loss: 0.0838\n",
      "Step 52/391, Loss: 0.0397\n",
      "Step 53/391, Loss: 0.0068\n",
      "Step 54/391, Loss: 0.0030\n",
      "Step 55/391, Loss: 0.0983\n",
      "Step 56/391, Loss: 0.0049\n",
      "Step 57/391, Loss: 0.0210\n",
      "Step 58/391, Loss: 0.0077\n",
      "Step 59/391, Loss: 0.1157\n",
      "Step 60/391, Loss: 0.0611\n",
      "Step 61/391, Loss: 0.0119\n",
      "Step 62/391, Loss: 0.0313\n",
      "Step 63/391, Loss: 0.0489\n",
      "Step 64/391, Loss: 0.0782\n",
      "Step 65/391, Loss: 0.0089\n",
      "Step 66/391, Loss: 0.0614\n",
      "Step 67/391, Loss: 0.1479\n",
      "Step 68/391, Loss: 0.0470\n",
      "Step 69/391, Loss: 0.0737\n",
      "Step 70/391, Loss: 0.0024\n",
      "Step 71/391, Loss: 0.0883\n",
      "Step 72/391, Loss: 0.0213\n",
      "Step 73/391, Loss: 0.0372\n",
      "Step 74/391, Loss: 0.0252\n",
      "Step 75/391, Loss: 0.0250\n",
      "Step 76/391, Loss: 0.0212\n",
      "Step 77/391, Loss: 0.0403\n",
      "Step 78/391, Loss: 0.0135\n",
      "Step 79/391, Loss: 0.0579\n",
      "Step 80/391, Loss: 0.0293\n",
      "Step 81/391, Loss: 0.1183\n",
      "Step 82/391, Loss: 0.0073\n",
      "Step 83/391, Loss: 0.0171\n",
      "Step 84/391, Loss: 0.0090\n",
      "Step 85/391, Loss: 0.0134\n",
      "Step 86/391, Loss: 0.0445\n",
      "Step 87/391, Loss: 0.0420\n",
      "Step 88/391, Loss: 0.0378\n",
      "Step 89/391, Loss: 0.0401\n",
      "Step 90/391, Loss: 0.0783\n",
      "Step 91/391, Loss: 0.0094\n",
      "Step 92/391, Loss: 0.0221\n",
      "Step 93/391, Loss: 0.0355\n",
      "Step 94/391, Loss: 0.0195\n",
      "Step 95/391, Loss: 0.0039\n",
      "Step 96/391, Loss: 0.0713\n",
      "Step 97/391, Loss: 0.0461\n",
      "Step 98/391, Loss: 0.0690\n",
      "Step 99/391, Loss: 0.0089\n",
      "Step 100/391, Loss: 0.0279\n",
      "Step 101/391, Loss: 0.0452\n",
      "Step 102/391, Loss: 0.0318\n",
      "Step 103/391, Loss: 0.0095\n",
      "Step 104/391, Loss: 0.0444\n",
      "Step 105/391, Loss: 0.0245\n",
      "Step 106/391, Loss: 0.0226\n",
      "Step 107/391, Loss: 0.0308\n",
      "Step 108/391, Loss: 0.0488\n",
      "Step 109/391, Loss: 0.0504\n",
      "Step 110/391, Loss: 0.0917\n",
      "Step 111/391, Loss: 0.0153\n",
      "Step 112/391, Loss: 0.0252\n",
      "Step 113/391, Loss: 0.0097\n",
      "Step 114/391, Loss: 0.0096\n",
      "Step 115/391, Loss: 0.0459\n",
      "Step 116/391, Loss: 0.0330\n",
      "Step 117/391, Loss: 0.0708\n",
      "Step 118/391, Loss: 0.0531\n",
      "Step 119/391, Loss: 0.0502\n",
      "Step 120/391, Loss: 0.1187\n",
      "Step 121/391, Loss: 0.0218\n",
      "Step 122/391, Loss: 0.0213\n",
      "Step 123/391, Loss: 0.0734\n",
      "Step 124/391, Loss: 0.0102\n",
      "Step 125/391, Loss: 0.0590\n",
      "Step 126/391, Loss: 0.0035\n",
      "Step 127/391, Loss: 0.0970\n",
      "Step 128/391, Loss: 0.0050\n",
      "Step 129/391, Loss: 0.0759\n",
      "Step 130/391, Loss: 0.0301\n",
      "Step 131/391, Loss: 0.0419\n",
      "Step 132/391, Loss: 0.0694\n",
      "Step 133/391, Loss: 0.0036\n",
      "Step 134/391, Loss: 0.0981\n",
      "Step 135/391, Loss: 0.0327\n",
      "Step 136/391, Loss: 0.0128\n",
      "Step 137/391, Loss: 0.0547\n",
      "Step 138/391, Loss: 0.0233\n",
      "Step 139/391, Loss: 0.0505\n",
      "Step 140/391, Loss: 0.0306\n",
      "Step 141/391, Loss: 0.0171\n",
      "Step 142/391, Loss: 0.0238\n",
      "Step 143/391, Loss: 0.0156\n",
      "Step 144/391, Loss: 0.0272\n",
      "Step 145/391, Loss: 0.0093\n",
      "Step 146/391, Loss: 0.0241\n",
      "Step 147/391, Loss: 0.0316\n",
      "Step 148/391, Loss: 0.0964\n",
      "Step 149/391, Loss: 0.0064\n",
      "Step 150/391, Loss: 0.0266\n",
      "Step 151/391, Loss: 0.0046\n",
      "Step 152/391, Loss: 0.0507\n",
      "Step 153/391, Loss: 0.0225\n",
      "Step 154/391, Loss: 0.0442\n",
      "Step 155/391, Loss: 0.0104\n",
      "Step 156/391, Loss: 0.0065\n",
      "Step 157/391, Loss: 0.0986\n",
      "Step 158/391, Loss: 0.0338\n",
      "Step 159/391, Loss: 0.0261\n",
      "Step 160/391, Loss: 0.0240\n",
      "Step 161/391, Loss: 0.0168\n",
      "Step 162/391, Loss: 0.0114\n",
      "Step 163/391, Loss: 0.0034\n",
      "Step 164/391, Loss: 0.0153\n",
      "Step 165/391, Loss: 0.0537\n",
      "Step 166/391, Loss: 0.0298\n",
      "Step 167/391, Loss: 0.0325\n",
      "Step 168/391, Loss: 0.0375\n",
      "Step 169/391, Loss: 0.0057\n",
      "Step 170/391, Loss: 0.0060\n",
      "Step 171/391, Loss: 0.0710\n",
      "Step 172/391, Loss: 0.0554\n",
      "Step 173/391, Loss: 0.0323\n",
      "Step 174/391, Loss: 0.0110\n",
      "Step 175/391, Loss: 0.0436\n",
      "Step 176/391, Loss: 0.0204\n",
      "Step 177/391, Loss: 0.0616\n",
      "Step 178/391, Loss: 0.0168\n",
      "Step 179/391, Loss: 0.0729\n",
      "Step 180/391, Loss: 0.0221\n",
      "Step 181/391, Loss: 0.0605\n",
      "Step 182/391, Loss: 0.0354\n",
      "Step 183/391, Loss: 0.0144\n",
      "Step 184/391, Loss: 0.0042\n",
      "Step 185/391, Loss: 0.0193\n",
      "Step 186/391, Loss: 0.0521\n",
      "Step 187/391, Loss: 0.1182\n",
      "Step 188/391, Loss: 0.0093\n",
      "Step 189/391, Loss: 0.0640\n",
      "Step 190/391, Loss: 0.0082\n",
      "Step 191/391, Loss: 0.0387\n",
      "Step 192/391, Loss: 0.0111\n",
      "Step 193/391, Loss: 0.0690\n",
      "Step 194/391, Loss: 0.0054\n",
      "Step 195/391, Loss: 0.1082\n",
      "Step 196/391, Loss: 0.0352\n",
      "Step 197/391, Loss: 0.0229\n",
      "Step 198/391, Loss: 0.0155\n",
      "Step 199/391, Loss: 0.0070\n",
      "Step 200/391, Loss: 0.0114\n",
      "Step 201/391, Loss: 0.0891\n",
      "Step 202/391, Loss: 0.0992\n",
      "Step 203/391, Loss: 0.0301\n",
      "Step 204/391, Loss: 0.0172\n",
      "Step 205/391, Loss: 0.0058\n",
      "Step 206/391, Loss: 0.0690\n",
      "Step 207/391, Loss: 0.0240\n",
      "Step 208/391, Loss: 0.0109\n",
      "Step 209/391, Loss: 0.0437\n",
      "Step 210/391, Loss: 0.0744\n",
      "Step 211/391, Loss: 0.0381\n",
      "Step 212/391, Loss: 0.0092\n",
      "Step 213/391, Loss: 0.0148\n",
      "Step 214/391, Loss: 0.0043\n",
      "Step 215/391, Loss: 0.0779\n",
      "Step 216/391, Loss: 0.0093\n",
      "Step 217/391, Loss: 0.0426\n",
      "Step 218/391, Loss: 0.0399\n",
      "Step 219/391, Loss: 0.0445\n",
      "Step 220/391, Loss: 0.0837\n",
      "Step 221/391, Loss: 0.0223\n",
      "Step 222/391, Loss: 0.0404\n",
      "Step 223/391, Loss: 0.0798\n",
      "Step 224/391, Loss: 0.0099\n",
      "Step 225/391, Loss: 0.0023\n",
      "Step 226/391, Loss: 0.0685\n",
      "Step 227/391, Loss: 0.0951\n",
      "Step 228/391, Loss: 0.0164\n",
      "Step 229/391, Loss: 0.0638\n",
      "Step 230/391, Loss: 0.0144\n",
      "Step 231/391, Loss: 0.0452\n",
      "Step 232/391, Loss: 0.0314\n",
      "Step 233/391, Loss: 0.0077\n",
      "Step 234/391, Loss: 0.1123\n",
      "Step 235/391, Loss: 0.0521\n",
      "Step 236/391, Loss: 0.0083\n",
      "Step 237/391, Loss: 0.0064\n",
      "Step 238/391, Loss: 0.0285\n",
      "Step 239/391, Loss: 0.0171\n",
      "Step 240/391, Loss: 0.1035\n",
      "Step 241/391, Loss: 0.0025\n",
      "Step 242/391, Loss: 0.0199\n",
      "Step 243/391, Loss: 0.0103\n",
      "Step 244/391, Loss: 0.0044\n",
      "Step 245/391, Loss: 0.0100\n",
      "Step 246/391, Loss: 0.0239\n",
      "Step 247/391, Loss: 0.0334\n",
      "Step 248/391, Loss: 0.0598\n",
      "Step 249/391, Loss: 0.0073\n",
      "Step 250/391, Loss: 0.0447\n",
      "Step 251/391, Loss: 0.0554\n",
      "Step 252/391, Loss: 0.0981\n",
      "Step 253/391, Loss: 0.0381\n",
      "Step 254/391, Loss: 0.0139\n",
      "Step 255/391, Loss: 0.0290\n",
      "Step 256/391, Loss: 0.0339\n",
      "Step 257/391, Loss: 0.0383\n",
      "Step 258/391, Loss: 0.0560\n",
      "Step 259/391, Loss: 0.0263\n",
      "Step 260/391, Loss: 0.0700\n",
      "Step 261/391, Loss: 0.0283\n",
      "Step 262/391, Loss: 0.0434\n",
      "Step 263/391, Loss: 0.0371\n",
      "Step 264/391, Loss: 0.0055\n",
      "Step 265/391, Loss: 0.0351\n",
      "Step 266/391, Loss: 0.0058\n",
      "Step 267/391, Loss: 0.0378\n",
      "Step 268/391, Loss: 0.0317\n",
      "Step 269/391, Loss: 0.0228\n",
      "Step 270/391, Loss: 0.0138\n",
      "Step 271/391, Loss: 0.0489\n",
      "Step 272/391, Loss: 0.0863\n",
      "Step 273/391, Loss: 0.0011\n",
      "Step 274/391, Loss: 0.0301\n",
      "Step 275/391, Loss: 0.0250\n",
      "Step 276/391, Loss: 0.0343\n",
      "Step 277/391, Loss: 0.0298\n",
      "Step 278/391, Loss: 0.0339\n",
      "Step 279/391, Loss: 0.0223\n",
      "Step 280/391, Loss: 0.0313\n",
      "Step 281/391, Loss: 0.0679\n",
      "Step 282/391, Loss: 0.0181\n",
      "Step 283/391, Loss: 0.0816\n",
      "Step 284/391, Loss: 0.0404\n",
      "Step 285/391, Loss: 0.0709\n",
      "Step 286/391, Loss: 0.0519\n",
      "Step 287/391, Loss: 0.0079\n",
      "Step 288/391, Loss: 0.0276\n",
      "Step 289/391, Loss: 0.0245\n",
      "Step 290/391, Loss: 0.0069\n",
      "Step 291/391, Loss: 0.0258\n",
      "Step 292/391, Loss: 0.0439\n",
      "Step 293/391, Loss: 0.0957\n",
      "Step 294/391, Loss: 0.0397\n",
      "Step 295/391, Loss: 0.0255\n",
      "Step 296/391, Loss: 0.0894\n",
      "Step 297/391, Loss: 0.0201\n",
      "Step 298/391, Loss: 0.0038\n",
      "Step 299/391, Loss: 0.0271\n",
      "Step 300/391, Loss: 0.0559\n",
      "Step 301/391, Loss: 0.0099\n",
      "Step 302/391, Loss: 0.0058\n",
      "Step 303/391, Loss: 0.0427\n",
      "Step 304/391, Loss: 0.0129\n",
      "Step 305/391, Loss: 0.0755\n",
      "Step 306/391, Loss: 0.0241\n",
      "Step 307/391, Loss: 0.0972\n",
      "Step 308/391, Loss: 0.1371\n",
      "Step 309/391, Loss: 0.0245\n",
      "Step 310/391, Loss: 0.0441\n",
      "Step 311/391, Loss: 0.0335\n",
      "Step 312/391, Loss: 0.0619\n",
      "Step 313/391, Loss: 0.0805\n",
      "Step 314/391, Loss: 0.0149\n",
      "Step 315/391, Loss: 0.0627\n",
      "Step 316/391, Loss: 0.0525\n",
      "Step 317/391, Loss: 0.0229\n",
      "Step 318/391, Loss: 0.0514\n",
      "Step 319/391, Loss: 0.0765\n",
      "Step 320/391, Loss: 0.0516\n",
      "Step 321/391, Loss: 0.0156\n",
      "Step 322/391, Loss: 0.0743\n",
      "Step 323/391, Loss: 0.0484\n",
      "Step 324/391, Loss: 0.0799\n",
      "Step 325/391, Loss: 0.0100\n",
      "Step 326/391, Loss: 0.0187\n",
      "Step 327/391, Loss: 0.0040\n",
      "Step 328/391, Loss: 0.0247\n",
      "Step 329/391, Loss: 0.0194\n",
      "Step 330/391, Loss: 0.0325\n",
      "Step 331/391, Loss: 0.0400\n",
      "Step 332/391, Loss: 0.0727\n",
      "Step 333/391, Loss: 0.0558\n",
      "Step 334/391, Loss: 0.0468\n",
      "Step 335/391, Loss: 0.0308\n",
      "Step 336/391, Loss: 0.0523\n",
      "Step 337/391, Loss: 0.0263\n",
      "Step 338/391, Loss: 0.0067\n",
      "Step 339/391, Loss: 0.0773\n",
      "Step 340/391, Loss: 0.0115\n",
      "Step 341/391, Loss: 0.0273\n",
      "Step 342/391, Loss: 0.1296\n",
      "Step 343/391, Loss: 0.0147\n",
      "Step 344/391, Loss: 0.0756\n",
      "Step 345/391, Loss: 0.0059\n",
      "Step 346/391, Loss: 0.0096\n",
      "Step 347/391, Loss: 0.0275\n",
      "Step 348/391, Loss: 0.0537\n",
      "Step 349/391, Loss: 0.0341\n",
      "Step 350/391, Loss: 0.0538\n",
      "Step 351/391, Loss: 0.0509\n",
      "Step 352/391, Loss: 0.0673\n",
      "Step 353/391, Loss: 0.0390\n",
      "Step 354/391, Loss: 0.0173\n",
      "Step 355/391, Loss: 0.0846\n",
      "Step 356/391, Loss: 0.0547\n",
      "Step 357/391, Loss: 0.0315\n",
      "Step 358/391, Loss: 0.0314\n",
      "Step 359/391, Loss: 0.0122\n",
      "Step 360/391, Loss: 0.0435\n",
      "Step 361/391, Loss: 0.0078\n",
      "Step 362/391, Loss: 0.0331\n",
      "Step 363/391, Loss: 0.0122\n",
      "Step 364/391, Loss: 0.0087\n",
      "Step 365/391, Loss: 0.0071\n",
      "Step 366/391, Loss: 0.0600\n",
      "Step 367/391, Loss: 0.0323\n",
      "Step 368/391, Loss: 0.0255\n",
      "Step 369/391, Loss: 0.0168\n",
      "Step 370/391, Loss: 0.0428\n",
      "Step 371/391, Loss: 0.0580\n",
      "Step 372/391, Loss: 0.0113\n",
      "Step 373/391, Loss: 0.0178\n",
      "Step 374/391, Loss: 0.0093\n",
      "Step 375/391, Loss: 0.0468\n",
      "Step 376/391, Loss: 0.0232\n",
      "Step 377/391, Loss: 0.0369\n",
      "Step 378/391, Loss: 0.0246\n",
      "Step 379/391, Loss: 0.0113\n",
      "Step 380/391, Loss: 0.0462\n",
      "Step 381/391, Loss: 0.1108\n",
      "Step 382/391, Loss: 0.0598\n",
      "Step 383/391, Loss: 0.0312\n",
      "Step 384/391, Loss: 0.0447\n",
      "Step 385/391, Loss: 0.0248\n",
      "Step 386/391, Loss: 0.0194\n",
      "Step 387/391, Loss: 0.0293\n",
      "Step 388/391, Loss: 0.0131\n",
      "Step 389/391, Loss: 0.0301\n",
      "Step 390/391, Loss: 0.0130\n",
      "Step 391/391, Loss: 0.0789\n",
      "Epoch 23/25, Average Train Loss: 0.0372\n",
      "Epoch 23/25, Average Validation Loss: 0.0734\n",
      "Model saved at epoch 23 with validation loss: 0.0734\n",
      "Step 1/391, Loss: 0.0235\n",
      "Step 2/391, Loss: 0.0546\n",
      "Step 3/391, Loss: 0.0059\n",
      "Step 4/391, Loss: 0.0078\n",
      "Step 5/391, Loss: 0.0310\n",
      "Step 6/391, Loss: 0.0107\n",
      "Step 7/391, Loss: 0.0502\n",
      "Step 8/391, Loss: 0.0122\n",
      "Step 9/391, Loss: 0.0337\n",
      "Step 10/391, Loss: 0.0064\n",
      "Step 11/391, Loss: 0.0842\n",
      "Step 12/391, Loss: 0.0231\n",
      "Step 13/391, Loss: 0.0277\n",
      "Step 14/391, Loss: 0.0293\n",
      "Step 15/391, Loss: 0.0159\n",
      "Step 16/391, Loss: 0.0383\n",
      "Step 17/391, Loss: 0.0039\n",
      "Step 18/391, Loss: 0.0175\n",
      "Step 19/391, Loss: 0.0158\n",
      "Step 20/391, Loss: 0.0171\n",
      "Step 21/391, Loss: 0.0824\n",
      "Step 22/391, Loss: 0.0159\n",
      "Step 23/391, Loss: 0.0108\n",
      "Step 24/391, Loss: 0.0041\n",
      "Step 25/391, Loss: 0.0457\n",
      "Step 26/391, Loss: 0.0855\n",
      "Step 27/391, Loss: 0.0190\n",
      "Step 28/391, Loss: 0.0474\n",
      "Step 29/391, Loss: 0.0036\n",
      "Step 30/391, Loss: 0.0427\n",
      "Step 31/391, Loss: 0.0097\n",
      "Step 32/391, Loss: 0.0284\n",
      "Step 33/391, Loss: 0.1153\n",
      "Step 34/391, Loss: 0.0966\n",
      "Step 35/391, Loss: 0.0325\n",
      "Step 36/391, Loss: 0.0244\n",
      "Step 37/391, Loss: 0.0465\n",
      "Step 38/391, Loss: 0.0052\n",
      "Step 39/391, Loss: 0.0409\n",
      "Step 40/391, Loss: 0.0101\n",
      "Step 41/391, Loss: 0.0067\n",
      "Step 42/391, Loss: 0.0373\n",
      "Step 43/391, Loss: 0.0042\n",
      "Step 44/391, Loss: 0.1252\n",
      "Step 45/391, Loss: 0.0295\n",
      "Step 46/391, Loss: 0.0341\n",
      "Step 47/391, Loss: 0.0129\n",
      "Step 48/391, Loss: 0.0049\n",
      "Step 49/391, Loss: 0.0056\n",
      "Step 50/391, Loss: 0.0218\n",
      "Step 51/391, Loss: 0.0374\n",
      "Step 52/391, Loss: 0.0403\n",
      "Step 53/391, Loss: 0.0420\n",
      "Step 54/391, Loss: 0.0503\n",
      "Step 55/391, Loss: 0.0364\n",
      "Step 56/391, Loss: 0.0054\n",
      "Step 57/391, Loss: 0.0115\n",
      "Step 58/391, Loss: 0.0229\n",
      "Step 59/391, Loss: 0.0256\n",
      "Step 60/391, Loss: 0.0989\n",
      "Step 61/391, Loss: 0.0107\n",
      "Step 62/391, Loss: 0.0095\n",
      "Step 63/391, Loss: 0.0171\n",
      "Step 64/391, Loss: 0.0062\n",
      "Step 65/391, Loss: 0.0398\n",
      "Step 66/391, Loss: 0.0108\n",
      "Step 67/391, Loss: 0.0414\n",
      "Step 68/391, Loss: 0.0291\n",
      "Step 69/391, Loss: 0.1010\n",
      "Step 70/391, Loss: 0.0120\n",
      "Step 71/391, Loss: 0.0576\n",
      "Step 72/391, Loss: 0.0067\n",
      "Step 73/391, Loss: 0.0269\n",
      "Step 74/391, Loss: 0.0791\n",
      "Step 75/391, Loss: 0.0294\n",
      "Step 76/391, Loss: 0.0658\n",
      "Step 77/391, Loss: 0.0176\n",
      "Step 78/391, Loss: 0.0183\n",
      "Step 79/391, Loss: 0.0149\n",
      "Step 80/391, Loss: 0.0022\n",
      "Step 81/391, Loss: 0.1042\n",
      "Step 82/391, Loss: 0.0895\n",
      "Step 83/391, Loss: 0.0273\n",
      "Step 84/391, Loss: 0.0424\n",
      "Step 85/391, Loss: 0.0882\n",
      "Step 86/391, Loss: 0.0143\n",
      "Step 87/391, Loss: 0.0120\n",
      "Step 88/391, Loss: 0.0039\n",
      "Step 89/391, Loss: 0.0188\n",
      "Step 90/391, Loss: 0.0148\n",
      "Step 91/391, Loss: 0.0473\n",
      "Step 92/391, Loss: 0.0554\n",
      "Step 93/391, Loss: 0.0663\n",
      "Step 94/391, Loss: 0.0116\n",
      "Step 95/391, Loss: 0.0331\n",
      "Step 96/391, Loss: 0.0388\n",
      "Step 97/391, Loss: 0.0188\n",
      "Step 98/391, Loss: 0.0302\n",
      "Step 99/391, Loss: 0.0095\n",
      "Step 100/391, Loss: 0.0173\n",
      "Step 101/391, Loss: 0.0014\n",
      "Step 102/391, Loss: 0.0050\n",
      "Step 103/391, Loss: 0.0406\n",
      "Step 104/391, Loss: 0.0247\n",
      "Step 105/391, Loss: 0.0098\n",
      "Step 106/391, Loss: 0.0432\n",
      "Step 107/391, Loss: 0.0216\n",
      "Step 108/391, Loss: 0.0036\n",
      "Step 109/391, Loss: 0.0210\n",
      "Step 110/391, Loss: 0.0777\n",
      "Step 111/391, Loss: 0.0040\n",
      "Step 112/391, Loss: 0.0497\n",
      "Step 113/391, Loss: 0.0093\n",
      "Step 114/391, Loss: 0.0063\n",
      "Step 115/391, Loss: 0.0777\n",
      "Step 116/391, Loss: 0.0169\n",
      "Step 117/391, Loss: 0.0173\n",
      "Step 118/391, Loss: 0.0321\n",
      "Step 119/391, Loss: 0.0364\n",
      "Step 120/391, Loss: 0.0123\n",
      "Step 121/391, Loss: 0.0447\n",
      "Step 122/391, Loss: 0.0059\n",
      "Step 123/391, Loss: 0.0509\n",
      "Step 124/391, Loss: 0.0879\n",
      "Step 125/391, Loss: 0.1275\n",
      "Step 126/391, Loss: 0.0119\n",
      "Step 127/391, Loss: 0.0657\n",
      "Step 128/391, Loss: 0.0233\n",
      "Step 129/391, Loss: 0.0161\n",
      "Step 130/391, Loss: 0.0294\n",
      "Step 131/391, Loss: 0.0242\n",
      "Step 132/391, Loss: 0.0277\n",
      "Step 133/391, Loss: 0.0246\n",
      "Step 134/391, Loss: 0.0060\n",
      "Step 135/391, Loss: 0.0576\n",
      "Step 136/391, Loss: 0.0018\n",
      "Step 137/391, Loss: 0.0121\n",
      "Step 138/391, Loss: 0.0266\n",
      "Step 139/391, Loss: 0.0751\n",
      "Step 140/391, Loss: 0.0508\n",
      "Step 141/391, Loss: 0.0080\n",
      "Step 142/391, Loss: 0.0133\n",
      "Step 143/391, Loss: 0.0241\n",
      "Step 144/391, Loss: 0.0085\n",
      "Step 145/391, Loss: 0.0125\n",
      "Step 146/391, Loss: 0.0426\n",
      "Step 147/391, Loss: 0.0108\n",
      "Step 148/391, Loss: 0.0062\n",
      "Step 149/391, Loss: 0.0398\n",
      "Step 150/391, Loss: 0.0068\n",
      "Step 151/391, Loss: 0.0225\n",
      "Step 152/391, Loss: 0.0046\n",
      "Step 153/391, Loss: 0.0464\n",
      "Step 154/391, Loss: 0.0191\n",
      "Step 155/391, Loss: 0.0244\n",
      "Step 156/391, Loss: 0.0015\n",
      "Step 157/391, Loss: 0.0050\n",
      "Step 158/391, Loss: 0.0216\n",
      "Step 159/391, Loss: 0.0046\n",
      "Step 160/391, Loss: 0.0026\n",
      "Step 161/391, Loss: 0.0088\n",
      "Step 162/391, Loss: 0.0029\n",
      "Step 163/391, Loss: 0.0390\n",
      "Step 164/391, Loss: 0.0032\n",
      "Step 165/391, Loss: 0.0097\n",
      "Step 166/391, Loss: 0.0400\n",
      "Step 167/391, Loss: 0.0277\n",
      "Step 168/391, Loss: 0.0307\n",
      "Step 169/391, Loss: 0.0788\n",
      "Step 170/391, Loss: 0.0065\n",
      "Step 171/391, Loss: 0.0372\n",
      "Step 172/391, Loss: 0.0224\n",
      "Step 173/391, Loss: 0.0143\n",
      "Step 174/391, Loss: 0.0166\n",
      "Step 175/391, Loss: 0.0189\n",
      "Step 176/391, Loss: 0.0308\n",
      "Step 177/391, Loss: 0.0968\n",
      "Step 178/391, Loss: 0.0071\n",
      "Step 179/391, Loss: 0.0430\n",
      "Step 180/391, Loss: 0.0087\n",
      "Step 181/391, Loss: 0.0385\n",
      "Step 182/391, Loss: 0.0667\n",
      "Step 183/391, Loss: 0.0349\n",
      "Step 184/391, Loss: 0.0655\n",
      "Step 185/391, Loss: 0.0073\n",
      "Step 186/391, Loss: 0.0333\n",
      "Step 187/391, Loss: 0.0046\n",
      "Step 188/391, Loss: 0.0141\n",
      "Step 189/391, Loss: 0.0430\n",
      "Step 190/391, Loss: 0.0169\n",
      "Step 191/391, Loss: 0.0196\n",
      "Step 192/391, Loss: 0.0742\n",
      "Step 193/391, Loss: 0.0854\n",
      "Step 194/391, Loss: 0.0637\n",
      "Step 195/391, Loss: 0.0106\n",
      "Step 196/391, Loss: 0.0613\n",
      "Step 197/391, Loss: 0.0761\n",
      "Step 198/391, Loss: 0.0259\n",
      "Step 199/391, Loss: 0.0250\n",
      "Step 200/391, Loss: 0.0104\n",
      "Step 201/391, Loss: 0.0221\n",
      "Step 202/391, Loss: 0.0159\n",
      "Step 203/391, Loss: 0.0085\n",
      "Step 204/391, Loss: 0.0764\n",
      "Step 205/391, Loss: 0.0417\n",
      "Step 206/391, Loss: 0.0299\n",
      "Step 207/391, Loss: 0.0045\n",
      "Step 208/391, Loss: 0.0079\n",
      "Step 209/391, Loss: 0.0302\n",
      "Step 210/391, Loss: 0.0525\n",
      "Step 211/391, Loss: 0.0346\n",
      "Step 212/391, Loss: 0.0599\n",
      "Step 213/391, Loss: 0.0108\n",
      "Step 214/391, Loss: 0.0340\n",
      "Step 215/391, Loss: 0.0141\n",
      "Step 216/391, Loss: 0.0061\n",
      "Step 217/391, Loss: 0.0275\n",
      "Step 218/391, Loss: 0.0095\n",
      "Step 219/391, Loss: 0.0049\n",
      "Step 220/391, Loss: 0.0108\n",
      "Step 221/391, Loss: 0.0048\n",
      "Step 222/391, Loss: 0.0025\n",
      "Step 223/391, Loss: 0.0604\n",
      "Step 224/391, Loss: 0.0308\n",
      "Step 225/391, Loss: 0.0276\n",
      "Step 226/391, Loss: 0.0032\n",
      "Step 227/391, Loss: 0.0641\n",
      "Step 228/391, Loss: 0.0065\n",
      "Step 229/391, Loss: 0.0046\n",
      "Step 230/391, Loss: 0.0246\n",
      "Step 231/391, Loss: 0.0135\n",
      "Step 232/391, Loss: 0.0578\n",
      "Step 233/391, Loss: 0.0272\n",
      "Step 234/391, Loss: 0.0105\n",
      "Step 235/391, Loss: 0.0857\n",
      "Step 236/391, Loss: 0.0124\n",
      "Step 237/391, Loss: 0.0084\n",
      "Step 238/391, Loss: 0.0074\n",
      "Step 239/391, Loss: 0.0501\n",
      "Step 240/391, Loss: 0.1072\n",
      "Step 241/391, Loss: 0.0169\n",
      "Step 242/391, Loss: 0.0498\n",
      "Step 243/391, Loss: 0.0302\n",
      "Step 244/391, Loss: 0.0608\n",
      "Step 245/391, Loss: 0.0745\n",
      "Step 246/391, Loss: 0.0395\n",
      "Step 247/391, Loss: 0.0078\n",
      "Step 248/391, Loss: 0.0452\n",
      "Step 249/391, Loss: 0.0709\n",
      "Step 250/391, Loss: 0.0351\n",
      "Step 251/391, Loss: 0.0084\n",
      "Step 252/391, Loss: 0.0258\n",
      "Step 253/391, Loss: 0.0229\n",
      "Step 254/391, Loss: 0.0195\n",
      "Step 255/391, Loss: 0.0646\n",
      "Step 256/391, Loss: 0.0024\n",
      "Step 257/391, Loss: 0.0685\n",
      "Step 258/391, Loss: 0.0156\n",
      "Step 259/391, Loss: 0.0089\n",
      "Step 260/391, Loss: 0.0402\n",
      "Step 261/391, Loss: 0.0200\n",
      "Step 262/391, Loss: 0.0175\n",
      "Step 263/391, Loss: 0.0424\n",
      "Step 264/391, Loss: 0.0587\n",
      "Step 265/391, Loss: 0.0315\n",
      "Step 266/391, Loss: 0.0162\n",
      "Step 267/391, Loss: 0.0120\n",
      "Step 268/391, Loss: 0.0681\n",
      "Step 269/391, Loss: 0.0275\n",
      "Step 270/391, Loss: 0.0126\n",
      "Step 271/391, Loss: 0.0125\n",
      "Step 272/391, Loss: 0.0501\n",
      "Step 273/391, Loss: 0.0374\n",
      "Step 274/391, Loss: 0.0137\n",
      "Step 275/391, Loss: 0.0379\n",
      "Step 276/391, Loss: 0.0586\n",
      "Step 277/391, Loss: 0.0134\n",
      "Step 278/391, Loss: 0.0030\n",
      "Step 279/391, Loss: 0.0056\n",
      "Step 280/391, Loss: 0.0041\n",
      "Step 281/391, Loss: 0.0050\n",
      "Step 282/391, Loss: 0.0271\n",
      "Step 283/391, Loss: 0.0577\n",
      "Step 284/391, Loss: 0.0360\n",
      "Step 285/391, Loss: 0.0156\n",
      "Step 286/391, Loss: 0.0455\n",
      "Step 287/391, Loss: 0.0592\n",
      "Step 288/391, Loss: 0.0079\n",
      "Step 289/391, Loss: 0.0207\n",
      "Step 290/391, Loss: 0.0144\n",
      "Step 291/391, Loss: 0.0090\n",
      "Step 292/391, Loss: 0.0394\n",
      "Step 293/391, Loss: 0.0552\n",
      "Step 294/391, Loss: 0.0018\n",
      "Step 295/391, Loss: 0.0330\n",
      "Step 296/391, Loss: 0.0747\n",
      "Step 297/391, Loss: 0.0391\n",
      "Step 298/391, Loss: 0.0212\n",
      "Step 299/391, Loss: 0.0568\n",
      "Step 300/391, Loss: 0.0481\n",
      "Step 301/391, Loss: 0.0019\n",
      "Step 302/391, Loss: 0.0406\n",
      "Step 303/391, Loss: 0.0071\n",
      "Step 304/391, Loss: 0.0232\n",
      "Step 305/391, Loss: 0.0723\n",
      "Step 306/391, Loss: 0.0234\n",
      "Step 307/391, Loss: 0.0535\n",
      "Step 308/391, Loss: 0.0280\n",
      "Step 309/391, Loss: 0.0195\n",
      "Step 310/391, Loss: 0.0110\n",
      "Step 311/391, Loss: 0.0259\n",
      "Step 312/391, Loss: 0.0401\n",
      "Step 313/391, Loss: 0.0140\n",
      "Step 314/391, Loss: 0.0109\n",
      "Step 315/391, Loss: 0.0551\n",
      "Step 316/391, Loss: 0.0398\n",
      "Step 317/391, Loss: 0.0269\n",
      "Step 318/391, Loss: 0.0683\n",
      "Step 319/391, Loss: 0.0334\n",
      "Step 320/391, Loss: 0.0280\n",
      "Step 321/391, Loss: 0.0263\n",
      "Step 322/391, Loss: 0.0121\n",
      "Step 323/391, Loss: 0.0615\n",
      "Step 324/391, Loss: 0.0682\n",
      "Step 325/391, Loss: 0.0685\n",
      "Step 326/391, Loss: 0.0163\n",
      "Step 327/391, Loss: 0.0014\n",
      "Step 328/391, Loss: 0.0207\n",
      "Step 329/391, Loss: 0.0251\n",
      "Step 330/391, Loss: 0.0162\n",
      "Step 331/391, Loss: 0.0518\n",
      "Step 332/391, Loss: 0.0444\n",
      "Step 333/391, Loss: 0.1017\n",
      "Step 334/391, Loss: 0.0593\n",
      "Step 335/391, Loss: 0.0179\n",
      "Step 336/391, Loss: 0.0594\n",
      "Step 337/391, Loss: 0.0115\n",
      "Step 338/391, Loss: 0.0216\n",
      "Step 339/391, Loss: 0.0835\n",
      "Step 340/391, Loss: 0.0206\n",
      "Step 341/391, Loss: 0.0356\n",
      "Step 342/391, Loss: 0.0390\n",
      "Step 343/391, Loss: 0.0026\n",
      "Step 344/391, Loss: 0.0999\n",
      "Step 345/391, Loss: 0.0215\n",
      "Step 346/391, Loss: 0.0766\n",
      "Step 347/391, Loss: 0.0115\n",
      "Step 348/391, Loss: 0.0082\n",
      "Step 349/391, Loss: 0.0236\n",
      "Step 350/391, Loss: 0.0105\n",
      "Step 351/391, Loss: 0.0150\n",
      "Step 352/391, Loss: 0.0490\n",
      "Step 353/391, Loss: 0.0368\n",
      "Step 354/391, Loss: 0.0480\n",
      "Step 355/391, Loss: 0.0186\n",
      "Step 356/391, Loss: 0.0047\n",
      "Step 357/391, Loss: 0.0049\n",
      "Step 358/391, Loss: 0.0466\n",
      "Step 359/391, Loss: 0.0281\n",
      "Step 360/391, Loss: 0.0136\n",
      "Step 361/391, Loss: 0.0413\n",
      "Step 362/391, Loss: 0.0435\n",
      "Step 363/391, Loss: 0.0209\n",
      "Step 364/391, Loss: 0.0152\n",
      "Step 365/391, Loss: 0.0058\n",
      "Step 366/391, Loss: 0.0519\n",
      "Step 367/391, Loss: 0.0564\n",
      "Step 368/391, Loss: 0.0079\n",
      "Step 369/391, Loss: 0.0208\n",
      "Step 370/391, Loss: 0.0265\n",
      "Step 371/391, Loss: 0.0144\n",
      "Step 372/391, Loss: 0.0080\n",
      "Step 373/391, Loss: 0.0413\n",
      "Step 374/391, Loss: 0.0080\n",
      "Step 375/391, Loss: 0.0056\n",
      "Step 376/391, Loss: 0.0048\n",
      "Step 377/391, Loss: 0.0301\n",
      "Step 378/391, Loss: 0.0301\n",
      "Step 379/391, Loss: 0.0244\n",
      "Step 380/391, Loss: 0.0148\n",
      "Step 381/391, Loss: 0.0204\n",
      "Step 382/391, Loss: 0.0078\n",
      "Step 383/391, Loss: 0.1518\n",
      "Step 384/391, Loss: 0.0161\n",
      "Step 385/391, Loss: 0.0061\n",
      "Step 386/391, Loss: 0.0690\n",
      "Step 387/391, Loss: 0.0031\n",
      "Step 388/391, Loss: 0.0635\n",
      "Step 389/391, Loss: 0.0033\n",
      "Step 390/391, Loss: 0.0276\n",
      "Step 391/391, Loss: 0.1393\n",
      "Epoch 24/25, Average Train Loss: 0.0312\n",
      "Epoch 24/25, Average Validation Loss: 0.0798\n",
      "Step 1/391, Loss: 0.0148\n",
      "Step 2/391, Loss: 0.0067\n",
      "Step 3/391, Loss: 0.0034\n",
      "Step 4/391, Loss: 0.0087\n",
      "Step 5/391, Loss: 0.0275\n",
      "Step 6/391, Loss: 0.0075\n",
      "Step 7/391, Loss: 0.0102\n",
      "Step 8/391, Loss: 0.0221\n",
      "Step 9/391, Loss: 0.0077\n",
      "Step 10/391, Loss: 0.0302\n",
      "Step 11/391, Loss: 0.0433\n",
      "Step 12/391, Loss: 0.0243\n",
      "Step 13/391, Loss: 0.0200\n",
      "Step 14/391, Loss: 0.0407\n",
      "Step 15/391, Loss: 0.0351\n",
      "Step 16/391, Loss: 0.0229\n",
      "Step 17/391, Loss: 0.0343\n",
      "Step 18/391, Loss: 0.0113\n",
      "Step 19/391, Loss: 0.0102\n",
      "Step 20/391, Loss: 0.0299\n",
      "Step 21/391, Loss: 0.0139\n",
      "Step 22/391, Loss: 0.0157\n",
      "Step 23/391, Loss: 0.0396\n",
      "Step 24/391, Loss: 0.0300\n",
      "Step 25/391, Loss: 0.0475\n",
      "Step 26/391, Loss: 0.0015\n",
      "Step 27/391, Loss: 0.0330\n",
      "Step 28/391, Loss: 0.0252\n",
      "Step 29/391, Loss: 0.0139\n",
      "Step 30/391, Loss: 0.0497\n",
      "Step 31/391, Loss: 0.0030\n",
      "Step 32/391, Loss: 0.0227\n",
      "Step 33/391, Loss: 0.0032\n",
      "Step 34/391, Loss: 0.0393\n",
      "Step 35/391, Loss: 0.0059\n",
      "Step 36/391, Loss: 0.0390\n",
      "Step 37/391, Loss: 0.0174\n",
      "Step 38/391, Loss: 0.0291\n",
      "Step 39/391, Loss: 0.0358\n",
      "Step 40/391, Loss: 0.0010\n",
      "Step 41/391, Loss: 0.0526\n",
      "Step 42/391, Loss: 0.0159\n",
      "Step 43/391, Loss: 0.1277\n",
      "Step 44/391, Loss: 0.0389\n",
      "Step 45/391, Loss: 0.0527\n",
      "Step 46/391, Loss: 0.0078\n",
      "Step 47/391, Loss: 0.0021\n",
      "Step 48/391, Loss: 0.0023\n",
      "Step 49/391, Loss: 0.0288\n",
      "Step 50/391, Loss: 0.0057\n",
      "Step 51/391, Loss: 0.0937\n",
      "Step 52/391, Loss: 0.0443\n",
      "Step 53/391, Loss: 0.0848\n",
      "Step 54/391, Loss: 0.0034\n",
      "Step 55/391, Loss: 0.0321\n",
      "Step 56/391, Loss: 0.0483\n",
      "Step 57/391, Loss: 0.0020\n",
      "Step 58/391, Loss: 0.0296\n",
      "Step 59/391, Loss: 0.0625\n",
      "Step 60/391, Loss: 0.0226\n",
      "Step 61/391, Loss: 0.0235\n",
      "Step 62/391, Loss: 0.0177\n",
      "Step 63/391, Loss: 0.0683\n",
      "Step 64/391, Loss: 0.0275\n",
      "Step 65/391, Loss: 0.0614\n",
      "Step 66/391, Loss: 0.0358\n",
      "Step 67/391, Loss: 0.0752\n",
      "Step 68/391, Loss: 0.0227\n",
      "Step 69/391, Loss: 0.0034\n",
      "Step 70/391, Loss: 0.0337\n",
      "Step 71/391, Loss: 0.0230\n",
      "Step 72/391, Loss: 0.0301\n",
      "Step 73/391, Loss: 0.0094\n",
      "Step 74/391, Loss: 0.0502\n",
      "Step 75/391, Loss: 0.0145\n",
      "Step 76/391, Loss: 0.0043\n",
      "Step 77/391, Loss: 0.0688\n",
      "Step 78/391, Loss: 0.0257\n",
      "Step 79/391, Loss: 0.0316\n",
      "Step 80/391, Loss: 0.0108\n",
      "Step 81/391, Loss: 0.0629\n",
      "Step 82/391, Loss: 0.0885\n",
      "Step 83/391, Loss: 0.0251\n",
      "Step 84/391, Loss: 0.0526\n",
      "Step 85/391, Loss: 0.0080\n",
      "Step 86/391, Loss: 0.1932\n",
      "Step 87/391, Loss: 0.0118\n",
      "Step 88/391, Loss: 0.0348\n",
      "Step 89/391, Loss: 0.0103\n",
      "Step 90/391, Loss: 0.0382\n",
      "Step 91/391, Loss: 0.1009\n",
      "Step 92/391, Loss: 0.0289\n",
      "Step 93/391, Loss: 0.0195\n",
      "Step 94/391, Loss: 0.0392\n",
      "Step 95/391, Loss: 0.0316\n",
      "Step 96/391, Loss: 0.0867\n",
      "Step 97/391, Loss: 0.0109\n",
      "Step 98/391, Loss: 0.0672\n",
      "Step 99/391, Loss: 0.0317\n",
      "Step 100/391, Loss: 0.0065\n",
      "Step 101/391, Loss: 0.0411\n",
      "Step 102/391, Loss: 0.0076\n",
      "Step 103/391, Loss: 0.0172\n",
      "Step 104/391, Loss: 0.0286\n",
      "Step 105/391, Loss: 0.0119\n",
      "Step 106/391, Loss: 0.0444\n",
      "Step 107/391, Loss: 0.0262\n",
      "Step 108/391, Loss: 0.0166\n",
      "Step 109/391, Loss: 0.0633\n",
      "Step 110/391, Loss: 0.0102\n",
      "Step 111/391, Loss: 0.0048\n",
      "Step 112/391, Loss: 0.0180\n",
      "Step 113/391, Loss: 0.0452\n",
      "Step 114/391, Loss: 0.0269\n",
      "Step 115/391, Loss: 0.0738\n",
      "Step 116/391, Loss: 0.0308\n",
      "Step 117/391, Loss: 0.0288\n",
      "Step 118/391, Loss: 0.0044\n",
      "Step 119/391, Loss: 0.0296\n",
      "Step 120/391, Loss: 0.0116\n",
      "Step 121/391, Loss: 0.0497\n",
      "Step 122/391, Loss: 0.0211\n",
      "Step 123/391, Loss: 0.0494\n",
      "Step 124/391, Loss: 0.0517\n",
      "Step 125/391, Loss: 0.0028\n",
      "Step 126/391, Loss: 0.1048\n",
      "Step 127/391, Loss: 0.0626\n",
      "Step 128/391, Loss: 0.0174\n",
      "Step 129/391, Loss: 0.0065\n",
      "Step 130/391, Loss: 0.0119\n",
      "Step 131/391, Loss: 0.0097\n",
      "Step 132/391, Loss: 0.0071\n",
      "Step 133/391, Loss: 0.0690\n",
      "Step 134/391, Loss: 0.0649\n",
      "Step 135/391, Loss: 0.0169\n",
      "Step 136/391, Loss: 0.0463\n",
      "Step 137/391, Loss: 0.0057\n",
      "Step 138/391, Loss: 0.0429\n",
      "Step 139/391, Loss: 0.0984\n",
      "Step 140/391, Loss: 0.0272\n",
      "Step 141/391, Loss: 0.0110\n",
      "Step 142/391, Loss: 0.0460\n",
      "Step 143/391, Loss: 0.1067\n",
      "Step 144/391, Loss: 0.0523\n",
      "Step 145/391, Loss: 0.0602\n",
      "Step 146/391, Loss: 0.0680\n",
      "Step 147/391, Loss: 0.0449\n",
      "Step 148/391, Loss: 0.0105\n",
      "Step 149/391, Loss: 0.0762\n",
      "Step 150/391, Loss: 0.0159\n",
      "Step 151/391, Loss: 0.0040\n",
      "Step 152/391, Loss: 0.0038\n",
      "Step 153/391, Loss: 0.0100\n",
      "Step 154/391, Loss: 0.0783\n",
      "Step 155/391, Loss: 0.0149\n",
      "Step 156/391, Loss: 0.0742\n",
      "Step 157/391, Loss: 0.0351\n",
      "Step 158/391, Loss: 0.0579\n",
      "Step 159/391, Loss: 0.0215\n",
      "Step 160/391, Loss: 0.0718\n",
      "Step 161/391, Loss: 0.0204\n",
      "Step 162/391, Loss: 0.0267\n",
      "Step 163/391, Loss: 0.0409\n",
      "Step 164/391, Loss: 0.0038\n",
      "Step 165/391, Loss: 0.0496\n",
      "Step 166/391, Loss: 0.0042\n",
      "Step 167/391, Loss: 0.0264\n",
      "Step 168/391, Loss: 0.0057\n",
      "Step 169/391, Loss: 0.0215\n",
      "Step 170/391, Loss: 0.0274\n",
      "Step 171/391, Loss: 0.0100\n",
      "Step 172/391, Loss: 0.0127\n",
      "Step 173/391, Loss: 0.0737\n",
      "Step 174/391, Loss: 0.0291\n",
      "Step 175/391, Loss: 0.0140\n",
      "Step 176/391, Loss: 0.0459\n",
      "Step 177/391, Loss: 0.0610\n",
      "Step 178/391, Loss: 0.0241\n",
      "Step 179/391, Loss: 0.0171\n",
      "Step 180/391, Loss: 0.0253\n",
      "Step 181/391, Loss: 0.0116\n",
      "Step 182/391, Loss: 0.0421\n",
      "Step 183/391, Loss: 0.0398\n",
      "Step 184/391, Loss: 0.0267\n",
      "Step 185/391, Loss: 0.0481\n",
      "Step 186/391, Loss: 0.0022\n",
      "Step 187/391, Loss: 0.0408\n",
      "Step 188/391, Loss: 0.0172\n",
      "Step 189/391, Loss: 0.0540\n",
      "Step 190/391, Loss: 0.0089\n",
      "Step 191/391, Loss: 0.0036\n",
      "Step 192/391, Loss: 0.0366\n",
      "Step 193/391, Loss: 0.0085\n",
      "Step 194/391, Loss: 0.0161\n",
      "Step 195/391, Loss: 0.0810\n",
      "Step 196/391, Loss: 0.0212\n",
      "Step 197/391, Loss: 0.0122\n",
      "Step 198/391, Loss: 0.0428\n",
      "Step 199/391, Loss: 0.0732\n",
      "Step 200/391, Loss: 0.0288\n",
      "Step 201/391, Loss: 0.0033\n",
      "Step 202/391, Loss: 0.0314\n",
      "Step 203/391, Loss: 0.0562\n",
      "Step 204/391, Loss: 0.0222\n",
      "Step 205/391, Loss: 0.0123\n",
      "Step 206/391, Loss: 0.1003\n",
      "Step 207/391, Loss: 0.0501\n",
      "Step 208/391, Loss: 0.0498\n",
      "Step 209/391, Loss: 0.0197\n",
      "Step 210/391, Loss: 0.0280\n",
      "Step 211/391, Loss: 0.0790\n",
      "Step 212/391, Loss: 0.0151\n",
      "Step 213/391, Loss: 0.0288\n",
      "Step 214/391, Loss: 0.0091\n",
      "Step 215/391, Loss: 0.0168\n",
      "Step 216/391, Loss: 0.0178\n",
      "Step 217/391, Loss: 0.0245\n",
      "Step 218/391, Loss: 0.0025\n",
      "Step 219/391, Loss: 0.0827\n",
      "Step 220/391, Loss: 0.0107\n",
      "Step 221/391, Loss: 0.0293\n",
      "Step 222/391, Loss: 0.0040\n",
      "Step 223/391, Loss: 0.0391\n",
      "Step 224/391, Loss: 0.0434\n",
      "Step 225/391, Loss: 0.0884\n",
      "Step 226/391, Loss: 0.0367\n",
      "Step 227/391, Loss: 0.0087\n",
      "Step 228/391, Loss: 0.0138\n",
      "Step 229/391, Loss: 0.0085\n",
      "Step 230/391, Loss: 0.0291\n",
      "Step 231/391, Loss: 0.0032\n",
      "Step 232/391, Loss: 0.0304\n",
      "Step 233/391, Loss: 0.1017\n",
      "Step 234/391, Loss: 0.0050\n",
      "Step 235/391, Loss: 0.0026\n",
      "Step 236/391, Loss: 0.0078\n",
      "Step 237/391, Loss: 0.0224\n",
      "Step 238/391, Loss: 0.0262\n",
      "Step 239/391, Loss: 0.0091\n",
      "Step 240/391, Loss: 0.0192\n",
      "Step 241/391, Loss: 0.0029\n",
      "Step 242/391, Loss: 0.0208\n",
      "Step 243/391, Loss: 0.0300\n",
      "Step 244/391, Loss: 0.0420\n",
      "Step 245/391, Loss: 0.0263\n",
      "Step 246/391, Loss: 0.0119\n",
      "Step 247/391, Loss: 0.0018\n",
      "Step 248/391, Loss: 0.0158\n",
      "Step 249/391, Loss: 0.0025\n",
      "Step 250/391, Loss: 0.0058\n",
      "Step 251/391, Loss: 0.0342\n",
      "Step 252/391, Loss: 0.0475\n",
      "Step 253/391, Loss: 0.0086\n",
      "Step 254/391, Loss: 0.0175\n",
      "Step 255/391, Loss: 0.0170\n",
      "Step 256/391, Loss: 0.0012\n",
      "Step 257/391, Loss: 0.0345\n",
      "Step 258/391, Loss: 0.0296\n",
      "Step 259/391, Loss: 0.0072\n",
      "Step 260/391, Loss: 0.0077\n",
      "Step 261/391, Loss: 0.0044\n",
      "Step 262/391, Loss: 0.0062\n",
      "Step 263/391, Loss: 0.0185\n",
      "Step 264/391, Loss: 0.0475\n",
      "Step 265/391, Loss: 0.0350\n",
      "Step 266/391, Loss: 0.0257\n",
      "Step 267/391, Loss: 0.0495\n",
      "Step 268/391, Loss: 0.0904\n",
      "Step 269/391, Loss: 0.0845\n",
      "Step 270/391, Loss: 0.0203\n",
      "Step 271/391, Loss: 0.0031\n",
      "Step 272/391, Loss: 0.0236\n",
      "Step 273/391, Loss: 0.0252\n",
      "Step 274/391, Loss: 0.0881\n",
      "Step 275/391, Loss: 0.0223\n",
      "Step 276/391, Loss: 0.0607\n",
      "Step 277/391, Loss: 0.0289\n",
      "Step 278/391, Loss: 0.0145\n",
      "Step 279/391, Loss: 0.0401\n",
      "Step 280/391, Loss: 0.0374\n",
      "Step 281/391, Loss: 0.0771\n",
      "Step 282/391, Loss: 0.0366\n",
      "Step 283/391, Loss: 0.0188\n",
      "Step 284/391, Loss: 0.0090\n",
      "Step 285/391, Loss: 0.0121\n",
      "Step 286/391, Loss: 0.0021\n",
      "Step 287/391, Loss: 0.0121\n",
      "Step 288/391, Loss: 0.0457\n",
      "Step 289/391, Loss: 0.0111\n",
      "Step 290/391, Loss: 0.0202\n",
      "Step 291/391, Loss: 0.0491\n",
      "Step 292/391, Loss: 0.0262\n",
      "Step 293/391, Loss: 0.0261\n",
      "Step 294/391, Loss: 0.0073\n",
      "Step 295/391, Loss: 0.0200\n",
      "Step 296/391, Loss: 0.0396\n",
      "Step 297/391, Loss: 0.0195\n",
      "Step 298/391, Loss: 0.0725\n",
      "Step 299/391, Loss: 0.0133\n",
      "Step 300/391, Loss: 0.0246\n",
      "Step 301/391, Loss: 0.1343\n",
      "Step 302/391, Loss: 0.0890\n",
      "Step 303/391, Loss: 0.0818\n",
      "Step 304/391, Loss: 0.0215\n",
      "Step 305/391, Loss: 0.0090\n",
      "Step 306/391, Loss: 0.0474\n",
      "Step 307/391, Loss: 0.0565\n",
      "Step 308/391, Loss: 0.0022\n",
      "Step 309/391, Loss: 0.0195\n",
      "Step 310/391, Loss: 0.0305\n",
      "Step 311/391, Loss: 0.0720\n",
      "Step 312/391, Loss: 0.0137\n",
      "Step 313/391, Loss: 0.0014\n",
      "Step 314/391, Loss: 0.0170\n",
      "Step 315/391, Loss: 0.0764\n",
      "Step 316/391, Loss: 0.0923\n",
      "Step 317/391, Loss: 0.0352\n",
      "Step 318/391, Loss: 0.0517\n",
      "Step 319/391, Loss: 0.0105\n",
      "Step 320/391, Loss: 0.0954\n",
      "Step 321/391, Loss: 0.0681\n",
      "Step 322/391, Loss: 0.0695\n",
      "Step 323/391, Loss: 0.0972\n",
      "Step 324/391, Loss: 0.0824\n",
      "Step 325/391, Loss: 0.0312\n",
      "Step 326/391, Loss: 0.0236\n",
      "Step 327/391, Loss: 0.0615\n",
      "Step 328/391, Loss: 0.0678\n",
      "Step 329/391, Loss: 0.0347\n",
      "Step 330/391, Loss: 0.0062\n",
      "Step 331/391, Loss: 0.0506\n",
      "Step 332/391, Loss: 0.0043\n",
      "Step 333/391, Loss: 0.0319\n",
      "Step 334/391, Loss: 0.0420\n",
      "Step 335/391, Loss: 0.0668\n",
      "Step 336/391, Loss: 0.0138\n",
      "Step 337/391, Loss: 0.0934\n",
      "Step 338/391, Loss: 0.0497\n",
      "Step 339/391, Loss: 0.1170\n",
      "Step 340/391, Loss: 0.0092\n",
      "Step 341/391, Loss: 0.0701\n",
      "Step 342/391, Loss: 0.0123\n",
      "Step 343/391, Loss: 0.0047\n",
      "Step 344/391, Loss: 0.0267\n",
      "Step 345/391, Loss: 0.0351\n",
      "Step 346/391, Loss: 0.0386\n",
      "Step 347/391, Loss: 0.0092\n",
      "Step 348/391, Loss: 0.1131\n",
      "Step 349/391, Loss: 0.0537\n",
      "Step 350/391, Loss: 0.0393\n",
      "Step 351/391, Loss: 0.0798\n",
      "Step 352/391, Loss: 0.0258\n",
      "Step 353/391, Loss: 0.0623\n",
      "Step 354/391, Loss: 0.0363\n",
      "Step 355/391, Loss: 0.0066\n",
      "Step 356/391, Loss: 0.0519\n",
      "Step 357/391, Loss: 0.0292\n",
      "Step 358/391, Loss: 0.0476\n",
      "Step 359/391, Loss: 0.0512\n",
      "Step 360/391, Loss: 0.0557\n",
      "Step 361/391, Loss: 0.0548\n",
      "Step 362/391, Loss: 0.0226\n",
      "Step 363/391, Loss: 0.0505\n",
      "Step 364/391, Loss: 0.0296\n",
      "Step 365/391, Loss: 0.0524\n",
      "Step 366/391, Loss: 0.0056\n",
      "Step 367/391, Loss: 0.0332\n",
      "Step 368/391, Loss: 0.0312\n",
      "Step 369/391, Loss: 0.0388\n",
      "Step 370/391, Loss: 0.0541\n",
      "Step 371/391, Loss: 0.0693\n",
      "Step 372/391, Loss: 0.0372\n",
      "Step 373/391, Loss: 0.1203\n",
      "Step 374/391, Loss: 0.0964\n",
      "Step 375/391, Loss: 0.0076\n",
      "Step 376/391, Loss: 0.0758\n",
      "Step 377/391, Loss: 0.0501\n",
      "Step 378/391, Loss: 0.0265\n",
      "Step 379/391, Loss: 0.0404\n",
      "Step 380/391, Loss: 0.0633\n",
      "Step 381/391, Loss: 0.0426\n",
      "Step 382/391, Loss: 0.0295\n",
      "Step 383/391, Loss: 0.0086\n",
      "Step 384/391, Loss: 0.1037\n",
      "Step 385/391, Loss: 0.0457\n",
      "Step 386/391, Loss: 0.0064\n",
      "Step 387/391, Loss: 0.0309\n",
      "Step 388/391, Loss: 0.1109\n",
      "Step 389/391, Loss: 0.0232\n",
      "Step 390/391, Loss: 0.0326\n",
      "Step 391/391, Loss: 0.0656\n",
      "Epoch 25/25, Average Train Loss: 0.0349\n",
      "Epoch 25/25, Average Validation Loss: 0.0720\n",
      "Model saved at epoch 25 with validation loss: 0.0720\n",
      "Elapsed time: 120 sec\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.in_dim = 784 # 28 * 28\n",
    "args.out_dim = 10 # number of classes \n",
    "args.hid_dim = 200\n",
    "args.n_layers = 5\n",
    "args.act_layer = nn.ReLU\n",
    "args.dropout = 0.1\n",
    "args.batch_norm = True\n",
    "args.init_weights = True\n",
    "args.val_interval = 1\n",
    "\n",
    "args.lr = 0.005\n",
    "args.epoch = 25\n",
    "\n",
    "list_epoch, list_train_loss, list_val_loss, best_model = run_experiment(args)\n",
    "\n",
    "te = time.time()\n",
    "\n",
    "print('Elapsed time: {} sec'.format(int(te-ts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Report and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'epoch vs loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# ====== Loss Fluctuation ====== #\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(list_epoch, list_train_loss, label='train_loss')\n",
    "ax1.plot(list_epoch, list_val_loss, '--', label='val_loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_ylim(0, max(list_train_loss) + 0.5)\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "ax1.set_title('epoch vs loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data shape: torch.Size([128, 1, 28, 28])\n",
      "Example targets shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(f\"Example data shape: {example_data.shape}\")\n",
    "print(f\"Example targets shape: {example_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the best model on test\n",
    "\n",
    "best_model.eval() # Set the model be 'test mode'\n",
    "\n",
    "\n",
    "all_true_ys = []\n",
    "all_pred_ys = []\n",
    "\n",
    "# ====== Test ====== #\n",
    "with torch.no_grad():\n",
    "\n",
    "    for input_X, true_y in test_loader:\n",
    "\n",
    "        input_x = input_X.squeeze()\n",
    "        input_x = input_x.view(-1, 784)\n",
    "        input_x = input_x.to(device)\n",
    "        true_y = true_y.to(device)\n",
    "\n",
    "        pred_y = best_model(input_x)\n",
    "\n",
    "        pred_y = torch.argmax(pred_y, dim=1)\n",
    "        pred_y = pred_y.cpu().numpy()\n",
    "        true_y = true_y.cpu().numpy()\n",
    "\n",
    "        # get all the true and predicted labels\n",
    "        all_true_ys.extend(y for y in true_y)\n",
    "        all_pred_ys.extend(y for y in pred_y)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(true_y, pred_y)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    cm = confusion_matrix(true_y, pred_y)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
